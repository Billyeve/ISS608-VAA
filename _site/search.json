[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04.2.html",
    "title": "Hands-on Exercise 04.2",
    "section": "",
    "text": "A point estimate is a single number, such as a mean.\nUncertainty is expressed as standard error, confidence interval, or credible interval\nImportant:\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate, ggpubr)\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nThe code chunk below performs the followings:\n\ngroup the observation by RACE,\ncomputes the count of observations, mean, standard deviation and standard error of Maths by RACE, and\nsave the output as a tibble data table called my_sum.\n\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nNote: For the mathematical explanation, please refer to Slide 20 of Lesson 4.\nNext, the code chunk below will\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\n\n\nThe code chunk below is used to reveal the standard error of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE,-mean), \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.95, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\np <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE,-mean), \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.99, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"99% confidence interval of mean maths score by race\")\n\npp <- highlight(ggplotly(p))\n\nd <- highlight_key(my_sum)\n\ncrosstalk::bscols(pp,\n                  DT::datatable(d))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04.2.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 04.2",
    "section": "Visualising Uncertainty: ggdist package",
    "text": "Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +   #<<\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\nWarning in layer_slabinterval(data = data, mapping = mapping, stat =\nStatPointinterval, : Ignoring unknown parameters: `.point` and `.interval`\n\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\nWarning: fill_type = \"gradient\" is not supported by the current graphics device.\n - Falling back to fill_type = \"segments\".\n - If you believe your current graphics device *does* support\n   fill_type = \"gradient\" but auto-detection failed, set that option\n   explicitly and consider reporting a bug.\n - See help(\"geom_slabinterval\") for more information.\n\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04.2.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 04.2",
    "section": "Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nSkipping install of 'ungeviz' from a github remote, the SHA1 (aeae12b0) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\nWarning in geom_hpline(data = sampler(25, group = RACE), height = 0.6, color =\n\"#D55E00\"): Ignoring unknown parameters: `height`\n\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.2.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04.2.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on Exercise 04.2",
    "section": "Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\nWarning in geom_hpline(data = sampler(25, group = RACE), height = 0.6, color =\n\"#D55E00\"): Ignoring unknown parameters: `height`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04.3.html",
    "title": "Hands-on Exercise 04.3",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04.3.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 04.3",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04.3.html#importing-data",
    "title": "Hands-on Exercise 04.3",
    "section": "Importing Data",
    "text": "Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)\n\nRows: 267 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, District, Sub-district\ndbl (4): Sub-district ID, Positive, Recovered, Death\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04.3.html#funnelplotr-methods",
    "title": "Hands-on Exercise 04.3",
    "section": "FunnelPlotR methods",
    "text": "FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\nFunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\nFunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #<<\n  xrange = c(0, 6500),  #<<\n  yrange = c(0, 0.05)   #<<\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead. For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead. For more options, see the help: `?funnel_plot`\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\nFunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead. For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead. For more options, see the help: `?funnel_plot`\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04.3.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 04.3",
    "section": "Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\nComputing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\nCalculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\n\n\nPlotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\nWarning in geom_point(aes(label = `Sub-district`), alpha = 0.4): Ignoring\nunknown aesthetics: label\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\np\n\n\n\n\n\n\nInteractive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.3.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04.3.html#references",
    "title": "Hands-on Exercise 04.3",
    "section": "References",
    "text": "References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04.1.html",
    "title": "Hands-on Exercise 04.1",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04.1.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 04.1",
    "section": "Visual Statistical Analysis with ggstatsplot",
    "text": "Visual Statistical Analysis with ggstatsplot\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04.1.html#getting-started",
    "title": "Hands-on Exercise 04.1",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\nImporting data\n\n\n\n\n\n\nDo-it-Yourself\n\n\n\nImporting Exam.csv data by using appropriate tidyverse package.\n\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nOne-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\nUnpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\nHow to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\nTwo-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\nOneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\nggbetweenstats - Summary of tests\n\n\n\n\n\n\nSignificant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\nSignificant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 <- exam %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(.fns = ~droplevels(as.factor(.x)))`.\nCaused by warning:\n! Using `across()` without supplying `.cols` was deprecated in dplyr 1.1.0.\nℹ Please supply `.cols` instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04.1.html#visualising-models",
    "title": "Hands-on Exercise 04.1",
    "section": "Visualising Models",
    "text": "Visualising Models\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex04.1.html#getting-started-1",
    "title": "Hands-on Exercise 04.1",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04.1.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04.1.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 04.1",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\nImporting Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\nMultiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\nModel Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\nModel Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n <- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\nModel Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\nModel Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\nVisualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\nVisualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 08",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on Exercise 08",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#the-data",
    "title": "Hands-on Exercise 08",
    "section": "The Data",
    "text": "The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nThe edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#the-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#the-data-1",
    "title": "Hands-on Exercise 08",
    "section": "The Data",
    "text": "The Data\n\nThe nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#importing-network-data-from-files",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#importing-network-data-from-files",
    "title": "Hands-on Exercise 08",
    "section": "Importing network data from files",
    "text": "Importing network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\n\nRows: 54 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): label, Department, Title\ndbl (1): id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\nRows: 9063 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): SentDate, Subject, MainSubject, sourceLabel, targetLabel\ndbl  (2): source, target\ntime (1): SentTime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nReviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nWarning: The output report of GAStech_edges above reveals that the SentDate is treated as “Character”” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\nWrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\nThings to learn from the code chunk above:\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\n\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\nReviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    <date> 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     <ord> Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\nWrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\nThings to learn from the code chunk above:\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\n\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\nReviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  <dbl> 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday <ord> Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  <int> 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 08",
    "section": "Creating network objects using tidygraph",
    "text": "Creating network objects using tidygraph\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 – A tidy hope\n\n\nThe tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network.\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#the-dplyr-verbs-in-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#the-dplyr-verbs-in-tidygraph",
    "title": "Hands-on Exercise 08",
    "section": "The dplyr verbs in tidygraph",
    "text": "The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\nUsing tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\nReviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# … with 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# … with 1,369 more rows\n\n\n\n\nReviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\nChanging the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# … with 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# … with 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\nPlotting Network Data with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\n[edges]((https://cran.r-project.org/web/packages/ggraph/vignettes/Edges.html) and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nPlotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\nUsing \"stress\" as default layout\n\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\nChanging the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\nUsing \"stress\" as default layout\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\n\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\nChanging the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\nUsing \"stress\" as default layout\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\nWorking with ggraph’s layouts\nggraph() support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\nFruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\nModifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\nModifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#creating-facet-graphs",
    "title": "Hands-on Exercise 08",
    "section": "Creating facet graphs",
    "text": "Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\nWorking with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\nWorking with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\nA framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nWorking with facet_nodes()\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#network-metrics-analysis",
    "title": "Hands-on Exercise 08",
    "section": "Network Metrics Analysis",
    "text": "Network Metrics Analysis\n\nComputing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\nVisualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\nVisualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `community = as.factor(group_edge_betweenness(weights = Weight,\n  directed = TRUE))`.\nCaused by warning in `cluster_edge_betweenness()`:\n! At core/community/edge_betweenness.c:493 : Membership vector will be selected based on the highest modularity score.\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 08",
    "section": "Building Interactive Network Graph with visNetwork",
    "text": "Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\nData preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'from'. You can override using the\n`.groups` argument.\n\n\n\n\nPlotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\nWorking with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\nWorking with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nWorking with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument. ]\n\n\nInteractivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n- The argument highlightNearest highlights nearest when clicking a node.\n- The argument nodesIdSelection adds an id node selection creating an HTML select element.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09.html",
    "title": "Hands-on Exercise 09",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#getting-started",
    "title": "Hands-on Exercise 09",
    "section": "Getting started",
    "text": "Getting started\nFor the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse, RODBC, readr)\n\n\ntidyverse provides a collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data. It is not a single package but a collection of modern R packages including but not limited to readr, tidyr, dplyr, ggplot, tibble, stringr, forcats and purrr.\nlubridate provides functions to work with dates and times more efficiently.\nggthemes is an extension of ggplot2. It provides additional themes beyond the basic themes of ggplot2.\ngtExtras provides some additional helper functions to assist in creating beautiful tables with gt, an R package specially designed for anyone to make wonderful-looking tables using the R programming language.\nreactablefmtr provides various features to streamline and enhance the styling of interactive reactable tables with easy-to-use and highly-customizable functions and themes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#importing-microsoft-access-database",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#importing-microsoft-access-database",
    "title": "Hands-on Exercise 09",
    "section": "Importing Microsoft Access database",
    "text": "Importing Microsoft Access database\n\nThe data set\nFor the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\n\n\nImporting database into R\nIn the code chunk below, odbcConnectAccess() of RODBC package is used used to import a database query table into R.\n\n#library(RODBC)\n#con <- odbcConnectAccess('data/Coffee Chain.mdb')\n#coffeechain <- sqlFetch(con, 'CoffeeChain Query')\n#write_rds(coffeechain, \"data/CoffeeChain.rds\")\n#odbcClose(con)\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the odbcConnectAccess() is based on 32bit and not 64bit\n\n\nData Preparation\nThe code chunk below is used to import CoffeeChain.rds into R.\n\ncoffeechain <- read_rds(\"data/CoffeeChain.rds\")\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nproduct <- coffeechain %>%\n  group_by(`Product`) %>%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %>%\n  ungroup()\n\n\n\nBullet chart in ggplot2\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#plotting-sparklines-using-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#plotting-sparklines-using-ggplot2",
    "title": "Hands-on Exercise 09",
    "section": "Plotting sparklines using ggplot2",
    "text": "Plotting sparklines using ggplot2\nIn this section, you will learn how to plot sparklines by using ggplot2.\n\nPreparing the data\n\nsales_report <- coffeechain %>%\n  filter(Date >= \"2013-01-01\") %>%\n  mutate(Month = month(Date)) %>%\n  group_by(Month, Product) %>%\n  summarise(Sales = sum(Sales)) %>%\n  ungroup() %>%\n  select(Month, Product, Sales)\n\n`summarise()` has grouped output by 'Month'. You can override using the\n`.groups` argument.\n\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\nmins <- group_by(sales_report, Product) %>% \n  slice(which.min(Sales))\nmaxs <- group_by(sales_report, Product) %>% \n  slice(which.max(Sales))\nends <- group_by(sales_report, Product) %>% \n  filter(Month == max(Month))\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\nquarts <- sales_report %>%\n  group_by(Product) %>%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %>%\n  right_join(sales_report)\n\nJoining with `by = join_by(Product)`\n\n\n\n\nsparklines in ggplot2\nThe code chunk used.\n\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "title": "Hands-on Exercise 09",
    "section": "Static Information Dashboard Design: gt and gtExtras methods",
    "text": "Static Information Dashboard Design: gt and gtExtras methods\nIn this section, you will learn how to create static information dashboard by using gt and gtExtras packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\n\nPlotting a simple bullet chart\nIn this section, you will learn how to prepare a bullet chart report by using functions of gt and gtExtras packages.\n\nproduct %>%\n  gt::gt() %>%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %>%\n  gt_theme_538()\n\n\n\n\n\n  \n  \n    \n      Product\n      current\n    \n  \n  \n    Amaretto\n          \n    Caffe Latte\n          \n    Caffe Mocha\n          \n    Chamomile\n          \n    Colombian\n          \n    Darjeeling\n          \n    Decaf Espresso\n          \n    Decaf Irish Cream\n          \n    Earl Grey\n          \n    Green Tea\n          \n    Lemon\n          \n    Mint\n          \n    Regular Espresso"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#sparklines-gtextras-method",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#sparklines-gtextras-method",
    "title": "Hands-on Exercise 09",
    "section": "sparklines: gtExtras method",
    "text": "sparklines: gtExtras method\nBefore we can prepare the sales report by product by using gtExtras functions, code chunk below will be used to prepare the data.\n\nreport <- coffeechain %>%\n  mutate(Year = year(Date)) %>%\n  filter(Year == \"2013\") %>%\n  mutate (Month = month(Date, \n                        label = TRUE, \n                        abbr = TRUE)) %>%\n  group_by(Product, Month) %>%\n  summarise(Sales = sum(Sales)) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'Product'. You can override using the\n`.groups` argument.\n\n\nIt is important to note that one of the requirement of gtExtras functions is that almost exclusively they require you to pass data.frame with list columns. In view of this, code chunk below will be used to convert the report data.frame into list columns.\n\nreport %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n# A tibble: 13 × 2\n   Product           `Monthly Sales`\n   <chr>             <list>         \n 1 Amaretto          <dbl [12]>     \n 2 Caffe Latte       <dbl [12]>     \n 3 Caffe Mocha       <dbl [12]>     \n 4 Chamomile         <dbl [12]>     \n 5 Colombian         <dbl [12]>     \n 6 Darjeeling        <dbl [12]>     \n 7 Decaf Espresso    <dbl [12]>     \n 8 Decaf Irish Cream <dbl [12]>     \n 9 Earl Grey         <dbl [12]>     \n10 Green Tea         <dbl [12]>     \n11 Lemon             <dbl [12]>     \n12 Mint              <dbl [12]>     \n13 Regular Espresso  <dbl [12]>     \n\n\n\nPlotting Coffechain Sales report\n\nreport %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %>%\n   gt() %>%\n   gt_plt_sparkline('Monthly Sales')\n\n\n\n\n\n  \n  \n    \n      Product\n      Monthly Sales\n    \n  \n  \n    Amaretto\n          1.2K\n    Caffe Latte\n          1.5K\n    Caffe Mocha\n          3.7K\n    Chamomile\n          3.3K\n    Colombian\n          5.5K\n    Darjeeling\n          3.0K\n    Decaf Espresso\n          3.2K\n    Decaf Irish Cream\n          2.7K\n    Earl Grey\n          3.0K\n    Green Tea\n          1.5K\n    Lemon\n          4.4K\n    Mint\n          1.5K\n    Regular Espresso\n          1.1K\n  \n  \n  \n\n\n\n\n\n\nAdding statistics\nFirst, calculate summary statistics by using the code chunk below.\n\nreport %>% \n  group_by(Product) %>% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %>%\n  gt() %>%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\n  \n  \n    \n      Product\n      Min\n      Max\n      Average\n    \n  \n  \n    Amaretto\n1016\n1210\n1,119.00\n    Caffe Latte\n1398\n1653\n1,528.33\n    Caffe Mocha\n3322\n3828\n3,613.92\n    Chamomile\n2967\n3395\n3,217.42\n    Colombian\n5132\n5961\n5,457.25\n    Darjeeling\n2926\n3281\n3,112.67\n    Decaf Espresso\n3181\n3493\n3,326.83\n    Decaf Irish Cream\n2463\n2901\n2,648.25\n    Earl Grey\n2730\n3005\n2,841.83\n    Green Tea\n1339\n1476\n1,398.75\n    Lemon\n3851\n4418\n4,080.83\n    Mint\n1388\n1669\n1,519.17\n    Regular Espresso\n890\n1218\n1,023.42\n  \n  \n  \n\n\n\n\n\n\nCombining the data.frame\nNext, use the code chunk below to add the statistics on the table.\n\nspark <- report %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\nsales <- report %>% \n  group_by(Product) %>% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\nsales_data = left_join(sales, spark)\n\nJoining with `by = join_by(Product)`\n\n\n\n\nPlotting the updated data.table\n\nsales_data %>%\n  gt() %>%\n  gt_plt_sparkline('Monthly Sales')\n\n\n\n\n\n  \n  \n    \n      Product\n      Min\n      Max\n      Average\n      Monthly Sales\n    \n  \n  \n    Amaretto\n1016\n1210\n1119.000\n          1.2K\n    Caffe Latte\n1398\n1653\n1528.333\n          1.5K\n    Caffe Mocha\n3322\n3828\n3613.917\n          3.7K\n    Chamomile\n2967\n3395\n3217.417\n          3.3K\n    Colombian\n5132\n5961\n5457.250\n          5.5K\n    Darjeeling\n2926\n3281\n3112.667\n          3.0K\n    Decaf Espresso\n3181\n3493\n3326.833\n          3.2K\n    Decaf Irish Cream\n2463\n2901\n2648.250\n          2.7K\n    Earl Grey\n2730\n3005\n2841.833\n          3.0K\n    Green Tea\n1339\n1476\n1398.750\n          1.5K\n    Lemon\n3851\n4418\n4080.833\n          4.4K\n    Mint\n1388\n1669\n1519.167\n          1.5K\n    Regular Espresso\n890\n1218\n1023.417\n          1.1K\n  \n  \n  \n\n\n\n\n\n\nCombining bullet chart and sparklines\nSimilarly, we can combining the bullet chart and sparklines using the steps below.\n\nbullet <- coffeechain %>%\n  filter(Date >= \"2013-01-01\") %>%\n  group_by(`Product`) %>%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %>%\n  ungroup() \n\n\nsales_data = sales_data %>%\n  left_join(bullet)\n\nJoining with `by = join_by(Product)`\n\n\n\nsales_data %>%\n  gt() %>%\n  gt_plt_sparkline('Monthly Sales') %>%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %>%\n  gt_theme_538()\n\n\n\n\n\n  \n  \n    \n      Product\n      Min\n      Max\n      Average\n      Monthly Sales\n      Actual\n    \n  \n  \n    Amaretto\n1016\n1210\n1119.000\n          1.2K\n          \n    Caffe Latte\n1398\n1653\n1528.333\n          1.5K\n          \n    Caffe Mocha\n3322\n3828\n3613.917\n          3.7K\n          \n    Chamomile\n2967\n3395\n3217.417\n          3.3K\n          \n    Colombian\n5132\n5961\n5457.250\n          5.5K\n          \n    Darjeeling\n2926\n3281\n3112.667\n          3.0K\n          \n    Decaf Espresso\n3181\n3493\n3326.833\n          3.2K\n          \n    Decaf Irish Cream\n2463\n2901\n2648.250\n          2.7K\n          \n    Earl Grey\n2730\n3005\n2841.833\n          3.0K\n          \n    Green Tea\n1339\n1476\n1398.750\n          1.5K\n          \n    Lemon\n3851\n4418\n4080.833\n          4.4K\n          \n    Mint\n1388\n1669\n1519.167\n          1.5K\n          \n    Regular Espresso\n890\n1218\n1023.417\n          1.1K"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "title": "Hands-on Exercise 09",
    "section": "Interactive Information Dashboard Design: reactable and reactablefmtr methods",
    "text": "Interactive Information Dashboard Design: reactable and reactablefmtr methods\nIn this section, you will learn how to create interactive information dashboard by using reactable and reactablefmtr packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\nIn order to build an interactive sparklines, we need to install dataui R package by using the code chunk below.\n\nremotes::install_github(\"timelyportfolio/dataui\")\n\nSkipping install of 'dataui' from a github remote, the SHA1 (39583c66) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\nNext, you all need to load the package onto R environment by using the code chunk below.\n\nlibrary(dataui)\n\n\nPlotting interactive sparklines\nSimilar to gtExtras, to plot an interactive sparklines by using reactablefmtr package we need to prepare the list field by using the code chunk below.\n\nreport <- report %>%\n  group_by(Product) %>%\n  summarize(`Monthly Sales` = list(Sales))\n\nNext, react_sparkline will be to plot the sparklines as shown below.\n\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\nWarning: `bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n\n\n\n\n\n\n\n\n\nChanging the pagesize\nBy default the pagesize is 10. In the code chunk below, arguments defaultPageSize is used to change the default setting.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\nWarning: `bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n\n\n\n\n\n\n\n\n\nAdding points and labels\nIn the code chunk below highlight_points argument is used to show the minimum and maximum values points and label argument is used to label first and last values.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\nWarning: `bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n\n\n\n\n\n\n\n\n\nAdding reference line\nIn the code chunk below statline argument is used to show the mean line.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\nWarning: `bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n\n\n\n\n\n\n\n\n\nAdding bandline\nInstead adding reference line, bandline can be added by using the bandline argument.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\nWarning: `bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n\n\n\n\n\n\n\n\n\nChanging from sparkline to sparkbar\nInstead of displaying the values as sparklines, we can display them as sparkbars as shiwn below.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)\n\nWarning: `bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'. \n`bindFillRole()` only works on htmltools::tag() objects (e.g., div(), p(), etc.), not objects of type 'shiny.tag.list'."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.3.html",
    "href": "Hands-on_Ex/Hands-on_Ex07.3.html",
    "title": "Hands-on Exercise 07.2",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07.3.html#getting-started",
    "title": "Hands-on Exercise 07.2",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and loading packages\n\npacman::p_load(tmap, tidyverse, sf)\n\n\n\nImporting data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp <- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.3.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex07.3.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 07.2",
    "section": "Basic Choropleth Mapping",
    "text": "Basic Choropleth Mapping\n\nVisualizing distribution of non-functional water point\n\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.3.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex07.3.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 07.2",
    "section": "Choropleth Map for Rates",
    "text": "Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\nDeriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\nPlotting map of rate\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.3.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex07.3.html#extreme-value-maps",
    "title": "Hands-on Exercise 07.2",
    "section": "Extreme Value Maps",
    "text": "Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\nPercentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\nData Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent <- c(0,.01,.1,.5,.9,.99,1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\nWhy writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\nCreating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% \n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\nA percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\nTest drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\nBox map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\nCreating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n\nCreating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\nTest drive the newly created function\nLet’s test the newly created function\n\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\nBoxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nboxmap(\"wp_nonfunctional\", NGA_wp)\n\nWarning: Breaks contains positive and negative values. Better is to use\ndiverging scale instead, or set auto.palette.mapping to FALSE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex05.1.html",
    "title": "Hands-on Exercise 05.1",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.1.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05.1.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 05.1",
    "section": "Installing and launching R packages",
    "text": "Installing and launching R packages\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\npacman::p_load(ggtern, plotly, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.1.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05.1.html#data-preparation",
    "title": "Hands-on Exercise 05.1",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nThe data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\nImporting Data\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\nRows: 108126 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): PA, SZ, AG\ndbl (2): Year, Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nPreparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.1.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05.1.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 05.1",
    "section": "Plotting Ternary Diagram with R",
    "text": "Plotting Ternary Diagram with R\n\nPlotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\nPlotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\nNo scatterternary mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex07.2.html",
    "title": "Hands-on Exercise 07.2",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07.2.html#getting-started",
    "title": "Hands-on Exercise 07.2",
    "section": "Getting Started",
    "text": "Getting Started\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.2.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07.2.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 07.2",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nThe data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\nData Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools <- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nRows: 306 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): NAME, ADDRESS, OUTLET TYPE\ndbl (4): POSTCODE, XCOORD, YCOORD, Gp1Gp2 Winnings\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME                            ADDRESS POSTC…¹ XCOORD YCOORD OUTLE…² Gp1Gp…³\n   <chr>                           <chr>     <dbl>  <dbl>  <dbl> <chr>     <dbl>\n 1 Livewire (Marina Bay Sands)     2 Bayf…   18972 30842. 29599. Branch        5\n 2 Livewire (Resorts World Sentos… 26 Sen…   98138 26704. 26526. Branch       11\n 3 SportsBuzz (Kranji)             Lotus …  738078 20118. 44888. Branch        0\n 4 SportsBuzz (PoMo)               1 Sele…  188306 29777. 31382. Branch       44\n 5 Prime Serangoon North           Blk 54…  552542 32239. 39519. Branch        0\n 6 Singapore Pools Woodlands Cent… 1A Woo…  731001 21012. 46987. Branch        3\n 7 Singapore Pools 64 Circuit Rd … Blk 64…  370064 33990. 34356. Branch       17\n 8 Singapore Pools 88 Circuit Rd … Blk 88…  370088 33847. 33976. Branch       16\n 9 Singapore Pools Anchorvale Rd … Blk 30…  540308 33910. 41275. Branch       21\n10 Singapore Pools Ang Mo Kio N2 … Blk 20…  560202 29246. 38943. Branch       25\n# … with 296 more rows, and abbreviated variable names ¹​POSTCODE,\n#   ²​`OUTLET TYPE`, ³​`Gp1Gp2 Winnings`\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\nCreating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf <- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                ADDRESS POSTC…¹ OUTLE…² Gp1Gp…³            geometry\n * <chr>               <chr>     <dbl> <chr>     <dbl>         <POINT [m]>\n 1 Livewire (Marina B… 2 Bayf…   18972 Branch        5 (30841.56 29598.56)\n 2 Livewire (Resorts … 26 Sen…   98138 Branch       11  (26703.87 26525.7)\n 3 SportsBuzz (Kranji) Lotus …  738078 Branch        0 (20117.93 44888.06)\n 4 SportsBuzz (PoMo)   1 Sele…  188306 Branch       44 (29776.95 31382.18)\n 5 Prime Serangoon No… Blk 54…  552542 Branch        0 (32238.69 39518.76)\n 6 Singapore Pools Wo… 1A Woo…  731001 Branch        3 (21012.15 46987.32)\n 7 Singapore Pools 64… Blk 64…  370064 Branch       17 (33990.39 34355.53)\n 8 Singapore Pools 88… Blk 88…  370088 Branch       16 (33847.38 33976.04)\n 9 Singapore Pools An… Blk 30…  540308 Branch       21 (33909.93 41274.52)\n10 Singapore Pools An… Blk 20…  560202 Branch       25  (29246.06 38942.6)\n# … with 296 more rows, and abbreviated variable names ¹​POSTCODE,\n#   ²​`OUTLET TYPE`, ³​`Gp1Gp2 Winnings`\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.2.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex07.2.html#drawing-proportional-symbol-map",
    "title": "Hands-on Exercise 07.2",
    "section": "Drawing Proportional Symbol Map",
    "text": "Drawing Proportional Symbol Map\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\n\nIt all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nLets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\nLets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\nI have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\nLegend for symbol sizes not available in view mode.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex07.2.html#reference",
    "title": "Hands-on Exercise 07.2",
    "section": "Reference",
    "text": "Reference\n\nAll about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\nGeospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\nData wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex05.2.html",
    "title": "Hands-on Exercise 05.2",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.2.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05.2.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 05.2",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nBefore you get started, you are required:\n\nto start a new R project, and\nto create a new R Markdown document.\n\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, tidyverse, ggstatsplot, ggcorrplot)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.2.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05.2.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 05.2",
    "section": "Importing and Preparing The Data Set",
    "text": "Importing and Preparing The Data Set\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\nImporting Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\nRows: 6497 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): type\ndbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.2.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05.2.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 05.2",
    "section": "Building Correlation Matrix: pairs() method",
    "text": "Building Correlation Matrix: pairs() method\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\nBuilding a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\nDrawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\nIncluding with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr <- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr <- abs(cor(x, y, use=\"complete.obs\"))\ntxt <- format(c(r, 0.123456789), digits=digits)[1]\ntxt <- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter\n\nWarning in par(usr): argument 1 does not name a graphical parameter"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.2.html#visualizing-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05.2.html#visualizing-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 05.2",
    "section": "Visualizing Correlation Matrix: ggcormat()",
    "text": "Visualizing Correlation Matrix: ggcormat()\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\nThe basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n)\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\n\nBuilding multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.2.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05.2.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 05.2",
    "section": "Visualising Correlation Matrix using corrplot Package",
    "text": "Visualising Correlation Matrix using corrplot Package\nIn this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\nGetting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor <- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\nWorking with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\nWorking with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\n\nWorking with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\nCombining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\nReorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\nReordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05.2.html#reference",
    "title": "Hands-on Exercise 05.2",
    "section": "Reference",
    "text": "Reference\nMichael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180.\n\nR packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.3.html",
    "href": "Hands-on_Ex/Hands-on_Ex05.3.html",
    "title": "Hands-on Exercise 05.3",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.3.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05.3.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 05.3",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nBefore you get started, you are required:\n\nto start a new R project, and\nto create a new R Markdown document.\n\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.3.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05.3.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 05.3",
    "section": "Importing and Preparing The Data Set",
    "text": "Importing and Preparing The Data Set\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\nImporting the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe output tibbled data frame is called wh.\n\n\nPreparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) <- wh$Country\n\nWarning: Setting row names on a tibble is deprecated.\n\n\nNotice that the row number has been replaced into the country name.\n\n\nTransforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.3.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05.3.html#static-heatmap",
    "title": "Hands-on Exercise 05.3",
    "section": "Static Heatmap",
    "text": "Static Heatmap\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\nheatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.3.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05.3.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 05.3",
    "section": "Creating Interactive Heatmap",
    "text": "Creating Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\nWorking with heatmaply\n\nheatmaply(mtcars)\n\nWarning in doTryCatch(return(expr), name, parentenv, handler): unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':\n  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 0x0006): Library not loaded: /opt/X11/lib/libSM.6.dylib\n  Referenced from: <05451E21-B5F6-3B2F-9C0F-3EA08D57DC34> /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/modules/R_X11.so\n  Reason: tried: '/opt/X11/lib/libSM.6.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libSM.6.dylib' (no such file), '/opt/X11/lib/libSM.6.dylib' (no such file), '/Library/Frameworks/R.framework/Resources/lib/libSM.6.dylib' (no such file), '/Library/Java/JavaVirtualMachines/jdk-17.0.1+12/Contents/Home/lib/server/libSM.6.dylib' (no such file)\n\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.3.html#data-trasformation",
    "href": "Hands-on_Ex/Hands-on_Ex05.3.html#data-trasformation",
    "title": "Hands-on Exercise 05.3",
    "section": "Data trasformation",
    "text": "Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\nScaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\n\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nNormalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\nPercentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\nClustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\nManual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nStatistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n5.4 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\nRegistered S3 method overwritten by 'gclus':\n  method         from     \n  reorder.hclust seriation\n\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\nWorking with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.3.html#the-finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex05.3.html#the-finishing-touch",
    "title": "Hands-on Exercise 05.3",
    "section": "The finishing touch",
    "text": "The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex07.1.html",
    "title": "Hands-on Exercise 07.1",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07.1.html#getting-started",
    "title": "Hands-on Exercise 07.1",
    "section": "Getting Started",
    "text": "Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.1.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex07.1.html#importing-data-into-r",
    "title": "Hands-on Exercise 07.1",
    "section": "Importing Data into R",
    "text": "Importing Data into R\n\nThe Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\nImporting Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/bryantlee/Billyeve/ISS608-VAA/Hands-on_Ex/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\nImporting Attribute Data into R\nNext, we will import respopagsex2000to2018.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nData Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nData wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\nJoining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.1.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex07.1.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 07.1",
    "section": "Choropleth Mapping Geospatial Data Using tmap",
    "text": "Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\nPlotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\nCreating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nPlotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\n\nPlotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\nUsing ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\nMap Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMap style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\nCartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\nMappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07.1.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex07.1.html#reference",
    "title": "Hands-on Exercise 07.1",
    "section": "Reference",
    "text": "Reference\n\nAll about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\nGeospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\nData wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.4.html",
    "href": "Hands-on_Ex/Hands-on_Ex05.4.html",
    "title": "Hands-on Exercise 05.3",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package.\n\n\n\nFor this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.4.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05.4.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 05.3",
    "section": "Plotting Static Parallel Coordinates Plot",
    "text": "Plotting Static Parallel Coordinates Plot\nIn this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\nPlotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\nPlotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\n\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\nParallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\nRotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\nAdjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.4.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05.4.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 05.3",
    "section": "Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\nThe basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh <- wh %>%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\nRotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\nChanging the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\nParallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.4.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex05.4.html#references",
    "title": "Hands-on Exercise 05.3",
    "section": "References",
    "text": "References\n\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 02",
    "section": "",
    "text": "Before we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\nThe chunk code on the right will do the trick.\n\n\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel) \n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#beyond-ggplot2-annotation",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#beyond-ggplot2-annotation",
    "title": "Hands-on Exercise 02",
    "section": "Beyond ggplot2 Annotation",
    "text": "Beyond ggplot2 Annotation\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nWorking with ggrepel\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right. We simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 02",
    "section": "Beyond ggplot2 Themes",
    "text": "Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +  \n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\nWorking with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\nWorking with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18, \n              base_size = 15, \n              grid = \"Y\") \n\n\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk below?\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#beyond-ggplot2-facet",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#beyond-ggplot2-facet",
    "title": "Hands-on Exercise 02",
    "section": "Beyond ggplot2 facet",
    "text": "Beyond ggplot2 facet\nIn this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics.\n\np1 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\np2 <- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\np3 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\nCreating Composite Graphics: pathwork methods\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, I am going to shared with you patchwork.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines: - Two-Column Layout using the Plus Sign +. - Parenthesis () to create a subplot group. - Two-Row Layout using the Division Sign \\\n\n\n\nWorking with patchwork\n\np1 + p2 / p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nwill place the plots beside each other, while / will stack them.\n\n\n(p1 / p2) | p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nTo learn more about, refer to Plot Assembly.\npatchwork also provides auto-tagging capabilities, in order to identify subplots in text:\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\npatchwork <- (p1 / p2) | p3\npatchwork & theme_economist()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 02",
    "section": "Reference",
    "text": "Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 02",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create:\n\ninteractive data visualisation by using ggiraph and plotlyr packages,\nanimated data visualisation by using gganimate and plotlyr packages.\nVisualising univariate data with large number of categories by using rPackedBar package.\n\nAt the same time, you will also learn how to:\n\nreshape data by using tidyr package, and\nprocess, wrangle and transform data by using dplyr package.\n\n\nGetting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for compising multiple plots.\n\n\npacman::p_load(ggiraph, plotly, gganimate, DT, tidyverse, patchwork, gapminder, rPackedBar, ggplot2, gifski, av, magick)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 02",
    "section": "Importing Data",
    "text": "Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 02",
    "section": "Interactive Data Visualisation - ggiraph methods",
    "text": "Interactive Data Visualisation - ggiraph methods\n\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nTooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nInteractivity: By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\nComparing ggplot2 and ggiraph codes\nThe original ggplot2 code chunk.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5, \n               dotsize = 0.5) +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\n\n\n\n\nThe ggiraph code chunk.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              #<<\n    aes(tooltip = ID),                   #<<\n    stackgroups = TRUE,                  #<<\n    binwidth = 1,                        #<<\n    method = \"histodot\") +               #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  #<<\n  ggobj = p,                             #<<\n  width_svg = 6,                         #<<\n  height_svg = 6*0.618                   #<<   \n)                                        #<<\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\nDisplaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip <- c(paste0(     #<<\n  \"Name = \", exam_data$ID,         #<<\n  \"\\n Class = \", exam_data$CLASS)) #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), #<<\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nInteractivity: By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\nCustomising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css <- \"background-color:white; #<<\nfont-style:bold; color:black;\" #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #<<\n    opts_tooltip(    #<<\n      css = tooltip_css)) #<<\n)                                        \n\n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\nDisplaying statistics on tooltip\n\ntooltip <- function(y, ymax, accuracy = .01) {   #<<\n  mean <- scales::number(y, accuracy = accuracy) #<<\n  sem <- scales::number(ymax - y, accuracy = accuracy) #<<\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem) #<<\n} #<<\n\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  #<<\n                     tooltip(y, ymax))),  #<<\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #<<\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nCode chunk on the left shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\n\nHover effect with data_id aesthetic\nCode chunk below show the second interactive feature of ggiraph, namely data_id.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             #<<\n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\nStyling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        #<<\n    opts_hover(css = \"fill: #202020;\"),  #<<\n    opts_hover_inv(css = \"opacity:0.2;\") #<<\n  )                                      #<<  \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote: Different from Slide 9, in this example the ccs customisation request are encoded directly.\n\n\nCombining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, #<<\n        data_id = CLASS),#<<              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\nClick effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on ther web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              #<<\n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\nCoordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation on the right.\n\nwhen a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\n\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n\np2 <- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2), #<<\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 02",
    "section": "Interactive Data Visualisation - plotly methods!",
    "text": "Interactive Data Visualisation - plotly methods!\n\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics.\nDifferent from other plotly platform, plot.R is free and open source.\n\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\nCreating an interactive scatter plot: plot_ly() method\nThe code chunk below plots an interactive scatter plot by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nWorking with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE) #<<\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nChanging colour pallete: plot_ly() method\nIn the code chunk below, colors argument is used to change the default colour palette to ColorBrewel colour palette.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = \"Set1\") #<<\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nCustomising colour scheme: plot_ly() method\nIn the code chunk below, a customised colour scheme is created. Then, colors argument is used to change the default colour palette to the customised colour scheme.\n\npal <- c(\"red\", \"purple\", \"blue\", \"green\") #<<\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = pal) #<<\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nCustomising tooltip: plot_ly() method\nIn the code chunk below, text argument is used to change the default tooltip.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID,     #<<\n                      \"<br>Class:\", CLASS),  #<<\n        color = ~RACE, \n        colors = \"Set1\")\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nWorking with layout: plot_ly() method\nIn the code chunk below, layout argument is used to change the default tooltip.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID,     \n                      \"<br>Class:\", CLASS),  \n        color = ~RACE, \n        colors = \"Set1\") %>%\n  layout(title = 'English Score versus Maths Score ', #<<\n         xaxis = list(range = c(0, 100)),             #<<\n         yaxis = list(range = c(0, 100)))             #<<\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\nTo learn more about layout, visit this link.\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nWarning in geom_point(dotsize = 1): Ignoring unknown parameters: `dotsize`\n\nggplotly(p) #<<\n\n\n\n\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\nCoordinated Multiple Views with plotly\nCode chunk below plots two scatterplots and places them next to each other side-by-side by using subplot() of plotly package.\n\np1 <- ggplot(data=exam_data, \n              aes(x = MATHS,\n                  y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nsubplot(ggplotly(p1), \n        ggplotly(p2))\n\n\n\n\n\n\nd <- highlight_key(exam_data)  #<<\np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 02",
    "section": "Interactive Data Visualisation - crosstalk methods!",
    "text": "Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nInteractive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\nd <- highlight_key(exam_data) \np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nSetting the `off` event (i.e., 'plotly_deselect') to match the `on` event (i.e., 'plotly_selected'). You can change this default via the `highlight()` function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 02",
    "section": "Animated Data Visualisation: gganimate methods",
    "text": "Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nGetting started\nAdd the following packages in the packages list:\n\ngganimate: An ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\n\n\n\nImporting the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol <- c(\"Country\", \"Continent\")\nglobalPop <- readxl::read_xls(\"data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %>%\n  mutate_each_(funs(factor(.)), col) %>%\n  mutate(Year = as.integer(Year))\n\nWarning: `mutate_each_()` was deprecated in dplyr 0.7.0.\nℹ Please use `across()` instead.\n\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nBuilding a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\nBuilding the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       #<<\n  ease_aes('linear')            #<<"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#visualizing-large-data-interactively",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#visualizing-large-data-interactively",
    "title": "Hands-on Exercise 02",
    "section": "Visualizing Large Data Interactively",
    "text": "Visualizing Large Data Interactively\nIn this hands-on exercise you will learn how to visualise large data by using packed bar methods. For the purpose of this hands-on exercise, two data sets will be used. They are:\n\nGDP.csv provides GDP, GDP per capita and GDP PPP data for world countries from 2000 to 2020. The data was extracted from World Development Indicators Database of World Bank.\nWorldCountry.csv provides a list of country names and the continent they belong to extracted from Statistics Times.\nWrite a code chunk to import both data sets by using read_csv() of readr package.\n\nThe solution:\n\nGDP <- read_csv(\"data/GDP.csv\")\n\nRows: 648 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (25): Country Name, Country Code, Series Name, Series Code, 2000, 2001, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nWorldCountry <- read_csv(\"data/WorldCountry.csv\")\n\nRows: 250 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Country or Area, ISO-alpha3 Code, Region 1, Region 2, Continent\ndbl (2): No, M49 Code\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nData preparetion\nBefore programming the data visualisation, it is important for us to reshape, wrangle and transform the raw data to meet the data visualisation need.\nCode chunk below performs following tasks:\n\nmutate() of dplyr package is used to convert all values in the 202 field into numeric data type.\nselect() of dplyr package is used to extract column 1 to 3 and Values field.\npivot_wider() of tidyr package is used to split the values in Series Name field into columns.\nleft_join() of dplyr package is used to perform a left-join by using Country Code of GDP_selected and ISO-alpha3 Code of WorldCountry tibble data tables as unique identifier.\n\n\nGDP_selected <- GDP %>%\n  mutate(Values = as.numeric(`2020`)) %>%\n  select(1:3, Values) %>%\n  pivot_wider(names_from = `Series Name`,\n              values_from = `Values`) %>%\n  left_join(y=WorldCountry, by = c(\"Country Code\" = \"ISO-alpha3 Code\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Values = as.numeric(`2020`)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n\nIntroducing packed bar method\n\npacked bar is a relatively new data visualisation method introduced by Xan Gregg from JMP.\n\nIt aims to support the need of visualising skewed data over hundreds of categories.\n\nThe idea is to support the Focus+Context data visualization principle.\nVisit this JMP Blog to learn more about the design principles of packed bar.\n\n\n\nData Preparation\nAs usual, we need to prepare the data before building the packed bar. Prepare the data by using the code chunk below.\n\nGDP_selected <- GDP %>%\n  mutate(GDP = as.numeric(`2020`)) %>%\n  filter(`Series Name` == \"GDP (current US$)\") %>%\n  select(1:2, GDP) %>%\n  na.omit()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `GDP = as.numeric(`2020`)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n\nThing to learn from the code chunk above\n\nna.omit() is used to exclude rows with missing values. This is because rPackedBar package does not support missing values.\n\n\n\n\nBuilding a packed bar by using rPackedBar package.\nIn the code chunk below, plotly_packed_bar() of rPackedBar package is used to create an interactive packed bar.\n\np = plotly_packed_bar(\n  input_data = GDP_selected,\n  label_column = \"Country Name\",\n  value_column = \"GDP\",\n  number_rows = 10,\n  plot_title = \"Top 10 countries by GDP, 2020\",\n  xaxis_label = \"GDP (US$)\",\n  hover_label = \"GDP\",\n  min_label_width = 0.018,\n  color_bar_color = \"#00aced\",\n  label_color = \"white\")\nplotly::config(p, displayModeBar = FALSE)\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#reference",
    "title": "Hands-on Exercise 02",
    "section": "Reference",
    "text": "Reference\n\nggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\n\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\nplotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels\n\n\n\nPacked Bar\nrPackedBar: Packed Bar Charts with ‘plotly’\n\nVisualizing Twitter Data with a Packed Barchart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 01",
    "section": "",
    "text": "tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\n\n\n\n\ndplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges.\ntidyr helps R users to create tidy data.\nstringr provides a cohesive set of functions designed to make working with strings as easy as possible.\nforcats provides a suite of tools that solve common problems with factors, including changing the order of levels or the values.\n\n\n\nreadr provides a fast and friendly way to read rectangular data (like csv, tsv, and fwf).\ntibble is a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not.\nggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics.\npurrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors.\n\n\n\n\n\nReference: Introduction to the Tidyverse: How to be a tidy data scientist.\n\n\n\n\n\nBefore we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\n\npacman::p_load(tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk on the right assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 01",
    "section": "Introducing ggplot",
    "text": "Introducing ggplot\n\nAn R package for declaratively creating data-driven graphics based on The Grammar of Graphics\nIt is part of the tidyverse family specially designed for visual exploration and communication.\nFor more detail, visit ggplot2 link.\n\n\n\nR Graphics VS ggplot\n\nR Graphics\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\nggplot2\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\nThen, why ggplot2\n\n\n\n\n\n\nNote\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive.\nHadley Wickham\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\nGrammar of Graphics\n\nWilkinson, L. (1999) Grammar of Graphics, Springer.\nThe grammar of graphics is an answer to a question:\n\n\nWhat is a statistical graphic?\n\nGrammar of graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nTwo principles\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\n\n\n\nA good grammar will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978).\nA grammar provides a strong foundation for understanding a diverse range of graphics.\nA grammar may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\n\n\nEssential Grammatical Elements in ggplot2\nA Layered Grammar of Graphics\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\n\nThe ggplot() function and data argument\n\nLet us call the ggplot() function using the code chunk on the right.\nNotice that a blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify().\n\n\nggplot(data=exam_data)\n\n\n\n\n\n\nThe Aesthetic mappings\n\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency.\nEach visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\n\n\n\nWorking with aes()\n\nThe code chunk on the right add the aesthetic element into the plot.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\nNotice that ggplot includes the x-axis and the axis’s label.\n\n\n\nGeometric Objects: geom\n\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n\nGeometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\nGeometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\n\n\n\n\n\n\nWarning\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\nGeometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\nModifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\nModifying a geometric object by changing aes()\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\nGeometric Objects: geom-density\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\nReference: Kernel density estimation\nThe code chunk below plots two kernel density lines by using color or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\nGeometric Objects: geom_boxplot\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().]\n\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\nReference: Notched Box Plots.\n\n\ngeom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +              #<<      \n  geom_point(position=\"jitter\", #<<\n             size = 0.5)        #<<\n\n\n\n\n\n\nGeometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\nGeometric Objects: geom_violin() and geom_boxplot()\nThe code chunk below combined a violin plot and a boxplot to show the distribution of Maths scores by gender.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin(fill=\"light blue\") +\n  geom_boxplot(alpha=0.5)           \n\n\n\n\n\n\nGeometric Objects: geom_point()\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\nStatistics, stat\n\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n\nWorking with stat\n\nThe boxplots on the right are incomplete because the positions of the means were not shown.\nNext two slides will show you how to add the mean values on the boxplots.\n\n\n\n\nWorking with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\nWorking with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\nHow to add a best fit curve on a scatterplot?\n\nThe scatterplot on the right shows the relationship of Maths and English grades of pupils.\nThe interpretability of this graph can be improved by adding a best fit curve.\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nThe default method used is loess.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nFacets\n\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data.\nFacets are an alternative to aesthetics for displaying additional discrete variables.\nggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\n\nfacet_wrap()\n\nfacet_wrap wraps a 1d sequence of panels into 2d.\nThis is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\n\n\n\nWorking with facet_wrap()\nThe code chunk below plots a trellis plot using facet-wrap().\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\nfacet_grid() function\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables.\nIt is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\n\n\n\nWorking with facet_grid()\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)\n\n\n\n\n\n\nWorking with facet\n\n\n\n\n\n\nNote\n\n\n\nPlot a trellis boxplot looks similar to the figure below.\n\n\n\nThe solution:\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= CLASS)) +\n  geom_boxplot() +\n  facet_grid(~ GENDER)\n\n\n\n\n\n\n\nWorking with facet\n\n\n\n\n\n\nNote\n\n\n\nPlot a trellis boxplot looks similar to the figure below.\n\n\n\nThe solution:\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= CLASS)) +\n  geom_boxplot() +\n  facet_grid(GENDER ~.)\n\n\n\n\n\n\n\nWorking with facet\n\n\n\n\n\n\nNote\n\n\n\nPlot a trellis boxplot looks similar to the figure below.\n\n\n\nThe solution:\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n    facet_grid(GENDER ~ CLASS)\n\n\n\n\n\n\n\nCoordinates\n\nThe Coordinates functions map the position of objects onto the plane of the plot.\nThere are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian(): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps.\n\n\n\n\nWorking with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\nHow to change to the y- and x-axis range?\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nThemes\n\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include:\n\ntheme_gray() (default)\ntheme_bw()\ntheme_classic()\n\nA list of theme can be found at this link.\nEach theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n\n\nWorking with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nPlot a horizontal bar chart looks similar to the figure below.\n\nChanging the colors of plot panel background of theme_minimal() to light blue and the color of grid lines to white.\n\n\n\n\nThe solution\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal() +\n  theme(panel.background = element_rect(\n    fill = \"lightblue\",\n    colour = \"lightblue\",\n    size = 0.5,\n    linetype = \"solid\"),\n    panel.grid.major = element_line(\n      size = 0.5,\n      linetype = 'solid',\n      colour = \"white\"), \n    panel.grid.minor = element_line(\n      size = 0.25,\n      linetype = 'solid',\n      colour = \"white\"))\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\n\nDesigning Data-drive Graphics for Analysis I\n\nThe original design\nA simple vertical bar chart for frequency analysis. Critics:\n\ny-aixs label is not clear (i.e. count)\nTo support effective comparison, the bars should be sorted by their resepctive frequencies.\nFor static graph, frequency values should be added to provide addition information.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWith reference to the critics on the earlier slide, create a makeover looks similar to the figure on the right.\n\n\n\nggplot(data=exam_data,\n       aes(x=reorder(RACE,RACE,\n                function(x)-length(x))))+\n  geom_bar() +\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\nThe makeover design\nThis code chunk uses fct_infreq() of forcats package.\n\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))\n\n\n\n\nCredit: I learned this trick from Getting things into the right order of Prof. Claus O. Wilke, the author of Fundamentals of Data Visualization\n\n\n\nDesigning Data-drive Graphics for Analysis II\n\nThe original design\n\n\n\n\n\n\n\nNote\n\n\n\n\nAdding mean and median lines on the histogram plot.\nChange fill color and line color\n\n\n\nThe code chunk:\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(MATHS,\n                                 na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=1) +\n  geom_vline(aes(xintercept=median(MATHS,\n                                  na.rm=T)),\n             color=\"grey30\",\n             linetype=\"dashed\", \n             size=1)\n\n\n\n\n\n\n\nDesigning Data-drive Graphics for Analysis III\n\nThe original design\nThe histograms on the left are elegantly designed but not informative. This is because they only reveal the distribution of English scores by gender but without context such as all pupils.\n\n\n\n\n\n\n\nImportant\n\n\n\nCreate a makeover looks similar to the figure below. The background histograms show the distribution of English scores for all pupils.\n\n\n\nThe code chunk\n\nd <- exam_data   \nd_bg <- d[, -3]  \n\nggplot(d, aes(x = ENGLISH, fill = GENDER)) +\n  geom_histogram(data = d_bg, fill = \"grey\", alpha = .5) +\n  geom_histogram(colour = \"black\") +\n  facet_wrap(~ GENDER) +\n  guides(fill = FALSE) +  \n  theme_bw()\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nDesigning Data-drive Graphics for Analysis IV\n\nThe original design.\n\n\n\n\n\n\n\nImportant\n\n\n\nCreate a makeover looks similar to the figure on the right.\n\n\nA within group scatterplot with reference lines.\n\nggplot(data=exam_data, \n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  geom_hline(yintercept=50,\n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1) + \n  geom_vline(xintercept=50, \n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 01",
    "section": "Reference",
    "text": "Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10.html",
    "title": "Hands-on Exercise 10",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\nextract stock price data from financial portal such as Yahoo Finance by using tidyquant package\nplot horizon graph by using ggHoriPlot package,\nplot static and interactive stock prices line graph(s) by ggplot2 and plotly R packages,\nplot static candlestick chart by using tidyquant package,\nplot static bollinger bands by using tidyquant, and\nplot interactive candlestick chart by using ggplot2 and plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#getting-started",
    "title": "Hands-on Exercise 10",
    "section": "Getting started",
    "text": "Getting started\nFor the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(lubridate, tidyquant, ggHoriPlot,\n               timetk, ggthemes, plotly, tidyverse)\n\n\ntidyverse provides a collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data. It is not a single package but a collection of modern R packages including but not limited to readr, tidyr, dplyr, ggplot, tibble, stringr, forcats and purrr.\nlubridate provides functions to work with dates and times more efficiently.\ntidyquant bringing business and financial analysis to the ‘tidyverse’. It provides a convenient wrapper to various ‘xts’, ‘zoo’, ‘quantmod’, ‘TTR’ and ‘PerformanceAnalytics’ package functions and returns the objects in the tidy ‘tibble’ format.\nggHoriPlot: A user-friendly, highly customisable R package for building horizon plots in the ‘ggplot2’ environment."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#data-extraction-with-tidyquant",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#data-extraction-with-tidyquant",
    "title": "Hands-on Exercise 10",
    "section": "Data Extraction with tidyquant",
    "text": "Data Extraction with tidyquant\ntidyquant integrates resources for collecting and analysing financial data with the tidy data infrastructure of the tidyverse, allowing for seamless interaction between each.\nIn this section, you will learn how to extract the daily stock values of a selected stocks from Yahoo Finance by using tidyquant.\nStep 1: We will import a pre-prepared company list called companySG.csv onto R. The list consists of top 45 companies by market capitalisation in Singapore. However, we just want the top 40.\n\ncompany <- read_csv(\"data/companySG.csv\")\n\nNew names:\nRows: 46 Columns: 7\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): Name, symbol, country dbl (4): ...1, Rank, marketcap, price..USD.\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n\nTop40 <- company %>% \n  slice_max(`marketcap`, n=40) %>% \n  select(symbol)\n\nStep 2: tq_get() method will be used to extract daily values of these stocks from Yahoo Finance via APIs. The time period for the data was set from 1st January 2020 to 31st March 2021. The data are specified to be returned in daily intervals.\n\nStock40_daily <- Top40 %>%\n  tq_get(get = \"stock.prices\", \n         from = \"2020-01-01\", \n         to = \"2022-03-31\") %>%\n  group_by(symbol) %>%\n  tq_transmute(select = NULL, \n               mutate_fun = to.period, \n               period  = \"days\")\n\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `data.. = purrr::map(...)`.\nCaused by warning:\n! x = 'RW0U.SI', get = 'stock.prices': Error in getSymbols.yahoo(Symbols = \"RW0U.SI\", env = <environment>, verbose = FALSE, : Unable to import \"RW0U.SI\".\nRW0U.SI download failed after two attempts. Error message:\nHTTP error 404.\n Removing RW0U.SI."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#plotting-a-horizon-graph",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#plotting-a-horizon-graph",
    "title": "Hands-on Exercise 10",
    "section": "Plotting a horizon graph",
    "text": "Plotting a horizon graph\nIn this section, you will learn how to plot a horizon graph by using geom_horizon() of ggHoriPlot package.\n\nStock40_daily %>% \n  ggplot() +\n  geom_horizon(aes(x = date, y=adjusted), origin = \"midpoint\", horizonscale = 6)+\n  facet_grid(symbol~.)+\n  theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand=c(0,0), date_breaks = \"1 month\", date_labels = \"%b%y\") +\n  ggtitle('Daily Adjusted Prices (Jan 2020 to Mar 2022)') \n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\nHorizon graph makeover\n\nInstead of showing stock code, the stock name will be displayed.\nAdding reference lines\n\nStep 1: left_join() of dplyr package is used to append fields from company data.frame onto Stock_daily data.frame. Next select() is used to select columns 1 to 8 and 11 to 12.\n\nStock40_daily <- Stock40_daily %>%\n  left_join(company) %>%\n  select(1:8, 11:12)\n\nJoining with `by = join_by(symbol)`\n\n\nStep 2: geom_vline() is used to add the vertical reference lines.\n\nStock40_daily %>% \n  ggplot() +\n  geom_horizon(aes(x = date, y=adjusted), origin = \"midpoint\", horizonscale = 6)+\n  facet_grid(Name~.)+ #<<\n  geom_vline(xintercept = as.Date(\"2020-03-11\"), colour = \"grey15\", linetype = \"dashed\", size = 0.5)+ #<<\n  geom_vline(xintercept = as.Date(\"2020-12-14\"), colour = \"grey15\", linetype = \"dashed\", size = 0.5)+ #<<\n  theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"),\n        strip.text.y = element_text(size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand=c(0,0), date_breaks = \"1 month\", date_labels = \"%b%y\") +\n  ggtitle('Daily Adjusted Prices (Jan 2020 to Mar 2022)') \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#plotting-stock-price-line-graph-ggplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#plotting-stock-price-line-graph-ggplot-methods",
    "title": "Hands-on Exercise 10",
    "section": "Plotting Stock Price Line Graph: ggplot methods",
    "text": "Plotting Stock Price Line Graph: ggplot methods\nIn the code chunk below, geom_line() of ggplot2 is used to plot the stock prices.\n\nStock40_daily %>%\n  filter(symbol == \"DBSDF\") %>%\n  ggplot(aes(x = date, y = close)) +\n    geom_line() +\n    labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\", \n         y = \"Closing Price\", x = \"\") + \n    theme_tq()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#plotting-interactive-stock-price-line-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#plotting-interactive-stock-price-line-graphs",
    "title": "Hands-on Exercise 10",
    "section": "Plotting interactive stock price line graphs",
    "text": "Plotting interactive stock price line graphs\nIn this section, we will create interactive line graphs for four selected stocks.\nStep 1: Selecting the four stocks of interest\n\nselected_stocks <-  Stock40_daily %>%\n  filter (`symbol` == c(\"C09.SI\", \"SINGF\", \"SNGNF\", \"C52.SI\"))\n\nWarning: There were 38 warnings in `filter()`.\nThe first warning was:\nℹ In argument: `symbol == c(\"C09.SI\", \"SINGF\", \"SNGNF\", \"C52.SI\")`.\nℹ In group 1: `symbol = \"2588.HK\"`.\nCaused by warning in `symbol == c(\"C09.SI\", \"SINGF\", \"SNGNF\", \"C52.SI\")`:\n! longer object length is not a multiple of shorter object length\nℹ Run `dplyr::last_dplyr_warnings()` to see the 37 remaining warnings.\n\n\nStep 2: Plotting the line graphs by using ggplot2 functions and ggplotly() of plotly R package\n\np <- ggplot(selected_stocks, \n            aes(x = date, y = adjusted)) + \n  scale_y_continuous() +\n  geom_line() +\n  facet_wrap(~Name, scales = \"free_y\",) +\n  theme_tq() +\n  labs(title = \"Daily stock prices of selected weak stocks\", \n       x = \"\", y = \"Adjusted Price\") + \n  theme(axis.text.x = element_text(size = 6), \n        axis.text.y = element_text(size = 6))\n\nggplotly(p)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#plotting-candlestick-chart-tidyquant-method",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#plotting-candlestick-chart-tidyquant-method",
    "title": "Hands-on Exercise 10",
    "section": "Plotting Candlestick Chart: tidyquant method",
    "text": "Plotting Candlestick Chart: tidyquant method\nIn this section, you will learn how to plot candlestick chart by using geom_candlestick() of tidyquant package.\nBefore plotting the candlesticks, the code chunk below will be used to define the end data parameter. It will be used when setting date limits throughout the examples.\n\nend <- as_date(\"2022-03-31\")\n\nNow we are ready to plot the candlesticks by using the code chunk below.\n\nStock40_daily %>%\n  filter(symbol == \"DBSDF\") %>%\n  ggplot(aes(\n    x = date, y = close)) +\n  geom_candlestick(aes(\n    open = open, high = high, \n    low = low, close = close)) +\n  geom_line(size = 0.5)+\n    coord_x_date(xlim = c(end - weeks(12), \n                          end),\n                 ylim = c(20, 35),\n                 expand = TRUE) +\n  labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\", \n       y = \"Closing Price\", x = \"\") + \n  theme_tq()\n\nWarning: The following aesthetics were dropped during statistical transformation: open,\nhigh, low, close, y\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\nWarning: The following aesthetics were dropped during statistical transformation: x,\nopen, high, low, close, y\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\nPlotting candlestick chart and MA lines: tidyquant method\n\nStock40_daily %>%\n  filter(symbol == \"DBSDF\") %>%\n  ggplot(aes(\n    x = date, y = close)) +\n  geom_candlestick(aes(\n    open = open, high = high, \n    low = low, close = close)) +\n  geom_line(size = 0.5)+\n  geom_ma(color = \"darkgreen\", n = 20) +\n  geom_ma(color = \"lightgreen\", n = 5) + \n    coord_x_date(xlim = c(end - weeks(12), \n                          end),\n                 ylim = c(20, 35),\n                 expand = TRUE) +\n  labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\",\n       subtitle = \"darkgreen = 1-day MA, lightgreen = 5-day MA\",\n       y = \"Closing Price\", x = \"\") + \n  theme_tq()\n\nWarning: The following aesthetics were dropped during statistical transformation: open,\nhigh, low, close, y\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\nWarning: The following aesthetics were dropped during statistical transformation: x,\nopen, high, low, close, y\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nThings to learn from the code chunk:\n\ngeom_MA is used to add the moving average line. It is a wrapper function of SMA() from the TTR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#plotting-bollinger-bands-tidyquant-method",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#plotting-bollinger-bands-tidyquant-method",
    "title": "Hands-on Exercise 10",
    "section": "Plotting Bollinger Bands: tidyquant method",
    "text": "Plotting Bollinger Bands: tidyquant method\nIn this section, you will learn how to plot bollinger bands by using geom_bbands() of tidyquant package.\n\nStock40_daily %>%\n  filter(symbol == \"DBSDF\") %>% \n  ggplot(aes(x=date, y=close))+\n  geom_line(size=0.5)+\n  geom_bbands(aes(\n    high = high, low = low, close = close), \n    ma_fun = SMA, sd = 2, n = 20,\n    size = 0.75, color_ma = \"royalblue4\", \n    color_bands = \"red1\")+\n    coord_x_date(xlim = c(\"2020-02-01\", \n                          \"2022-03-31\"), \n                 expand = TRUE)+\n    labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\",\n         subtitle = \"dotted red lines = bollinger bands\",\n         x = \"Date\", y =\"Price\") +\ntheme(legend.position=\"none\")\n\nWarning: The following aesthetics were dropped during statistical transformation: high,\nlow, close, y\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\nWarning: The following aesthetics were dropped during statistical transformation: high,\nlow, close\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\nThings you can learn from the code chunk:\n\ngeom_bbands() plots a range around a moving average typically two standard deviations up and down. The moving average functions used are specified in SMA() from the TTR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#plotting-interactive-candlesticks-chart-ggplot2-and-plotly-r-method",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#plotting-interactive-candlesticks-chart-ggplot2-and-plotly-r-method",
    "title": "Hands-on Exercise 10",
    "section": "Plotting Interactive Candlesticks Chart: ggplot2 and plotly R method",
    "text": "Plotting Interactive Candlesticks Chart: ggplot2 and plotly R method\nFirst, a candleStick_plot function is written as follows:\n\ncandleStick_plot<-function(symbol, from, to){\n  tq_get(symbol, from = from, to = to, warnings = FALSE) %>% \n    mutate(greenRed=ifelse(open-close>0, \"Red\", \"Green\")) %>% \n    ggplot()+\n    geom_segment(\n      aes(x = date, xend=date, y =open, yend =close, colour=greenRed), \n      size=3)+\n    theme_tq()+\n    geom_segment(\n      aes(x = date, xend=date, y =high, yend =low, colour=greenRed))+\n    scale_color_manual(values=c(\"ForestGreen\",\"Red\"))+\n    ggtitle(paste0(symbol,\" (\",from,\" - \",to,\")\"))+\n    theme(legend.position =\"none\",\n          axis.title.y = element_blank(),\n          axis.title.x=element_blank(),\n          axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1),\n          plot.title= element_text(hjust=0.5))\n}\n\nCredit: I learned this trick from RObservations #12: Making a Candlestick plot with the ggplot2 and tidyquant packages\n\np <- candleStick_plot(\"DBSDF\",\n                      from = '2022-01-01',\n                      to = today())\nggplotly(p)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 06",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 06",
    "section": "Getting Started",
    "text": "Getting Started\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 06",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmetically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\nRows: 199999 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): source_country, tz\ndttm (1): timestamp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\n\ntz field stores time zone of the source IP address.\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nNote: ymd_hms() and hour() are from lubridate package and weekdays() is a base R function.\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nNote: Beside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nThings to learn from the code chunk: - a tibble data table called grouped is derived by aggregating the attack by wkday and hour fields. - a new field called n is derived by using group_by() and count() functions. - na.omit() is used to exclude missing value. - geom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles. - theme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot. - coord_equal() is used to ensure the plot will have an aspect ratio of 1:1. - scale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme( axis.ticks = element_blank(),\n       plot.title = element_text(hjust = 0.5),\n       legend.title = element_text(size = 8),\n       legend.text = element_text(size = 6) )\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#cycle-plot",
    "title": "Hands-on Exercise 06",
    "section": "Cycle Plot",
    "text": "Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nData Preparation\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nPlotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 - Visual Analytics and Applications",
    "section": "",
    "text": "Hello there,\nThis is my Quarto/Netify Page, documenting my academic studies in the course ISSS608 - Visual Analytics and Applications.\nThis is a work in progress, keep track of the updates."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01.html",
    "title": "Data Visualization Makeover 01",
    "section": "",
    "text": "The objective is to create Age-Sex Pyramid Analytic Visualization to accurately describe the demographic of Singapore. It is a common visual representation to contrast and sub sect the population based on different classifiers, commonly by gender and age. To further illustrate the visualization, multiple Age-Sex Pyramids will be plotted by planning area using the trellis display. \nThe visualization is created using the Singapore Residents by Planning Area / Sub-zone, Age Group, Sex and Type of Dwelling, June 2022 (Singstat)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#data-cleaning-and-preparation",
    "href": "Take-home_Ex/Take-home_Ex01.html#data-cleaning-and-preparation",
    "title": "Data Visualization Makeover 01",
    "section": "Data Cleaning and Preparation",
    "text": "Data Cleaning and Preparation\nTo ensure that the data is properly loaded and read, the following actions will be done in the raw excel file and tableau. \n\n\n\n\n\n\n\nACTION\nIMAGE\n\n\nFrom the raw excel file, remove the unnecessary rows as not to confuse the tableau reading\n\n\n\nLink the three sheets with the following identifiers:\n\nPlanning Area\nSubzone\nAge Group\nType of Dwelling\n\nRename 2022 as population (either total, male, female)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#original-visualization",
    "href": "Take-home_Ex/Take-home_Ex01.html#original-visualization",
    "title": "Data Visualization Makeover 01",
    "section": "Original Visualization",
    "text": "Original Visualization\nTrellis Display is a visualization framework aimed at easily presenting visual data in tables and box subdivided by category. The aim is to be able to compare and contrast the data based on the category in one window. \n\n\n\n\n\nThough the original visualization is a trellis display, there are some issues on the clarity, aesthetics, and interactive design of the original data visualization to be explained at the next section."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#visualization-critique",
    "href": "Take-home_Ex/Take-home_Ex01.html#visualization-critique",
    "title": "Data Visualization Makeover 01",
    "section": "Visualization Critique",
    "text": "Visualization Critique\nThe issues of the original visualization are as follows: \n\nClarity\n\na. Lack of Header and Titles\nThere is no title to explain the context of the visual. Users would not know the message of the visual at first glance. While an age sex pyramid is a common visual tool to indicate a split in gender population, it is not clear which population is being discussed unless the user is aware of the Planning Areas. Furthermore, though indicated as 2022 at the x-axis, it would have been clearer if it is included in the header or title. A simple title such as 2022 Singapore Age – Sex Pyramid would be enough to communicate the topic of the visual.\n\n\nb. Lack of Color Labels\nThe color of the back-to-back horizontal bar chart is the same between male and female values. This may confuse users as it may give the wrong impression that both bars may belong to a single elongated bar. It is proposed that color for both male and female to be separate and distinct, even if in the terms of different shade. \n\n\n\nAesthetic\n\nc. Poor Layout\nThe Trellis chart is organized horizontally and side by side and as such is visually difficult to read as there is an estimated 55 Planning Areas to scroll from. This difficult extends also to comparing multiple charts as there is only so much that can be shown per plane. It is recommended to create a table like trellis chart with rows and columns as to ease visualization and maximize space. \n\n\nd. Lack of differentiating color per Area\nSimilar to the back to back horizontal bar, the color between planning areas are also the same. To improve aesthetic, it is recommended that Planning Areas will have the same color while male to female bars with share the same color but of different shades.\n\n\ne. Too many Age Groups\nThe is an overall 19 age gaps that extends the chart and limits the number of planes that can be shown per window. It is recommended to group together the different age groups from 5 years to 10 years thus reducing the y axis by half and increase the number of charts that can be seen in one viewing. \n\n\n\nInteractive\nThere is an opportunity to create filters to limit and focus the dashboard to a select Area, Subzone and Dwelling Type. This opportunity can allow for a more interactive and dynamic analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#proposed-design-of-trellis-chart",
    "href": "Take-home_Ex/Take-home_Ex01.html#proposed-design-of-trellis-chart",
    "title": "Data Visualization Makeover 01",
    "section": "Proposed Design of Trellis Chart",
    "text": "Proposed Design of Trellis Chart\n\n\n\n\n\n\nClarity\n\na. Proper Titles and Headers\nThe Age-Sex Pyramid Trellis Chart is titled correctly, indicating as 2022 Singapore Age-Sex Pyramid per Area. Furthermore, each Age-Sex Pyramid is labeled per Planning Area at the bottom right-hand corner of each plane. These labels ensure that users can properly read and identify the overall message of the chart and category of each individual pyramid. \nIt may be recommended to add value labels per bar to textually visualize the amount each chart, yet this step can be avoid as the chart allows for pop out labels and values to appear when hovering over the chart. Furthermore, on the design aspect, value labels will clutter the chart and cause it to be overly noisy. \n\n\nb. Differentiated Color Labels\nMale-Female bar colors are identified with different shades with the lighter colors indicating male and darker as female. This ensures visual differentiation between genders with ensuring some similarity within planning area.\n\n\n\nAesthetic\n\nc. 3 Column Tabular Trellis Chart\nThe Trellis Chart is organized to 3 columns to ensure that the pyramids are visually maximized both in terms of the number of pyramid charts in one viewing and the max value of the y-axis for the bars to be visually district.\n\n\nd. Differentiating Color per Area\nColors per Planning Area is colored differently to ensure distinct differentiation per pyramid. \n\n\ne. Simplified Age Groups\n19 age groups are reduced to 10 age groups to visually maximize the space of the plane without oversimplifying the data points. \n\n\n\nInteractive\nThe Trellis Chart can be filtered per Planning Area, Subzone and Type of Dwelling. This ensures interactive use of the chart and allow for more drilled down analysis of the data. Though there is a limitation as this chart cannot compare Subzones within the same Planning Area as can be an improvement for future developments."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#process-and-development",
    "href": "Take-home_Ex/Take-home_Ex01.html#process-and-development",
    "title": "Data Visualization Makeover 01",
    "section": "Process and Development",
    "text": "Process and Development\n\n\n\n\n\n\n\nACTION\nIMAGE\n\n\n\n\nTo create the Trellis Chart, the table must be created first determining the number of columns, indicated in the parameter - # of Col\n\n\n\nNext is to define the rows and columns field with the following formula:\n\nIndex – Index ()\nColumn – [Index]%[# of Col]\nRows – int(([Index]-1)/[# of Col])\n\nThen place the calculated values at the column and row fields\n\n\n\nTo ensure that the values are not inflated due to the addition of the Total category, recreate the set of the following dimensions by excluding the Total and HDB Total (for Type of Dwelling)\n\nPlanning Area\nSubzone\nType of Dwelling\n\n\n\n\nBuild the Trellis Chart with multiple Age-Sex Pyramid with the correct filters\n*remember to set the colors base on the gender and planning area\n\n\n\nCreate a 0 mark parameter to as a line with Planning Area as the label. Set the 0 mark as a dual axis and make the line transparent to set the Planning Area label"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#dashboard-overview",
    "href": "Take-home_Ex/Take-home_Ex01.html#dashboard-overview",
    "title": "Data Visualization Makeover 01",
    "section": "Dashboard Overview",
    "text": "Dashboard Overview\nBesides the Trellis Chart, additional charts are created as well to build a better interactive dashboard. Page 1 of the dashboard is to give an overview of Singapore 2022 population while Page 2 presents the Trellis Chart and Age-Sex Pyramids per Planning Area. \n\n\n\nPage 1\nPage 2\n\n\n\n\n\n\n\n\n\n\nMajor Findings\n\nOverall, Singapore has more females than males by est. 500,000 heavily contributed by the adult (25 and above) age group. Male population is 11 million while Female is 11.5 million. This is a stark contrast from previous years as there are more males in Singapore than females, average ratio at 53% male and 47% female. The shift in population shares maybe due to migration and the impact of COVID lockdown as male manpower migrating to the city state decreased during COVID and has not recovered since. \nMale and Female distribution per Planning Area and age group are almost equal except for the senior population. The close distribution maybe due to the equal economic opportunity for both genders in Singapore. Furthermore, top areas that are heavily populated by males are populated by females as well. \nThe data may be incomplete as 26 out of 55 (48%) of Total Planning Area have either no data or negligible data. This is evident that some area’s population data is missing and is not only limited to far east and far west areas such as Tuas, but high population city center such as Orchard has no data recorded as well. \n\nDashboard Link: https://public.tableau.com/views/DataVizMakeover01_16743910439700/TotalSingapore?:language=en-US&publish=yes&:display_count=n&:origin=viz_share_link"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03.html",
    "title": "Data Visualization Makeover 03",
    "section": "",
    "text": "The objective of this exercise is to uncover the salient patterns of the resale prices of public housing property by residential towns and estates in Singapore by using appropriate analytical visualisation techniques and apply appropriate interactive techniques to enhance user and data discovery experiences.\nThe visualization is created using the Resale flat princes based on registration date from Jan-2017 onwards (Data.gov.sg).\n\n\nFor the purpose of this study, the focus should be on 3-ROOM, 4-ROOM and 5-ROOM types. You can choose to focus on either one housing type or multiple housing types. The study period should be on 2022."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html#getting-started---data-loading-and-processing",
    "href": "Take-home_Ex/Take-home_Ex03.html#getting-started---data-loading-and-processing",
    "title": "Data Visualization Makeover 03",
    "section": "Getting Started - Data Loading and Processing",
    "text": "Getting Started - Data Loading and Processing\n\nInstalling and loading the required libraries\nBefore we get started, it is important for us to ensure that the required R packages have been installed.\n\npacman::p_load(tidyverse, ggplot2, knitr, plotly, skimr, questionr, funModeling, sf, tmap, quanteda, NLP, ggiraph, ggstatsplot, dplyr, crosstalk, DT, ggdist, gganimate, ggpubr, corrplot, performance, parameters, see)\n\n\n\nImporting Data\nThis code chunk is to import the data from resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv file to the Quarto/R page.\n\ntotal_flat_data <- read_csv(\"data/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\")\n\nRows: 146429 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nFiltering the Dataset\nThis section deals with limiting the data to the following criteria:\n\nThe year should be 2022\nThe flat_type should be only 3-ROOM, 4-ROOM and 5-ROOM\n\n\n\n\n\n\n\nNote\n\n\n\nThis code uses the dplyr package to filter out the rows with year 2022 and correct flat type\n\n\n\nfilter_flat_data <- filter(total_flat_data, grepl('2022', month) & flat_type %in% c(\"3 ROOM\", \"4 ROOM\",\"5 ROOM\"))\n\nfilter_flat_data\n\n# A tibble: 24,374 × 11\n   month   town    flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n   <chr>   <chr>   <chr>   <chr> <chr>   <chr>     <dbl> <chr>     <dbl> <chr>  \n 1 2022-01 ANG MO… 3 ROOM  320   ANG MO… 07 TO …      73 New Ge…    1977 54 yea…\n 2 2022-01 ANG MO… 3 ROOM  225   ANG MO… 07 TO …      67 New Ge…    1978 55 yea…\n 3 2022-01 ANG MO… 3 ROOM  331   ANG MO… 07 TO …      68 New Ge…    1981 58 yea…\n 4 2022-01 ANG MO… 3 ROOM  534   ANG MO… 07 TO …      82 New Ge…    1980 57 yea…\n 5 2022-01 ANG MO… 3 ROOM  578   ANG MO… 04 TO …      67 New Ge…    1980 57 yea…\n 6 2022-01 ANG MO… 3 ROOM  452   ANG MO… 01 TO …      83 New Ge…    1979 56 yea…\n 7 2022-01 ANG MO… 3 ROOM  560   ANG MO… 01 TO …      67 New Ge…    1980 57 yea…\n 8 2022-01 ANG MO… 3 ROOM  435   ANG MO… 04 TO …      67 New Ge…    1979 56 yea…\n 9 2022-01 ANG MO… 3 ROOM  435   ANG MO… 04 TO …      67 New Ge…    1979 56 yea…\n10 2022-01 ANG MO… 3 ROOM  560   ANG MO… 10 TO …      67 New Ge…    1980 57 yea…\n# … with 24,364 more rows, 1 more variable: resale_price <dbl>, and abbreviated\n#   variable names ¹​flat_type, ²​street_name, ³​storey_range, ⁴​floor_area_sqm,\n#   ⁵​flat_model, ⁶​lease_commence_date, ⁷​remaining_lease\n\n\n\n\nExploring the Data\nThis section of the code aims to ensure that the scope and limitation are followed and the data are listed correctly\n\nskimr::skim(filter_flat_data)\n\n\nData summary\n\n\nName\nfilter_flat_data\n\n\nNumber of rows\n24374\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n8\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmonth\n0\n1\n7\n7\n0\n12\n0\n\n\ntown\n0\n1\n5\n15\n0\n26\n0\n\n\nflat_type\n0\n1\n6\n6\n0\n3\n0\n\n\nblock\n0\n1\n1\n4\n0\n2457\n0\n\n\nstreet_name\n0\n1\n7\n20\n0\n552\n0\n\n\nstorey_range\n0\n1\n8\n8\n0\n17\n0\n\n\nflat_model\n0\n1\n4\n22\n0\n16\n0\n\n\nremaining_lease\n0\n1\n8\n18\n0\n638\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nfloor_area_sqm\n0\n1\n94.07\n19.32\n51\n81\n93\n110\n159\n▅▇▆▃▁\n\n\nlease_commence_date\n0\n1\n1997.46\n14.98\n1967\n1985\n1998\n2014\n2019\n▂▆▅▃▇\n\n\nresale_price\n0\n1\n536391.17\n157993.72\n200000\n428000\n515000\n610000\n1418000\n▅▇▂▁▁\n\n\n\n\n\n\nglimpse(filter_flat_data, 60)\n\nRows: 24,374\nColumns: 11\n$ month               <chr> \"2022-01\", \"2022-01\", \"2022-01…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"A…\n$ flat_type           <chr> \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", …\n$ block               <chr> \"320\", \"225\", \"331\", \"534\", \"5…\n$ street_name         <chr> \"ANG MO KIO AVE 1\", \"ANG MO KI…\n$ storey_range        <chr> \"07 TO 09\", \"07 TO 09\", \"07 TO…\n$ floor_area_sqm      <dbl> 73, 67, 68, 82, 67, 83, 67, 67…\n$ flat_model          <chr> \"New Generation\", \"New Generat…\n$ lease_commence_date <dbl> 1977, 1978, 1981, 1980, 1980, …\n$ remaining_lease     <chr> \"54 years 05 months\", \"55 year…\n$ resale_price        <dbl> 358000, 355000, 338000, 420000…\n\n\n\nunique(filter_flat_data$month)\n\n [1] \"2022-01\" \"2022-02\" \"2022-03\" \"2022-04\" \"2022-05\" \"2022-06\" \"2022-07\"\n [8] \"2022-08\" \"2022-09\" \"2022-10\" \"2022-11\" \"2022-12\"\n\n\n\nunique(filter_flat_data$flat_type)\n\n[1] \"3 ROOM\" \"4 ROOM\" \"5 ROOM\"\n\n\n\nunique(filter_flat_data$storey_range)\n\n [1] \"07 TO 09\" \"04 TO 06\" \"01 TO 03\" \"10 TO 12\" \"13 TO 15\" \"25 TO 27\"\n [7] \"16 TO 18\" \"19 TO 21\" \"22 TO 24\" \"28 TO 30\" \"34 TO 36\" \"31 TO 33\"\n[13] \"37 TO 39\" \"40 TO 42\" \"43 TO 45\" \"49 TO 51\" \"46 TO 48\"\n\n\n\n\n\n\n\n\nCritical!\n\n\n\nstorey_range is listed as a string and needed for the arrangement to be corrected moving forward\n\n\n\nunique(filter_flat_data$floor_area_sqm)\n\n  [1]  73.0  67.0  68.0  82.0  83.0  75.0  74.0  60.0  81.0  92.0  99.0  93.0\n [13]  98.0 100.0  91.0 106.0  90.0  85.0 119.0 120.0 118.0 125.0 110.0 112.0\n [25]  69.0  59.0  70.0  66.0  65.0  88.0  94.0  95.0  87.0 104.0 103.0 107.0\n [37]  84.0 105.0 108.0 123.0 122.0 121.0 139.0 115.0 133.0 113.0 126.0  64.0\n [49] 116.0 114.0 111.0 130.0  77.0 102.0 117.0 101.0  96.0 149.0  62.0  63.0\n [61]  80.0 132.0  89.0 128.0  97.0 138.0  79.0 109.0 124.0 127.0 134.0 131.0\n [73]  57.0  56.0  61.0  52.0  72.0  58.0 129.0 136.0 140.0  53.0  76.0  86.0\n [85]  71.0 137.0 135.0 150.0  60.3  78.0  54.0 142.0  55.0 159.0 141.0 154.0\n [97]  63.1 144.0 155.0 157.0  51.0 152.0 143.0\n\n\n\nunique(filter_flat_data$remaining_lease)\n\n  [1] \"54 years 05 months\" \"55 years 01 month\"  \"58 years\"          \n  [4] \"57 years 02 months\" \"57 years 01 month\"  \"56 years 07 months\"\n  [7] \"56 years 01 month\"  \"56 years 05 months\" \"61 years 09 months\"\n [10] \"57 years\"           \"56 years 06 months\" \"54 years 04 months\"\n [13] \"55 years 10 months\" \"54 years 03 months\" \"54 years 09 months\"\n [16] \"55 years 09 months\" \"56 years\"           \"55 years 05 months\"\n [19] \"58 years 04 months\" \"63 years 01 month\"  \"62 years\"          \n [22] \"63 years\"           \"57 years 06 months\" \"58 years 03 months\"\n [25] \"57 years 08 months\" \"57 years 05 months\" \"56 years 08 months\"\n [28] \"56 years 04 months\" \"58 years 01 month\"  \"59 years 01 month\" \n [31] \"57 years 11 months\" \"57 years 07 months\" \"70 years 04 months\"\n [34] \"95 years 05 months\" \"83 years 04 months\" \"80 years 01 month\" \n [37] \"78 years 09 months\" \"79 years\"           \"88 years 08 months\"\n [40] \"87 years 05 months\" \"55 years 11 months\" \"56 years 09 months\"\n [43] \"54 years 07 months\" \"55 years 04 months\" \"63 years 03 months\"\n [46] \"55 years 03 months\" \"59 years 08 months\" \"58 years 07 months\"\n [49] \"63 years 02 months\" \"62 years 08 months\" \"64 years\"          \n [52] \"59 years 07 months\" \"59 years 06 months\" \"53 years 01 month\" \n [55] \"55 years 08 months\" \"55 years\"           \"60 years 04 months\"\n [58] \"93 years 11 months\" \"49 years 07 months\" \"57 years 04 months\"\n [61] \"57 years 03 months\" \"83 years\"           \"82 years 11 months\"\n [64] \"91 years 10 months\" \"91 years 08 months\" \"62 years 09 months\"\n [67] \"62 years 07 months\" \"64 years 03 months\" \"78 years\"          \n [70] \"62 years 04 months\" \"62 years 03 months\" \"62 years 02 months\"\n [73] \"54 years 08 months\" \"52 years 01 month\"  \"60 years 07 months\"\n [76] \"61 years\"           \"62 years 05 months\" \"73 years 11 months\"\n [79] \"91 years 09 months\" \"64 years 02 months\" \"60 years 01 month\" \n [82] \"59 years 05 months\" \"61 years 08 months\" \"62 years 06 months\"\n [85] \"70 years 05 months\" \"93 years 10 months\" \"66 years 04 months\"\n [88] \"62 years 11 months\" \"65 years 01 month\"  \"61 years 11 months\"\n [91] \"50 years 11 months\" \"50 years 09 months\" \"50 years 10 months\"\n [94] \"64 years 08 months\" \"65 years\"           \"69 years 08 months\"\n [97] \"69 years 07 months\" \"69 years 05 months\" \"69 years 04 months\"\n[100] \"75 years 06 months\" \"67 years 01 month\"  \"51 years 07 months\"\n[103] \"64 years 10 months\" \"65 years 07 months\" \"64 years 05 months\"\n[106] \"64 years 01 month\"  \"64 years 07 months\" \"63 years 06 months\"\n[109] \"67 years 02 months\" \"62 years 01 month\"  \"62 years 10 months\"\n[112] \"95 years 03 months\" \"65 years 04 months\" \"63 years 04 months\"\n[115] \"65 years 06 months\" \"63 years 08 months\" \"64 years 11 months\"\n[118] \"94 years 07 months\" \"61 years 07 months\" \"94 years 06 months\"\n[121] \"74 years 05 months\" \"75 years 02 months\" \"75 years 07 months\"\n[124] \"63 years 10 months\" \"64 years 06 months\" \"65 years 09 months\"\n[127] \"82 years 02 months\" \"81 years 09 months\" \"80 years 10 months\"\n[130] \"72 years 11 months\" \"74 years 11 months\" \"74 years 10 months\"\n[133] \"75 years 01 month\"  \"75 years\"           \"82 years 01 month\" \n[136] \"74 years 03 months\" \"93 years 01 month\"  \"60 years\"          \n[139] \"60 years 08 months\" \"61 years 04 months\" \"94 years 11 months\"\n[142] \"90 years 05 months\" \"90 years 04 months\" \"46 years 06 months\"\n[145] \"47 years\"           \"52 years 05 months\" \"58 years 09 months\"\n[148] \"48 years 01 month\"  \"48 years\"           \"50 years\"          \n[151] \"90 years 02 months\" \"52 years 03 months\" \"60 years 05 months\"\n[154] \"94 years 04 months\" \"53 years 03 months\" \"82 years 10 months\"\n[157] \"93 years\"           \"50 years 01 month\"  \"47 years 06 months\"\n[160] \"96 years 05 months\" \"96 years 04 months\" \"74 years 01 month\" \n[163] \"80 years 08 months\" \"80 years 09 months\" \"86 years\"          \n[166] \"86 years 01 month\"  \"80 years\"           \"74 years 06 months\"\n[169] \"80 years 06 months\" \"90 years 01 month\"  \"78 years 02 months\"\n[172] \"78 years 07 months\" \"78 years 06 months\" \"55 years 07 months\"\n[175] \"94 years 05 months\" \"53 years 08 months\" \"53 years 09 months\"\n[178] \"73 years 08 months\" \"79 years 11 months\" \"72 years 01 month\" \n[181] \"72 years\"           \"79 years 01 month\"  \"65 years 11 months\"\n[184] \"66 years\"           \"92 years 07 months\" \"92 years\"          \n[187] \"89 years 11 months\" \"65 years 02 months\" \"79 years 06 months\"\n[190] \"66 years 09 months\" \"94 years\"           \"74 years 08 months\"\n[193] \"66 years 01 month\"  \"65 years 08 months\" \"75 years 04 months\"\n[196] \"75 years 05 months\" \"75 years 09 months\" \"80 years 05 months\"\n[199] \"66 years 07 months\" \"65 years 10 months\" \"79 years 04 months\"\n[202] \"79 years 07 months\" \"89 years 10 months\" \"79 years 10 months\"\n[205] \"91 years\"           \"92 years 11 months\" \"92 years 10 months\"\n[208] \"76 years 02 months\" \"81 years 10 months\" \"90 years 11 months\"\n[211] \"79 years 05 months\" \"78 years 10 months\" \"66 years 05 months\"\n[214] \"66 years 03 months\" \"75 years 10 months\" \"76 years 05 months\"\n[217] \"75 years 11 months\" \"79 years 03 months\" \"92 years 06 months\"\n[220] \"78 years 11 months\" \"53 years 04 months\" \"51 years 04 months\"\n[223] \"66 years 06 months\" \"54 years 11 months\" \"56 years 03 months\"\n[226] \"61 years 06 months\" \"54 years 02 months\" \"54 years 01 month\" \n[229] \"88 years 01 month\"  \"88 years\"           \"60 years 10 months\"\n[232] \"61 years 01 month\"  \"94 years 09 months\" \"93 years 06 months\"\n[235] \"90 years 07 months\" \"95 years 02 months\" \"95 years 04 months\"\n[238] \"61 years 10 months\" \"94 years 03 months\" \"67 years 05 months\"\n[241] \"76 years 06 months\" \"67 years 07 months\" \"69 years 06 months\"\n[244] \"77 years 03 months\" \"94 years 02 months\" \"94 years 10 months\"\n[247] \"76 years 10 months\" \"77 years\"           \"80 years 07 months\"\n[250] \"67 years 03 months\" \"67 years 09 months\" \"72 years 05 months\"\n[253] \"73 years 05 months\" \"73 years 03 months\" \"95 years 01 month\" \n[256] \"66 years 02 months\" \"76 years 07 months\" \"76 years 04 months\"\n[259] \"93 years 05 months\" \"80 years 02 months\" \"76 years 11 months\"\n[262] \"76 years 09 months\" \"80 years 04 months\" \"79 years 08 months\"\n[265] \"70 years 06 months\" \"73 years 04 months\" \"71 years 10 months\"\n[268] \"71 years 04 months\" \"72 years 08 months\" \"94 years 08 months\"\n[271] \"61 years 03 months\" \"56 years 02 months\" \"90 years 09 months\"\n[274] \"55 years 06 months\" \"95 years 08 months\" \"91 years 11 months\"\n[277] \"56 years 11 months\" \"57 years 10 months\" \"57 years 09 months\"\n[280] \"90 years 08 months\" \"58 years 08 months\" \"56 years 10 months\"\n[283] \"52 years 07 months\" \"50 years 07 months\" \"44 years\"          \n[286] \"46 years 01 month\"  \"44 years 01 month\"  \"46 years\"          \n[289] \"84 years 01 month\"  \"59 years\"           \"53 years 06 months\"\n[292] \"49 years 08 months\" \"77 years 05 months\" \"58 years 06 months\"\n[295] \"59 years 04 months\" \"88 years 11 months\" \"82 years 03 months\"\n[298] \"67 years 06 months\" \"83 years 11 months\" \"77 years 06 months\"\n[301] \"89 years 05 months\" \"60 years 02 months\" \"52 years 06 months\"\n[304] \"60 years 03 months\" \"70 years 03 months\" \"63 years 07 months\"\n[307] \"63 years 05 months\" \"63 years 09 months\" \"93 years 03 months\"\n[310] \"66 years 08 months\" \"64 years 09 months\" \"74 years 04 months\"\n[313] \"93 years 02 months\" \"74 years 07 months\" \"69 years 10 months\"\n[316] \"69 years 09 months\" \"76 years 03 months\" \"92 years 05 months\"\n[319] \"60 years 09 months\" \"66 years 11 months\" \"76 years 01 month\" \n[322] \"60 years 06 months\" \"61 years 05 months\" \"58 years 05 months\"\n[325] \"58 years 11 months\" \"59 years 09 months\" \"52 years 10 months\"\n[328] \"52 years 11 months\" \"52 years 09 months\" \"91 years 05 months\"\n[331] \"91 years 04 months\" \"53 years 11 months\" \"51 years 10 months\"\n[334] \"49 years 01 month\"  \"89 years 03 months\" \"87 years 03 months\"\n[337] \"92 years 01 month\"  \"92 years 04 months\" \"79 years 02 months\"\n[340] \"67 years 11 months\" \"66 years 10 months\" \"78 years 03 months\"\n[343] \"78 years 01 month\"  \"79 years 09 months\" \"77 years 07 months\"\n[346] \"77 years 08 months\" \"77 years 11 months\" \"78 years 04 months\"\n[349] \"68 years 01 month\"  \"67 years 08 months\" \"83 years 05 months\"\n[352] \"89 years 02 months\" \"87 years 04 months\" \"77 years 09 months\"\n[355] \"61 years 02 months\" \"81 years 04 months\" \"77 years 10 months\"\n[358] \"85 years 06 months\" \"67 years 04 months\" \"73 years 02 months\"\n[361] \"51 years 09 months\" \"81 years 06 months\" \"53 years 10 months\"\n[364] \"47 years 05 months\" \"51 years 01 month\"  \"95 years\"          \n[367] \"59 years 03 months\" \"51 years\"           \"49 years\"          \n[370] \"80 years 03 months\" \"64 years 04 months\" \"82 years\"          \n[373] \"51 years 02 months\" \"87 years 11 months\" \"53 years 07 months\"\n[376] \"81 years 05 months\" \"77 years 04 months\" \"81 years 07 months\"\n[379] \"52 years 04 months\" \"53 years\"           \"72 years 03 months\"\n[382] \"72 years 06 months\" \"73 years 07 months\" \"72 years 07 months\"\n[385] \"70 years\"           \"69 years 11 months\" \"71 years\"          \n[388] \"70 years 08 months\" \"72 years 10 months\" \"73 years 09 months\"\n[391] \"72 years 04 months\" \"70 years 07 months\" \"70 years 09 months\"\n[394] \"72 years 02 months\" \"71 years 03 months\" \"73 years 10 months\"\n[397] \"91 years 03 months\" \"91 years 06 months\" \"81 years\"          \n[400] \"80 years 11 months\" \"85 years\"           \"90 years\"          \n[403] \"89 years 07 months\" \"93 years 08 months\" \"84 years 11 months\"\n[406] \"86 years 03 months\" \"88 years 03 months\" \"90 years 03 months\"\n[409] \"90 years 06 months\" \"89 years 06 months\" \"88 years 02 months\"\n[412] \"89 years 09 months\" \"84 years 07 months\" \"92 years 03 months\"\n[415] \"93 years 09 months\" \"81 years 08 months\" \"47 years 07 months\"\n[418] \"93 years 04 months\" \"93 years 07 months\" \"51 years 05 months\"\n[421] \"47 years 01 month\"  \"50 years 05 months\" \"51 years 06 months\"\n[424] \"83 years 07 months\" \"83 years 10 months\" \"83 years 08 months\"\n[427] \"88 years 07 months\" \"85 years 07 months\" \"89 years 08 months\"\n[430] \"83 years 06 months\" \"85 years 08 months\" \"78 years 08 months\"\n[433] \"81 years 03 months\" \"87 years 08 months\" \"78 years 05 months\"\n[436] \"83 years 01 month\"  \"92 years 09 months\" \"92 years 08 months\"\n[439] \"84 years 08 months\" \"88 years 10 months\" \"85 years 05 months\"\n[442] \"83 years 02 months\" \"86 years 07 months\" \"86 years 06 months\"\n[445] \"86 years 05 months\" \"81 years 11 months\" \"87 years\"          \n[448] \"86 years 11 months\" \"91 years 07 months\" \"76 years 08 months\"\n[451] \"71 years 11 months\" \"65 years 03 months\" \"73 years 06 months\"\n[454] \"72 years 09 months\" \"60 years 11 months\" \"71 years 02 months\"\n[457] \"85 years 11 months\" \"73 years\"           \"74 years 02 months\"\n[460] \"48 years 07 months\" \"44 years 06 months\" \"45 years 06 months\"\n[463] \"86 years 04 months\" \"89 years 04 months\" \"74 years 09 months\"\n[466] \"52 years 08 months\" \"59 years 10 months\" \"54 years 06 months\"\n[469] \"75 years 03 months\" \"77 years 02 months\" \"81 years 01 month\" \n[472] \"71 years 06 months\" \"58 years 02 months\" \"76 years\"          \n[475] \"77 years 01 month\"  \"90 years 10 months\" \"70 years 02 months\"\n[478] \"92 years 02 months\" \"65 years 05 months\" \"63 years 11 months\"\n[481] \"53 years 02 months\" \"55 years 02 months\" \"54 years\"          \n[484] \"49 years 06 months\" \"52 years\"           \"50 years 08 months\"\n[487] \"69 years 03 months\" \"67 years\"           \"49 years 11 months\"\n[490] \"52 years 02 months\" \"82 years 09 months\" \"54 years 10 months\"\n[493] \"75 years 08 months\" \"51 years 03 months\" \"94 years 01 month\" \n[496] \"74 years\"           \"43 years 11 months\" \"49 years 10 months\"\n[499] \"45 years 11 months\" \"81 years 02 months\" \"95 years 06 months\"\n[502] \"67 years 10 months\" \"49 years 05 months\" \"53 years 05 months\"\n[505] \"70 years 11 months\" \"70 years 10 months\" \"87 years 07 months\"\n[508] \"91 years 02 months\" \"86 years 02 months\" \"47 years 04 months\"\n[511] \"51 years 11 months\" \"46 years 11 months\" \"47 years 08 months\"\n[514] \"87 years 06 months\" \"88 years 09 months\" \"87 years 02 months\"\n[517] \"45 years 05 months\" \"44 years 05 months\" \"46 years 04 months\"\n[520] \"73 years 01 month\"  \"71 years 05 months\" \"58 years 10 months\"\n[523] \"88 years 06 months\" \"88 years 05 months\" \"59 years 11 months\"\n[526] \"69 years 02 months\" \"47 years 10 months\" \"96 years 03 months\"\n[529] \"48 years 04 months\" \"44 years 03 months\" \"46 years 05 months\"\n[532] \"46 years 10 months\" \"82 years 07 months\" \"85 years 10 months\"\n[535] \"82 years 08 months\" \"48 years 03 months\" \"59 years 02 months\"\n[538] \"87 years 10 months\" \"71 years 09 months\" \"47 years 11 months\"\n[541] \"45 years 10 months\" \"83 years 09 months\" \"70 years 01 month\" \n[544] \"68 years 02 months\" \"89 years 01 month\"  \"87 years 01 month\" \n[547] \"85 years 04 months\" \"85 years 03 months\" \"83 years 03 months\"\n[550] \"48 years 10 months\" \"91 years 01 month\"  \"84 years 10 months\"\n[553] \"84 years 06 months\" \"84 years 05 months\" \"43 years 10 months\"\n[556] \"89 years\"           \"86 years 10 months\" \"71 years 08 months\"\n[559] \"85 years 09 months\" \"50 years 04 months\" \"45 years 04 months\"\n[562] \"48 years 11 months\" \"49 years 04 months\" \"44 years 04 months\"\n[565] \"46 years 03 months\" \"88 years 04 months\" \"68 years 11 months\"\n[568] \"49 years 09 months\" \"47 years 09 months\" \"44 years 02 months\"\n[571] \"47 years 03 months\" \"96 years 02 months\" \"87 years 09 months\"\n[574] \"71 years 01 month\"  \"71 years 07 months\" \"50 years 03 months\"\n[577] \"43 years 09 months\" \"45 years 09 months\" \"84 years 09 months\"\n[580] \"50 years 02 months\" \"84 years 04 months\" \"85 years 02 months\"\n[583] \"45 years 03 months\" \"49 years 03 months\" \"46 years 09 months\"\n[586] \"45 years 02 months\" \"50 years 06 months\" \"69 years\"          \n[589] \"46 years 08 months\" \"96 years\"           \"82 years 06 months\"\n[592] \"96 years 01 month\"  \"45 years 08 months\" \"68 years 04 months\"\n[595] \"85 years 01 month\"  \"48 years 08 months\" \"47 years 02 months\"\n[598] \"51 years 08 months\" \"84 years 03 months\" \"48 years 02 months\"\n[601] \"45 years 01 month\"  \"48 years 09 months\" \"69 years 01 month\" \n[604] \"95 years 07 months\" \"46 years 02 months\" \"82 years 05 months\"\n[607] \"45 years 07 months\" \"49 years 02 months\" \"43 years 08 months\"\n[610] \"86 years 09 months\" \"46 years 07 months\" \"68 years 10 months\"\n[613] \"43 years 07 months\" \"43 years 06 months\" \"68 years 03 months\"\n[616] \"84 years 02 months\" \"48 years 06 months\" \"45 years\"          \n[619] \"68 years 09 months\" \"95 years 10 months\" \"82 years 04 months\"\n[622] \"48 years 05 months\" \"84 years\"           \"44 years 11 months\"\n[625] \"86 years 08 months\" \"68 years 08 months\" \"95 years 09 months\"\n[628] \"43 years 05 months\" \"43 years 04 months\" \"68 years\"          \n[631] \"68 years 07 months\" \"68 years 06 months\" \"43 years 03 months\"\n[634] \"44 years 09 months\" \"68 years 05 months\" \"43 years 02 months\"\n[637] \"43 years 01 month\"  \"44 years 07 months\"\n\n\n\n\n\n\n\n\nCritical!\n\n\n\nremaining lease is listed as a string and needed for the arrangement to be corrected moving foreward\n\n\n\nsummary(filter_flat_data$resale_price)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 200000  428000  515000  536391  610000 1418000 \n\n\n\n\nCorrecting the Data\nThis section deals with correcting the data last inspected previously.\n\nCorrecting the Storey Arrangement\nThe code adds corrects the order of the storey arrangement\n\nstorey_correct <- c(\"01 TO 03\", \"04 TO 06\", \"07 TO 09\", \"10 TO 12\", \"13 TO 15\", \"16 TO 18\", \"19 TO 21\", \"22 TO 24\", \"25 TO 27\", \"28 TO 30\", \"31 TO 33\", \"34 TO 36\", \"37 TO 39\", \"40 TO 42\", \"43 TO 45\", \"46 TO 48\", \"49 TO 51\")  \n\nuse_flat_data <- filter_flat_data %>%\n  mutate (storey_range = factor(storey_range, levels = storey_correct)) %>%\n  ungroup()\n\n\nggplot(data = use_flat_data,\n       aes(y = storey_range)) +\n  geom_bar() \n\n\n\n\n\n\nConverting Remaining Lease from String to Num\nThe code adds a new integer column derived from the remaining_lease string column.\n\n\n\n\n\n\nNote\n\n\n\nThis code uses the gsub-regex function to get the integer within the string.\n\n\n\nlease_ryear <- as.numeric(gsub(\"([0-9]+).*$\", \"\\\\1\", filter_flat_data$remaining_lease))\n\nuse_flat_data$lease_ryear <- lease_ryear\n\nuse_flat_data\n\n# A tibble: 24,374 × 12\n   month   town    flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n   <chr>   <chr>   <chr>   <chr> <chr>   <fct>     <dbl> <chr>     <dbl> <chr>  \n 1 2022-01 ANG MO… 3 ROOM  320   ANG MO… 07 TO …      73 New Ge…    1977 54 yea…\n 2 2022-01 ANG MO… 3 ROOM  225   ANG MO… 07 TO …      67 New Ge…    1978 55 yea…\n 3 2022-01 ANG MO… 3 ROOM  331   ANG MO… 07 TO …      68 New Ge…    1981 58 yea…\n 4 2022-01 ANG MO… 3 ROOM  534   ANG MO… 07 TO …      82 New Ge…    1980 57 yea…\n 5 2022-01 ANG MO… 3 ROOM  578   ANG MO… 04 TO …      67 New Ge…    1980 57 yea…\n 6 2022-01 ANG MO… 3 ROOM  452   ANG MO… 01 TO …      83 New Ge…    1979 56 yea…\n 7 2022-01 ANG MO… 3 ROOM  560   ANG MO… 01 TO …      67 New Ge…    1980 57 yea…\n 8 2022-01 ANG MO… 3 ROOM  435   ANG MO… 04 TO …      67 New Ge…    1979 56 yea…\n 9 2022-01 ANG MO… 3 ROOM  435   ANG MO… 04 TO …      67 New Ge…    1979 56 yea…\n10 2022-01 ANG MO… 3 ROOM  560   ANG MO… 10 TO …      67 New Ge…    1980 57 yea…\n# … with 24,364 more rows, 2 more variables: resale_price <dbl>,\n#   lease_ryear <dbl>, and abbreviated variable names ¹​flat_type, ²​street_name,\n#   ³​storey_range, ⁴​floor_area_sqm, ⁵​flat_model, ⁶​lease_commence_date,\n#   ⁷​remaining_lease"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html#data-exploration-through-statistical-visualization",
    "href": "Take-home_Ex/Take-home_Ex03.html#data-exploration-through-statistical-visualization",
    "title": "Data Visualization Makeover 03",
    "section": "Data Exploration through Statistical Visualization",
    "text": "Data Exploration through Statistical Visualization\nThis section presents the statistical visualization and explanation of the data.\n\nAnalysis on the Type of Flat\nThis section presents insights with regards to the relationship between Type of Flat and other variables.\n\nOne-way ANOVA Test on Type of Flat and Resale Price\n\n\nCode\nggbetweenstats(\n  data = use_flat_data,\n  x = flat_type,\n  y = resale_price, \n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\nComing from One-way ANOVA test between Type of Flat and the Resale Price, overall p-value of the ANOVA test is 0.00 < 0.05 means that we can reject the null hypotheses meaning each flat type have different mean resale price coming from the ANOVA hypothesis:\n\nHo = there’s no difference between the means and conclude that a significant difference does not exist.\nHa = there’s difference between the means and conclude that a significant difference does exist.\n\nPairwise P-Test also concluded the following:\n\n\n\n\n\n\n\n\nRelation\nP-Value\nRemark\n\n\n\n\n3 Room - 4 Room\n3.25 e-08 < 0.05\nReject null hypothesis, Significant difference\n\n\n3 Room - 5 Room\n0 < 0.05\nReject null hypothesis, Significant difference\n\n\n4 Room - 5 Room\n0 < 0.05\nReject null hypothesis, Significant difference\n\n\n\n\n\n\n\n\n\nP-Value = 0\n\n\n\nPlease note that P-Value cannot be equals to 0, the 0 value is a reference that p-value is very close to 0\n\n\nIt can also be noted that in 2022, around 46% (n = 11,312 rooms) of the total scoped rooms belong to the 4 Room category and with 54% of the rooms split almost evenly between 3 and 5 Room categories.\n\n\nOne-way ANOVA Test on Type of Flat and Floor Sqr Area\n\n\nCode\nggbetweenstats(\n  data = use_flat_data,\n  x = flat_type,\n  y = floor_area_sqm, \n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\nComing from One-way ANOVA test between Type of Flat and the Floor Area, overall p-value of the ANOVA test is 0.00 < 0.05 means that we can reject the null hypotheses meaning each flat type have different mean resale price coming from the ANOVA hypothesis:\n\nHo = there’s no difference between the means and conclude that a significant difference does not exist.\nHa = there’s difference between the means and conclude that a significant difference does exist.\n\nPairwise P-Test also concluded the following:\n\n\n\n\n\n\n\n\nRelation\nP-Value\nRemark\n\n\n\n\n3 Room - 4 Room\n1.19 e-08 < 0.05\nReject null hypothesis, Significant difference\n\n\n3 Room - 5 Room\n0 < 0.05\nReject null hypothesis, Significant difference\n\n\n4 Room - 5 Room\n1.07 e-09 < 0.05\nReject null hypothesis, Significant difference\n\n\n\n\n\nCorrelation between Resale Price, Remaining Lease Years and Floor Area\n\n\nCode\nggstatsplot::ggcorrmat(\n  data = use_flat_data,\n  cor.vars = c(resale_price, lease_ryear, floor_area_sqm)\n)\n\n\n\n\n\nBased on the correlation coefficients, there is moderate correlation between resale price and floor area and resale price and remaining lease year while weak correlation between the floor area and remaining lease year. This concludes that there is a relationship between resale price and remaining lease year and resale price and floor area though this does not mean causality between both relationship.\n\n\nModel Diagnostic\n\n\nCode\nmodel <- lm(resale_price ~ flat_type + lease_ryear + floor_area_sqm, data = use_flat_data)\n\ncheck_model(model)\n\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\nAnalysis on 3 Room Flats\n\nroom_3 <- filter(use_flat_data, grepl(\"3 ROOM\", flat_type))\nroom_3\n\n# A tibble: 6,346 × 12\n   month   town    flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n   <chr>   <chr>   <chr>   <chr> <chr>   <fct>     <dbl> <chr>     <dbl> <chr>  \n 1 2022-01 ANG MO… 3 ROOM  320   ANG MO… 07 TO …      73 New Ge…    1977 54 yea…\n 2 2022-01 ANG MO… 3 ROOM  225   ANG MO… 07 TO …      67 New Ge…    1978 55 yea…\n 3 2022-01 ANG MO… 3 ROOM  331   ANG MO… 07 TO …      68 New Ge…    1981 58 yea…\n 4 2022-01 ANG MO… 3 ROOM  534   ANG MO… 07 TO …      82 New Ge…    1980 57 yea…\n 5 2022-01 ANG MO… 3 ROOM  578   ANG MO… 04 TO …      67 New Ge…    1980 57 yea…\n 6 2022-01 ANG MO… 3 ROOM  452   ANG MO… 01 TO …      83 New Ge…    1979 56 yea…\n 7 2022-01 ANG MO… 3 ROOM  560   ANG MO… 01 TO …      67 New Ge…    1980 57 yea…\n 8 2022-01 ANG MO… 3 ROOM  435   ANG MO… 04 TO …      67 New Ge…    1979 56 yea…\n 9 2022-01 ANG MO… 3 ROOM  435   ANG MO… 04 TO …      67 New Ge…    1979 56 yea…\n10 2022-01 ANG MO… 3 ROOM  560   ANG MO… 10 TO …      67 New Ge…    1980 57 yea…\n# … with 6,336 more rows, 2 more variables: resale_price <dbl>,\n#   lease_ryear <dbl>, and abbreviated variable names ¹​flat_type, ²​street_name,\n#   ³​storey_range, ⁴​floor_area_sqm, ⁵​flat_model, ⁶​lease_commence_date,\n#   ⁷​remaining_lease\n\n\n\nOne-way ANOVA Test on Town and Resale Price\n\n\nCode\nggbetweenstats(\n  data = room_3,\n  x = town,\n  y = resale_price, \n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\nWarning: Number of labels is greater than default palette color count.\n• Select another color `palette` (and/or `package`).\n\n\n\n\n\n\nres.aov <- aov(resale_price~town, data = room_3)\nsummary (res.aov)\n\n              Df    Sum Sq   Mean Sq F value Pr(>F)    \ntown          25 6.746e+12 2.699e+11   43.27 <2e-16 ***\nResiduals   6320 3.942e+13 6.237e+09                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTukeyHSD(res.aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = resale_price ~ town, data = room_3)\n\n$town\n                                      diff          lwr         upr     p adj\nBEDOK-ANG MO KIO               -18620.3726  -36284.7679   -955.9773 0.0248933\nBISHAN-ANG MO KIO               28273.3450   -9921.2322  66467.9221 0.5371259\nBUKIT BATOK-ANG MO KIO         -15676.8676  -37133.0345   5779.2993 0.5659993\nBUKIT MERAH-ANG MO KIO          60593.6676   40297.5004  80889.8348 0.0000000\nBUKIT PANJANG-ANG MO KIO        -4396.5473  -34850.5958  26057.5011 1.0000000\nBUKIT TIMAH-ANG MO KIO          54741.7603  -26833.4109 136316.9316 0.7379320\nCENTRAL AREA-ANG MO KIO         68699.3131   34911.0399 102487.5864 0.0000000\nCHOA CHU KANG-ANG MO KIO         4861.0927  -26828.0770  36550.2623 1.0000000\nCLEMENTI-ANG MO KIO             42478.2353   20895.5975  64060.8730 0.0000000\nGEYLANG-ANG MO KIO             -31842.7295  -52570.7040 -11114.7549 0.0000053\nHOUGANG-ANG MO KIO                836.9030  -20126.7331  21800.5391 1.0000000\nJURONG EAST-ANG MO KIO         -17969.7384  -43153.6616   7214.1849 0.6172205\nJURONG WEST-ANG MO KIO         -31329.1798  -51894.3527 -10764.0068 0.0000069\nKALLANG/WHAMPOA-ANG MO KIO      61021.8457   40924.0372  81119.6543 0.0000000\nMARINE PARADE-ANG MO KIO        38314.0790    5333.6982  71294.4598 0.0052470\nPASIR RIS-ANG MO KIO            97581.9765   32926.1656 162237.7873 0.0000093\nPUNGGOL-ANG MO KIO              57573.7158   33827.6516  81319.7801 0.0000000\nQUEENSTOWN-ANG MO KIO           60308.2460   39899.1626  80717.3293 0.0000000\nSEMBAWANG-ANG MO KIO            46015.3881    7006.7132  85024.0631 0.0039681\nSENGKANG-ANG MO KIO             50753.9583   25570.0350  75937.8815 0.0000000\nSERANGOON-ANG MO KIO             3423.2353  -29403.8988  36250.3693 1.0000000\nTAMPINES-ANG MO KIO             27478.7721    8005.6287  46951.9155 0.0000669\nTOA PAYOH-ANG MO KIO            -3272.2922  -22701.8498  16157.2654 1.0000000\nWOODLANDS-ANG MO KIO           -16066.6297  -38591.1261   6457.8667 0.6179462\nYISHUN-ANG MO KIO               -5407.6457  -23199.4038  12384.1124 0.9999965\nBISHAN-BEDOK                    46893.7175    8801.1125  84986.3226 0.0017246\nBUKIT BATOK-BEDOK                2943.5049  -18330.6093  24217.6191 1.0000000\nBUKIT MERAH-BEDOK               79214.0402   59110.4275  99317.6528 0.0000000\nBUKIT PANJANG-BEDOK             14223.8252  -16102.2346  44549.8851 0.9939382\nBUKIT TIMAH-BEDOK               73362.1329   -8165.3434 154889.6093 0.1532958\nCENTRAL AREA-BEDOK              87319.6857   53646.7255 120992.6458 0.0000000\nCHOA CHU KANG-BEDOK             23481.4652   -8084.7241  55047.6546 0.5262089\nCLEMENTI-BEDOK                  61098.6078   39696.9470  82500.2687 0.0000000\nGEYLANG-BEDOK                  -13222.3569  -33761.8254   7317.1116 0.8060836\nHOUGANG-BEDOK                   19457.2756   -1319.9927  40234.5438 0.1045683\nJURONG EAST-BEDOK                 650.6342  -24378.3655  25679.6339 1.0000000\nJURONG WEST-BEDOK              -12708.8072  -33083.9680   7666.3536 0.8494961\nKALLANG/WHAMPOA-BEDOK           79642.2183   59738.8833  99545.5533 0.0000000\nMARINE PARADE-BEDOK             56934.4516   24072.2186  89796.6846 0.0000001\nPASIR RIS-BEDOK                116202.3490   51606.7245 180797.9736 0.0000000\nPUNGGOL-BEDOK                   76194.0884   52612.3920  99775.7848 0.0000000\nQUEENSTOWN-BEDOK                78928.6185   58711.0143  99146.2228 0.0000000\nSEMBAWANG-BEDOK                 64635.7607   25726.9242 103544.5972 0.0000003\nSENGKANG-BEDOK                  69374.3308   44345.3311  94403.3306 0.0000000\nSERANGOON-BEDOK                 22043.6078  -10664.8248  54752.0405 0.7302170\nTAMPINES-BEDOK                  46099.1447   26826.7772  65371.5122 0.0000000\nTOA PAYOH-BEDOK                 15348.0804   -3880.2463  34576.4070 0.3698323\nWOODLANDS-BEDOK                  2553.7429  -19797.4042  24904.8900 1.0000000\nYISHUN-BEDOK                    13212.7269   -4359.0543  30784.5080 0.5021302\nBUKIT BATOK-BISHAN             -43950.2126  -83942.4968  -3957.9284 0.0133576\nBUKIT MERAH-BISHAN              32320.3226   -7061.7812  71702.4264 0.3118034\nBUKIT PANJANG-BISHAN           -32669.8923  -78128.2773  12788.4927 0.6019101\nBUKIT TIMAH-BISHAN              26468.4154  -61812.5240 114749.3548 0.9999973\nCENTRAL AREA-BISHAN             40425.9682   -7330.3205  88182.2568 0.2519136\nCHOA CHU KANG-BISHAN           -23412.2523  -69707.1675  22882.6629 0.9834724\nCLEMENTI-BISHAN                 14204.8903  -25855.3886  54265.1693 0.9999347\nGEYLANG-BISHAN                 -60116.0744  -99722.4455 -20509.7034 0.0000078\nHOUGANG-BISHAN                 -27436.4420  -67166.6539  12293.7699 0.6841679\nJURONG EAST-BISHAN             -46243.0833  -88353.0072  -4133.1595 0.0135144\nJURONG WEST-BISHAN             -59602.5247  -99123.9371 -20081.1123 0.0000095\nKALLANG/WHAMPOA-BISHAN          32748.5008   -6531.7437  72028.7452 0.2806273\nMARINE PARADE-BISHAN            10040.7341  -37147.4129  57228.8811 1.0000000\nPASIR RIS-BISHAN                69308.6315   -3625.5140 142242.7770 0.0897604\nPUNGGOL-BISHAN                  29300.3709  -11965.7323  70566.4740 0.6276142\nQUEENSTOWN-BISHAN               32034.9010   -7405.5146  71475.3166 0.3330134\nSEMBAWANG-BISHAN                17742.0432  -33839.8570  69323.9433 0.9999626\nSENGKANG-BISHAN                 22480.6133  -19629.3106  64590.5372 0.9681761\nSERANGOON-BISHAN               -24850.1097  -71931.2782  22231.0588 0.9721390\nTAMPINES-BISHAN                  -794.5728  -39758.9028  38169.7572 1.0000000\nTOA PAYOH-BISHAN               -31545.6372  -70488.2026   7396.9283 0.3386057\nWOODLANDS-BISHAN               -44339.9746  -84915.4430  -3764.5062 0.0145896\nYISHUN-BISHAN                  -33680.9906  -71832.8235   4470.8423 0.1810828\nBUKIT MERAH-BUKIT BATOK         76270.5352   52765.3980  99775.6725 0.0000000\nBUKIT PANJANG-BUKIT BATOK       11280.3203  -21400.0430  43960.6835 0.9999601\nBUKIT TIMAH-BUKIT BATOK         70418.6280  -12013.5601 152850.8161 0.2354481\nCENTRAL AREA-BUKIT BATOK        84376.1807   48568.2978 120184.0637 0.0000000\nCHOA CHU KANG-BUKIT BATOK       20537.9603  -13296.3499  54372.2705 0.8810195\nCLEMENTI-BUKIT BATOK            58155.1029   33530.5760  82779.6298 0.0000000\nGEYLANG-BUKIT BATOK            -16165.8618  -40044.8485   7713.1248 0.7219671\nHOUGANG-BUKIT BATOK             16513.7706   -7570.0645  40597.6057 0.6979668\nJURONG EAST-BUKIT BATOK         -2292.8707  -30127.8678  25542.1264 1.0000000\nJURONG WEST-BUKIT BATOK        -15652.3121  -39390.1177   8085.4934 0.7682176\nKALLANG/WHAMPOA-BUKIT BATOK     76698.7133   53364.6399 100032.7868 0.0000000\nMARINE PARADE-BUKIT BATOK       53990.9467   18944.3692  89037.5241 0.0000048\nPASIR RIS-BUKIT BATOK          113258.8441   47525.0556 178992.6326 0.0000001\nPUNGGOL-BUKIT BATOK             73250.5834   46709.4335  99791.7334 0.0000000\nQUEENSTOWN-BUKIT BATOK          75985.1136   52382.4070  99587.8202 0.0000000\nSEMBAWANG-BUKIT BATOK           61692.2558   20921.7542 102462.7573 0.0000086\nSENGKANG-BUKIT BATOK            66430.8259   38595.8288  94265.8230 0.0000000\nSERANGOON-BUKIT BATOK           19100.1029  -15802.3011  54002.5069 0.9578702\nTAMPINES-BUKIT BATOK            43155.6398   20357.3857  65953.8938 0.0000000\nTOA PAYOH-BUKIT BATOK           12404.5754  -10356.4611  35165.6119 0.9597580\nWOODLANDS-BUKIT BATOK            -389.7620  -25843.8386  25064.3145 1.0000000\nYISHUN-BUKIT BATOK              10269.2220  -11110.7624  31649.2063 0.9915860\nBUKIT PANJANG-BUKIT MERAH      -64990.2149  -96920.9751 -33059.4547 0.0000000\nBUKIT TIMAH-BUKIT MERAH         -5851.9072  -87989.7970  76285.9826 1.0000000\nCENTRAL AREA-BUKIT MERAH         8105.6455  -27019.4422  43230.7333 1.0000000\nCHOA CHU KANG-BUKIT MERAH      -55732.5749  -88843.4168 -22621.7330 0.0000002\nCLEMENTI-BUKIT MERAH           -18115.4323  -41736.0723   5505.2076 0.4578283\nGEYLANG-BUKIT MERAH            -92436.3970 -115278.7548 -69594.0393 0.0000000\nHOUGANG-BUKIT MERAH            -59756.7646  -82813.1828 -36700.3464 0.0000000\nJURONG EAST-BUKIT MERAH        -78563.4059 -105514.3683 -51612.4436 0.0000000\nJURONG WEST-BUKIT MERAH        -91922.8474 -114617.5762 -69228.1185 0.0000000\nKALLANG/WHAMPOA-BUKIT MERAH       428.1781  -21843.9185  22700.2748 1.0000000\nMARINE PARADE-BUKIT MERAH      -22279.5886  -56628.2406  12069.0635 0.7946202\nPASIR RIS-BUKIT MERAH           36988.3089  -28376.0411 102352.6589 0.9396362\nPUNGGOL-BUKIT MERAH             -3019.9518  -28632.4477  22592.5442 1.0000000\nQUEENSTOWN-BUKIT MERAH           -285.4216  -22838.8041  22267.9609 1.0000000\nSEMBAWANG-BUKIT MERAH          -14578.2794  -54750.4228  25593.8639 0.9999009\nSENGKANG-BUKIT MERAH            -9839.7093  -36790.6716  17111.2530 0.9998897\nSERANGOON-BUKIT MERAH          -57170.4323  -91371.9690 -22968.8956 0.0000003\nTAMPINES-BUKIT MERAH           -33114.8954  -54824.9782 -11404.8127 0.0000066\nTOA PAYOH-BUKIT MERAH          -63865.9598  -85536.9562 -42194.9633 0.0000000\nWOODLANDS-BUKIT MERAH          -76660.2972 -101144.5231 -52176.0713 0.0000000\nYISHUN-BUKIT MERAH             -66001.3133  -86216.9269 -45785.6996 0.0000000\nBUKIT TIMAH-BUKIT PANJANG       59138.3077  -26079.9275 144356.5429 0.6744804\nCENTRAL AREA-BUKIT PANJANG      73095.8605   31271.3885 114920.3324 0.0000000\nCHOA CHU KANG-BUKIT PANJANG      9257.6400  -30890.1186  49405.3986 1.0000000\nCLEMENTI-BUKIT PANJANG          46874.7826   14111.2465  79638.3187 0.0000456\nGEYLANG-BUKIT PANJANG          -27446.1821  -59653.1375   4760.7732 0.2397921\nHOUGANG-BUKIT PANJANG            5233.4503  -27125.6764  37592.5771 1.0000000\nJURONG EAST-BUKIT PANJANG      -13573.1910  -48813.3532  21666.9712 0.9997196\nJURONG WEST-BUKIT PANJANG      -26932.6324  -59035.0526   5169.7878 0.2686211\nKALLANG/WHAMPOA-BUKIT PANJANG   65418.3931   33613.3470  97223.4391 0.0000000\nMARINE PARADE-BUKIT PANJANG     42710.6264    1536.0643  83885.1885 0.0311163\nPASIR RIS-BUKIT PANJANG        101978.5238   32783.0549 171173.9927 0.0000193\nPUNGGOL-BUKIT PANJANG           61970.2632   27742.8675  96197.6588 0.0000000\nQUEENSTOWN-BUKIT PANJANG        64704.7933   32702.1414  96707.4452 0.0000000\nSEMBAWANG-BUKIT PANJANG         50411.9355    4267.4259  96556.4451 0.0146514\nSENGKANG-BUKIT PANJANG          55150.5056   19910.3434  90390.6679 0.0000029\nSERANGOON-BUKIT PANJANG          7819.7826  -33232.1330  48871.6982 1.0000000\nTAMPINES-BUKIT PANJANG          31875.3195     461.2723  63289.3666 0.0416304\nTOA PAYOH-BUKIT PANJANG          1124.2552  -30262.7924  32511.3027 1.0000000\nWOODLANDS-BUKIT PANJANG        -11670.0823  -45061.5780  21721.4134 0.9999499\nYISHUN-BUKIT PANJANG            -1011.0983  -31411.5210  29389.3244 1.0000000\nCENTRAL AREA-BUKIT TIMAH        13957.5528  -72508.3130 100423.4186 1.0000000\nCHOA CHU KANG-BUKIT TIMAH      -49880.6677 -135548.0595  35786.7241 0.9194632\nCLEMENTI-BUKIT TIMAH           -12263.5251  -94728.7225  70201.6724 1.0000000\nGEYLANG-BUKIT TIMAH            -86584.4898 -168830.1430  -4338.8366 0.0253535\nHOUGANG-BUKIT TIMAH            -53904.8574 -136210.2191  28400.5044 0.7793168\nJURONG EAST-BUKIT TIMAH        -72711.4987 -156191.6073  10768.6099 0.2023762\nJURONG WEST-BUKIT TIMAH        -86070.9401 -168275.7142  -3866.1661 0.0273677\nKALLANG/WHAMPOA-BUKIT TIMAH      6280.0854  -75809.0153  88369.1860 1.0000000\nMARINE PARADE-BUKIT TIMAH      -16427.6813 -102581.0565  69725.6939 1.0000000\nPASIR RIS-BUKIT TIMAH           42840.2161  -59702.8110 145383.2432 0.9989278\nPUNGGOL-BUKIT TIMAH              2831.9555  -80225.6998  85889.6108 1.0000000\nQUEENSTOWN-BUKIT TIMAH           5566.4856  -76599.3785  87732.3497 1.0000000\nSEMBAWANG-BUKIT TIMAH           -8726.3722  -97362.5683  79909.8239 1.0000000\nSENGKANG-BUKIT TIMAH            -3987.8021  -87467.9106  79492.3065 1.0000000\nSERANGOON-BUKIT TIMAH          -51318.5251 -137413.3523  34776.3021 0.8992254\nTAMPINES-BUKIT TIMAH           -27262.9882 -109201.3910  54675.4146 0.9999799\nTOA PAYOH-BUKIT TIMAH          -58014.0525 -139942.1078  23914.0028 0.6333007\nWOODLANDS-BUKIT TIMAH          -70808.3900 -153525.0841  11908.3041 0.2317839\nYISHUN-BUKIT TIMAH             -60149.4060 -141704.5726  21405.7605 0.5452882\nCHOA CHU KANG-CENTRAL AREA     -63838.2205 -106570.4198 -21106.0211 0.0000128\nCLEMENTI-CENTRAL AREA          -26221.0779  -62104.8853   9662.7296 0.5657722\nGEYLANG-CENTRAL AREA          -100542.0426 -135918.3950 -65165.6901 0.0000000\nHOUGANG-CENTRAL AREA           -67862.4101 -103377.3566 -32347.4636 0.0000000\nJURONG EAST-CENTRAL AREA       -86669.0515 -124827.5024 -48510.6006 0.0000000\nJURONG WEST-CENTRAL AREA      -100028.4929 -135309.7021 -64747.2837 0.0000000\nKALLANG/WHAMPOA-CENTRAL AREA    -7677.4674  -42688.3128  27333.3780 1.0000000\nMARINE PARADE-CENTRAL AREA     -30385.2341  -74083.5510  13313.0829 0.6705238\nPASIR RIS-CENTRAL AREA          28882.6633  -41843.6490  99608.9757 0.9992564\nPUNGGOL-CENTRAL AREA           -11125.5973  -48350.7629  26099.5683 0.9999975\nQUEENSTOWN-CENTRAL AREA         -8391.0672  -43581.5214  26799.3871 1.0000000\nSEMBAWANG-CENTRAL AREA         -22683.9250  -71093.7805  25725.9305 0.9940190\nSENGKANG-CENTRAL AREA          -17945.3548  -56103.8058  20213.0961 0.9937075\nSERANGOON-CENTRAL AREA         -65276.0779 -108858.8510 -21693.3047 0.0000118\nTAMPINES-CENTRAL AREA          -41220.5410  -75876.5751  -6564.5069 0.0033972\nTOA PAYOH-CENTRAL AREA         -71971.6053 -106603.1674 -37340.0432 0.0000000\nWOODLANDS-CENTRAL AREA         -84765.9428 -121224.0053 -48307.8802 0.0000000\nYISHUN-CENTRAL AREA            -74106.9588 -107846.9061 -40367.0115 0.0000000\nCLEMENTI-CHOA CHU KANG          37617.1426    3702.4894  71531.7958 0.0115315\nGEYLANG-CHOA CHU KANG          -36703.8221  -70081.0955  -3326.5487 0.0132248\nHOUGANG-CHOA CHU KANG           -4024.1897  -37548.3226  29499.9433 1.0000000\nJURONG EAST-CHOA CHU KANG      -22830.8310  -59143.6860  13482.0240 0.8392466\nJURONG WEST-CHOA CHU KANG      -36190.2724  -69466.6873  -2913.8575 0.0157059\nKALLANG/WHAMPOA-CHOA CHU KANG   56160.7531   23171.1281  89150.3781 0.0000001\nMARINE PARADE-CHOA CHU KANG     33452.9864   -8643.3195  75549.2923 0.3793682\nPASIR RIS-CHOA CHU KANG         92720.8838   22972.9998 162468.7678 0.0003110\nPUNGGOL-CHOA CHU KANG           52712.6232   17381.7724  88043.4739 0.0000133\nQUEENSTOWN-CHOA CHU KANG        55447.1533   22266.9765  88627.3301 0.0000003\nSEMBAWANG-CHOA CHU KANG         41154.2955   -5814.5258  88123.1168 0.1927931\nSENGKANG-CHOA CHU KANG          45892.8656    9580.0106  82205.7206 0.0009912\nSERANGOON-CHOA CHU KANG         -1437.8574  -43414.2100  40538.4952 1.0000000\nTAMPINES-CHOA CHU KANG          22617.6795   -9995.1518  55230.5107 0.6757472\nTOA PAYOH-CHOA CHU KANG         -8133.3848  -40720.2098  24453.4401 0.9999999\nWOODLANDS-CHOA CHU KANG        -20927.7223  -55449.4023  13593.9577 0.8824086\nYISHUN-CHOA CHU KANG           -10268.7383  -41906.3758  21368.8992 0.9999875\nGEYLANG-CLEMENTI               -74320.9647  -98313.6544 -50328.2751 0.0000000\nHOUGANG-CLEMENTI               -41641.3323  -65837.9078 -17444.7568 0.0000001\nJURONG EAST-CLEMENTI           -60447.9736  -88380.5750 -32515.3723 0.0000000\nJURONG WEST-CLEMENTI           -73807.4150  -97659.5966 -49955.2334 0.0000000\nKALLANG/WHAMPOA-CLEMENTI        18543.6105   -4906.8082  41994.0291 0.3901003\nMARINE PARADE-CLEMENTI          -4164.1562  -39288.3039  30959.9914 1.0000000\nPASIR RIS-CLEMENTI              55103.7412  -10671.4373 120878.9197 0.2713411\nPUNGGOL-CLEMENTI                15095.4805  -11548.0139  41738.9750 0.9388630\nQUEENSTOWN-CLEMENTI             17830.0107   -5887.7234  41547.7448 0.5026374\nSEMBAWANG-CLEMENTI               3537.1529  -37300.0477  44374.3535 1.0000000\nSENGKANG-CLEMENTI                8275.7230  -19656.8783  36208.3244 0.9999979\nSERANGOON-CLEMENTI             -39055.0000  -74035.2939  -4074.7061 0.0103656\nTAMPINES-CLEMENTI              -14999.4631  -37916.7828   7917.8566 0.7803867\nTOA PAYOH-CLEMENTI             -45750.5275  -68630.8233 -22870.2317 0.0000000\nWOODLANDS-CLEMENTI             -58544.8649  -84105.6389 -32984.0909 0.0000000\nYISHUN-CLEMENTI                -47885.8809  -69392.7841 -26378.9778 0.0000000\nHOUGANG-GEYLANG                 32679.6324    9242.2063  56117.0586 0.0000924\nJURONG EAST-GEYLANG             13872.9911  -13404.6352  41150.6174 0.9822562\nJURONG WEST-GEYLANG               513.5497  -22568.1583  23595.2577 1.0000000\nKALLANG/WHAMPOA-GEYLANG         92864.5752   70198.2827 115530.8676 0.0000000\nMARINE PARADE-GEYLANG           70156.8085   35551.2537 104762.3633 0.0000000\nPASIR RIS-GEYLANG              129424.7059   63924.9900 194924.4218 0.0000000\nPUNGGOL-GEYLANG                 89416.4453   63460.4349 115372.4556 0.0000000\nQUEENSTOWN-GEYLANG              92150.9754   69208.2295 115093.7213 0.0000000\nSEMBAWANG-GEYLANG               77858.1176   37466.0933 118250.1419 0.0000000\nSENGKANG-GEYLANG                82596.6877   55319.0614 109874.3140 0.0000000\nSERANGOON-GEYLANG               35265.9647     806.4285  69725.5009 0.0372594\nTAMPINES-GEYLANG                59321.5016   37207.2026  81435.8006 0.0000000\nTOA PAYOH-GEYLANG               28570.4373    6494.5089  50646.3656 0.0005842\nWOODLANDS-GEYLANG               15776.0998   -9067.2463  40619.4459 0.8257573\nYISHUN-GEYLANG                  26435.0838    5785.9782  47084.1894 0.0007466\nJURONG EAST-HOUGANG            -18806.6413  -46263.7717   8650.4890 0.7000181\nJURONG WEST-HOUGANG            -32166.0828  -55459.6517  -8872.5138 0.0001194\nKALLANG/WHAMPOA-HOUGANG         60184.9427   37302.9427  83066.9427 0.0000000\nMARINE PARADE-HOUGANG           37477.1760    2729.9526  72224.3994 0.0178161\nPASIR RIS-HOUGANG               96745.0735   31170.3993 162319.7476 0.0000187\nPUNGGOL-HOUGANG                 56736.8128   30592.2229  82881.4028 0.0000000\nQUEENSTOWN-HOUGANG              59471.3430   36315.4647  82627.2213 0.0000000\nSEMBAWANG-HOUGANG               45178.4852    4665.0215  85691.9488 0.0105705\nSENGKANG-HOUGANG                49917.0553   22459.9250  77374.1856 0.0000000\nSERANGOON-HOUGANG                2586.3323  -32015.4704  37188.1349 1.0000000\nTAMPINES-HOUGANG                26641.8691    4306.5310  48977.2073 0.0032181\nTOA PAYOH-HOUGANG               -4109.1952  -26406.5431  18188.1527 1.0000000\nWOODLANDS-HOUGANG              -16903.5326  -41943.8392   8136.7739 0.7272232\nYISHUN-HOUGANG                  -6244.5487  -27130.2057  14641.1084 0.9999975\nJURONG WEST-JURONG EAST        -13359.4414  -40513.5628  13794.6799 0.9884069\nKALLANG/WHAMPOA-JURONG EAST     78991.5841   52189.6835 105793.4847 0.0000000\nMARINE PARADE-JURONG EAST       56283.8174   18838.8513  93728.7835 0.0000106\nPASIR RIS-JURONG EAST          115551.7148   48508.4911 182594.9385 0.0000001\nPUNGGOL-JURONG EAST             75543.4542   45907.4029 105179.5054 0.0000000\nQUEENSTOWN-JURONG EAST          78277.9843   51241.8853 105314.0833 0.0000000\nSEMBAWANG-JURONG EAST           63985.1265   21135.4277 106834.8253 0.0000129\nSENGKANG-JURONG EAST            68723.6966   37923.5350  99523.8583 0.0000000\nSERANGOON-JURONG EAST           21392.9736  -15917.0880  58703.0352 0.9308973\nTAMPINES-JURONG EAST            45448.5105   19111.7818  71785.2392 0.0000001\nTOA PAYOH-JURONG EAST           14697.4462  -11607.0720  41001.9643 0.9471863\nWOODLANDS-JURONG EAST            1903.1087  -26763.4730  30569.6904 1.0000000\nYISHUN-JURONG EAST              12562.0927  -12556.9563  37681.1417 0.9856626\nKALLANG/WHAMPOA-JURONG WEST     92351.0255   69833.5162 114868.5348 0.0000000\nMARINE PARADE-JURONG WEST       69643.2588   35134.9723 104151.5453 0.0000000\nPASIR RIS-JURONG WEST          128911.1562   63462.7782 194359.5343 0.0000000\nPUNGGOL-JURONG WEST             88902.8956   63076.7096 114729.0816 0.0000000\nQUEENSTOWN-JURONG WEST          91637.4257   68841.6586 114433.1929 0.0000000\nSEMBAWANG-JURONG WEST           77344.5679   37035.8463 117653.2895 0.0000000\nSENGKANG-JURONG WEST            82083.1380   54929.0167 109237.2594 0.0000000\nSERANGOON-JURONG WEST           34752.4150     390.5605  69114.2696 0.0434070\nTAMPINES-JURONG WEST            58807.9519   36846.1754  80769.7285 0.0000000\nTOA PAYOH-JURONG WEST           28056.8876    6133.7486  49980.0266 0.0007520\nWOODLANDS-JURONG WEST           15262.5501   -9445.1259  39970.2261 0.8613456\nYISHUN-JURONG WEST              25921.5341    5435.8569  46407.2113 0.0009654\nMARINE PARADE-KALLANG/WHAMPOA  -22707.7667  -56939.5853  11524.0519 0.7581007\nPASIR RIS-KALLANG/WHAMPOA       36560.1307  -28742.8995 101863.1610 0.9460582\nPUNGGOL-KALLANG/WHAMPOA         -3448.1299  -28903.7276  22007.4678 1.0000000\nQUEENSTOWN-KALLANG/WHAMPOA       -713.5998  -23088.6432  21661.4437 1.0000000\nSEMBAWANG-KALLANG/WHAMPOA      -15006.4576  -55078.7499  25065.8347 0.9998274\nSENGKANG-KALLANG/WHAMPOA       -10267.8874  -37069.7880  16534.0131 0.9997442\nSERANGOON-KALLANG/WHAMPOA      -57598.6105  -91682.8094 -23514.4115 0.0000002\nTAMPINES-KALLANG/WHAMPOA       -33543.0736  -55067.8314 -12018.3158 0.0000033\nTOA PAYOH-KALLANG/WHAMPOA      -64294.1379  -85779.4723 -42808.8035 0.0000000\nWOODLANDS-KALLANG/WHAMPOA      -77088.4754 -101408.5252 -52768.4256 0.0000000\nYISHUN-KALLANG/WHAMPOA         -66429.4914  -86445.9481 -46413.0347 0.0000000\nPASIR RIS-MARINE PARADE         59267.8974  -11076.0388 129611.8337 0.2606000\nPUNGGOL-MARINE PARADE           19259.6368  -17233.8018  55753.0754 0.9721751\nQUEENSTOWN-MARINE PARADE        21994.1669  -12421.3264  56409.6602 0.8167589\nSEMBAWANG-MARINE PARADE          7701.3091  -40148.1655  55550.7837 1.0000000\nSENGKANG-MARINE PARADE          12439.8792  -25005.0868  49884.8453 0.9999805\nSERANGOON-MARINE PARADE        -34890.8438  -77850.3157   8068.6281 0.3331537\nTAMPINES-MARINE PARADE         -10835.3069  -44704.1541  23033.5403 0.9999905\nTOA PAYOH-MARINE PARADE        -41586.3712  -75430.1772  -7742.5652 0.0017910\nWOODLANDS-MARINE PARADE        -54380.7087  -90091.3294 -18670.0879 0.0000070\nYISHUN-MARINE PARADE           -43721.7247  -76652.5940 -10790.8554 0.0003207\nPUNGGOL-PASIR RIS              -40008.2607 -106524.7204  26508.1991 0.8904692\nQUEENSTOWN-PASIR RIS           -37273.7305 -102673.2300  28125.7690 0.9350120\nSEMBAWANG-PASIR RIS            -51566.5883 -124930.3435  21797.1669 0.6486317\nSENGKANG-PASIR RIS             -46828.0182 -113871.2419  20215.2055 0.6614774\nSERANGOON-PASIR RIS            -94158.7412 -164430.9589 -23886.5235 0.0002565\nTAMPINES-PASIR RIS             -70103.2043 -135216.6988  -4989.7098 0.0183019\nTOA PAYOH-PASIR RIS           -100854.2687 -165954.7415 -35753.7958 0.0000040\nWOODLANDS-PASIR RIS           -113648.6061 -179738.8232 -47558.3891 0.0000001\nYISHUN-PASIR RIS              -102989.6221 -167620.1916 -38359.0527 0.0000015\nQUEENSTOWN-PUNGGOL               2734.5302  -22967.5365  28436.5968 1.0000000\nSEMBAWANG-PUNGGOL              -11558.3277  -53579.0638  30462.4085 0.9999995\nSENGKANG-PUNGGOL                -6819.7575  -36455.8088  22816.2937 1.0000000\nSERANGOON-PUNGGOL              -54150.4805  -90505.4840 -17795.4771 0.0000140\nTAMPINES-PUNGGOL               -30094.9437  -55060.2968  -5129.5905 0.0026248\nTOA PAYOH-PUNGGOL              -60846.0080  -85777.3788 -35914.6372 0.0000000\nWOODLANDS-PUNGGOL              -73640.3455 -101052.3589 -46228.3320 0.0000000\nYISHUN-PUNGGOL                 -62981.3615  -86658.6122 -39304.1108 0.0000000\nSEMBAWANG-QUEENSTOWN           -14292.8578  -54522.1678  25936.4522 0.9999324\nSENGKANG-QUEENSTOWN             -9554.2877  -36590.3867  17481.8113 0.9999386\nSERANGOON-QUEENSTOWN           -56885.0107  -91153.6756 -22616.3458 0.0000003\nTAMPINES-QUEENSTOWN            -32829.4738  -54645.1557 -11013.7920 0.0000102\nTOA PAYOH-QUEENSTOWN           -63580.5382  -85357.3232 -41803.7531 0.0000000\nWOODLANDS-QUEENSTOWN           -76374.8756 -100952.7844 -51796.9669 0.0000000\nYISHUN-QUEENSTOWN              -65715.8916  -86044.8689 -45386.9144 0.0000000\nSENGKANG-SEMBAWANG               4738.5701  -38111.1287  47588.2690 1.0000000\nSERANGOON-SEMBAWANG            -42592.1529  -90336.1308   5151.8251 0.1655197\nTAMPINES-SEMBAWANG             -18536.6160  -58299.2871  21226.0551 0.9944354\nTOA PAYOH-SEMBAWANG            -49287.6803  -89029.0241  -9546.3365 0.0014797\nWOODLANDS-SEMBAWANG            -62082.0178 -103424.7274 -20739.3082 0.0000109\nYISHUN-SEMBAWANG               -51423.0338  -90389.8576 -12456.2100 0.0003708\nSERANGOON-SENGKANG             -47330.7230  -84640.7846 -10020.6614 0.0009132\nTAMPINES-SENGKANG              -23275.1861  -49611.9149   3061.5426 0.1794610\nTOA PAYOH-SENGKANG             -54026.2505  -80330.7686 -27721.7323 0.0000000\nWOODLANDS-SENGKANG             -66820.5879  -95487.1696 -38154.0062 0.0000000\nYISHUN-SENGKANG                -56161.6039  -81280.6529 -31042.5550 0.0000000\nTAMPINES-SERANGOON              24055.5369   -9664.1016  57775.1754 0.6176415\nTOA PAYOH-SERANGOON             -6695.5275  -40390.0139  26998.9590 1.0000000\nWOODLANDS-SERANGOON            -19489.8649  -55059.0039  16079.2740 0.9572700\nYISHUN-SERANGOON                -8830.8809  -41608.2720  23946.5101 0.9999997\nTOA PAYOH-TAMPINES             -30751.0643  -51653.2412  -9848.8875 0.0000203\nWOODLANDS-TAMPINES             -43545.4018  -67351.8343 -19738.9693 0.0000000\nYISHUN-TAMPINES                -32886.4178  -52275.5886 -13497.2470 0.0000002\nWOODLANDS-TOA PAYOH            -12794.3375  -36565.1309  10976.4560 0.9650414\nYISHUN-TOA PAYOH                -2135.3535  -21480.7493  17210.0424 1.0000000\nYISHUN-WOODLANDS                10658.9840  -11792.9552  33110.9231 0.9928273\n\n\n\n\n\n\n\n\nToo Many Values\n\n\n\nThere is an estimated 55 areas as such would yield large amount of combination for pairwise analysis.\n\n\n\n\nOne-way ANOVA Test on Flat Model and Resale Price\n\n\nCode\nggbetweenstats(\n  data = room_3,\n  x = flat_model,\n  y = resale_price, \n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\nWarning: Number of labels is greater than default palette color count.\n• Select another color `palette` (and/or `package`).\n\n\n\n\n\nBased on the Oneway ANOVA, overall ANOVA has a p-value less than 0.05 (4.36 e-107 < 0.05), indicating that the mean price is significantly different from each Flat Model.\n\n\nCorrelation between Resale Price, Remaining Lease Years and Floor Area\n\n\nCode\nggstatsplot::ggcorrmat(\n  data = room_3,\n  cor.vars = c(resale_price, lease_ryear, floor_area_sqm)\n)\n\n\n\n\n\nBased on the correlation coefficients, there is moderate correlation between resale price and remaining lease year while weak to no correlation between the floor area and remaining lease year and resale price and floor area. This concludes that there is a relationship between resale price and remaining lease year though this does not mean causality between both relationship.\n\n\n\nAnalysis on 4 Room Flats\n\nroom_4 <- filter(use_flat_data, grepl(\"4 ROOM\", flat_type))\nroom_4\n\n# A tibble: 11,312 × 12\n   month   town    flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n   <chr>   <chr>   <chr>   <chr> <chr>   <fct>     <dbl> <chr>     <dbl> <chr>  \n 1 2022-01 ANG MO… 4 ROOM  438   ANG MO… 10 TO …      92 New Ge…    1979 56 yea…\n 2 2022-01 ANG MO… 4 ROOM  556   ANG MO… 13 TO …      92 New Ge…    1980 57 yea…\n 3 2022-01 ANG MO… 4 ROOM  419   ANG MO… 07 TO …      99 New Ge…    1979 56 yea…\n 4 2022-01 ANG MO… 4 ROOM  466   ANG MO… 04 TO …      93 New Ge…    1984 61 yea…\n 5 2022-01 ANG MO… 4 ROOM  472   ANG MO… 01 TO …      92 New Ge…    1979 56 yea…\n 6 2022-01 ANG MO… 4 ROOM  405   ANG MO… 01 TO …      92 New Ge…    1979 56 yea…\n 7 2022-01 ANG MO… 4 ROOM  547   ANG MO… 01 TO …      92 New Ge…    1981 58 yea…\n 8 2022-01 ANG MO… 4 ROOM  415   ANG MO… 01 TO …      92 New Ge…    1979 56 yea…\n 9 2022-01 ANG MO… 4 ROOM  324   ANG MO… 04 TO …      98 New Ge…    1978 55 yea…\n10 2022-01 ANG MO… 4 ROOM  121   ANG MO… 10 TO …      92 New Ge…    1978 55 yea…\n# … with 11,302 more rows, 2 more variables: resale_price <dbl>,\n#   lease_ryear <dbl>, and abbreviated variable names ¹​flat_type, ²​street_name,\n#   ³​storey_range, ⁴​floor_area_sqm, ⁵​flat_model, ⁶​lease_commence_date,\n#   ⁷​remaining_lease\n\n\n\nOne-way ANOVA Test on Flat Model and Resale Price\n\n\nCode\nggbetweenstats(\n  data = room_4,\n  x = flat_model,\n  y = resale_price, \n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\nWarning: Number of labels is greater than default palette color count.\n• Select another color `palette` (and/or `package`).\n\n\n\n\n\nBased on the Oneway ANOVA, overall ANOVA has a p-value less than 0.05 (5.37 e-34 < 0.05), indicating that the mean price is significantly different from each Flat Model.\n\n\nCorrelation between Resale Price, Remaining Lease Years and Floor Area\n\n\nCode\nggstatsplot::ggcorrmat(\n  data = room_4,\n  cor.vars = c(resale_price, lease_ryear, floor_area_sqm)\n)\n\n\n\n\n\nBased on the correlation coefficients, there is moderate correlation between resale price and remaining lease year while weak to no correlation between the floor area and remaining lease year and resale price and floor area. This concludes that there is a relationship between resale price and remaining lease year though this does not mean causality between both relationship.\n\n\n\nAnalysis on 5 Room Flats\n\nroom_5 <- filter(use_flat_data, grepl(\"5 ROOM\", flat_type))\nroom_5\n\n# A tibble: 6,716 × 12\n   month   town    flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n   <chr>   <chr>   <chr>   <chr> <chr>   <fct>     <dbl> <chr>     <dbl> <chr>  \n 1 2022-01 ANG MO… 5 ROOM  402   ANG MO… 19 TO …     119 Improv…    1979 56 yea…\n 2 2022-01 ANG MO… 5 ROOM  460   ANG MO… 16 TO …     120 Improv…    1980 57 yea…\n 3 2022-01 ANG MO… 5 ROOM  539   ANG MO… 22 TO …     118 Improv…    1980 57 yea…\n 4 2022-01 ANG MO… 5 ROOM  521   ANG MO… 10 TO …     118 Improv…    1980 57 yea…\n 5 2022-01 ANG MO… 5 ROOM  648   ANG MO… 01 TO …     125 Improv…    1980 57 yea…\n 6 2022-01 ANG MO… 5 ROOM  354   ANG MO… 04 TO …     110 Improv…    2001 78 yea…\n 7 2022-01 ANG MO… 5 ROOM  353   ANG MO… 04 TO …     110 Improv…    2001 78 yea…\n 8 2022-01 ANG MO… 5 ROOM  350   ANG MO… 22 TO …     110 Improv…    2001 79 yea…\n 9 2022-01 ANG MO… 5 ROOM  588A  ANG MO… 01 TO …     120 DBSS       2011 88 yea…\n10 2022-01 ANG MO… 5 ROOM  588B  ANG MO… 28 TO …     120 DBSS       2011 88 yea…\n# … with 6,706 more rows, 2 more variables: resale_price <dbl>,\n#   lease_ryear <dbl>, and abbreviated variable names ¹​flat_type, ²​street_name,\n#   ³​storey_range, ⁴​floor_area_sqm, ⁵​flat_model, ⁶​lease_commence_date,\n#   ⁷​remaining_lease\n\n\n\nOne-way ANOVA Test on Flat Model and Resale Price\n\n\nCode\nggbetweenstats(\n  data = room_5,\n  x = flat_model,\n  y = resale_price, \n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\nWarning: Number of labels is greater than default palette color count.\n• Select another color `palette` (and/or `package`).\n\n\n\n\n\nBased on the Oneway ANOVA, overall ANOVA has a p-value less than 0.05 (3.88 e-17 < 0.05), indicating that the mean price is significantly different from each Flat Model.\n\n\nCorrelation between Resale Price, Remaining Lease Years and Floor Area\n\n\nCode\nggstatsplot::ggcorrmat(\n  data = room_5,\n  cor.vars = c(resale_price, lease_ryear, floor_area_sqm)\n)\n\n\n\n\n\nBased on the correlation coefficients, for 5 Room Flats, the resale price, remaining lease years and floor area have weak to no correlation meaning each variable is independent of each other."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html#learning-and-insights",
    "href": "Take-home_Ex/Take-home_Ex03.html#learning-and-insights",
    "title": "Data Visualization Makeover 03",
    "section": "Learning and Insights",
    "text": "Learning and Insights\nSize Limitations: due to the limitations of quarto size, visualization many variables may be difficult. Filters and selected values may be considered\nEase of Statistical Understanding: certain visualizations may not be easily understood by readers/users. Simplification may be a better option."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02.html",
    "title": "Data Visualization Makeover 02",
    "section": "",
    "text": "The objective of this exercise is to critique and improve an Age-Sex Pyramid Analytic Visualization of Singapore of the year 2022. The output is to recreate a Trellis Chart Age-Sex Pyramid through R-Studios by using ggplot2, ggplot2 extensions and tidyverse packages.\nThe visualization is created using the Singapore Residents by Planning Area / Sub-zone, Age Group, Sex and Type of Dwelling, June 2022 (Singstat).\n\n\n\n\n\n\nNote\n\n\n\nThe output should be focused as a static Trellis Chart without filter interactivity.\n\n\n\n\nThe Original Visualization Source: https://public.tableau.com/app/profile/joseph.zexeong.tan/viz/SingaporePopulationPyramindJun2022v1_3/trel3x3_d?publish=yes\n\n\n\n\n\n\n\n\nThe Original Visualization shows 2 separate Age-Pyramid Trellis Chart that shows the same message. Two sets of visualization normally indicate that they visualize two different messages that may it be independent of each other or connected. The issue with the dashboard is that both sets indicate the same message just in a different format. This raises either confusion to the reader and a form of redundancy that can be best allocated to something else.\n3x3 Trellis Chart limits the visualization to only 9 Age-Sex Pyramids. Limited and focused visualizations are normally selected under a criteria. This criteria may be in terms of highest population cumulative or selective. The original visualization shows no indication of the criteria chosen to only visualize 9 areas and may only be concluded as a random selection.\n3x3 Trellis Chart lacks y-axis labels. Taking to consideration that the Trellis Charts is a stand alone visualization, the lack of y-axis label reduces the clarity of the y-axis values. Furthermore, both Trellis Charts lack x-axis values and labels but make up for it through text values per bar. In terms of clarity, one can argue that the lack of x-axis may confuse the reader due to the text values having no reference while others say the taxt vales are enough to compensate the lack of x-axis.\n\n\n\n\n\nText Values center bar alignment makes reading the values difficult. Due to the mismatched alignment of the text values brought abut by the central alignment placement in the bar chart makes reading the values difficult as the reader cannot simply scroll down and read the values, not mention creates unnecessary confusion in the graph.\nText Values on each Bar Chart overwhelms the visualization. More than the mismatch alignment, the number of the text values in the chart saturates the charts and makes it “noisy”. The text values fill the dashboard with a lot of numbers that is makes the labels and visuals difficult to look at and interpret.\nHorizontally arranged Trellis Chart limits and squeezes the Age-Sex Pyramids. This visualization arrangement artificially contorts the bar length due to the lack of width space. The squeeze minimizes the visual differentiation between bar charts as such creates an illusion that some bars are of the same size."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#getting-started---data-loading-and-processing",
    "href": "Take-home_Ex/Take-home_Ex02.html#getting-started---data-loading-and-processing",
    "title": "Data Visualization Makeover 02",
    "section": "Getting Started - Data Loading and Processing",
    "text": "Getting Started - Data Loading and Processing\n\nInstalling and loading the required libraries\nBefore we get started, it is important for us to ensure that the required R packages have been installed.\n\npacman::p_load(tidyverse,ggplot2,knitr, plotly, skimr, questionr, funModeling, sf, tmap, quanteda, NLP, ggiraph)\n\n\n\nImporting Data\nThis code chunk is to import the data from respopagesextod2022.csv file to the Quarto/R page.\n\npop_data <- read_csv(\"data/respopagesextod2022.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe CSV File contains the following columns:\n\n\n\n\n\n\n\n\nCOLUMN NAME\nDATA TYPE\nDESCRIPTION\n\n\n\n\nPlanning Area (PA)\nCharacter\nDistinct Planning Areas in Singapore designated and mapped by the Government of Singapore\n\n\nSubzone (SZ)\nCharacter\nSub-areas within each Planning Areas\n\n\nAge Group (AG)\nCharacter\nSets of population age group by 5 (ex 0-4, 5-9, etc)\n\n\nSex\nCharacter\nBinary biological identifier of gender\n\n\nType of Dwelling (TOD)\nCharacter\nAvailable dwelling types in Sinagpore\n\n\nPopulation (Pop)\nNumerical\nPopulation per category\n\n\nTime\nNumerical\nYear -> 2022\n\n\n\n\n\nData Exploration and Cleaning\nThis section is to check incorrect and missing values in the data set.\n\nskimr::skim(pop_data)\n\n\nData summary\n\n\nName\npop_data\n\n\nNumber of rows\n100928\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nPA\n0\n1\n4\n23\n0\n55\n0\n\n\nSZ\n0\n1\n4\n29\n0\n332\n0\n\n\nAG\n0\n1\n6\n11\n0\n19\n0\n\n\nSex\n0\n1\n5\n7\n0\n2\n0\n\n\nTOD\n0\n1\n6\n39\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPop\n0\n1\n40.44\n125.73\n0\n0\n0\n20\n2300\n▇▁▁▁▁\n\n\nTime\n0\n1\n2022.00\n0.00\n2022\n2022\n2022\n2022\n2022\n▁▁▇▁▁"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#create-age-sex-pyramid",
    "href": "Take-home_Ex/Take-home_Ex02.html#create-age-sex-pyramid",
    "title": "Data Visualization Makeover 02",
    "section": "Create Age-Sex Pyramid",
    "text": "Create Age-Sex Pyramid\nThis section explores the creation of an Age-Sex Pyramid.\n\nExploration of y-axis Data\n\nExp1 <- pop_data %>% \n  filter(PA == \"Ang Mo Kio\") %>%\n  group_by(AG, Sex) %>%\n  summarise(`sum_pop` = sum(`Pop`), n = n()) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'AG'. You can override using the `.groups`\nargument.\n\n\n\nggplot(data = Exp1,\n       aes(y = AG)) +\n  geom_bar() +\n  theme_bw() +  \n  ggtitle(\"Test: Age Group Distribution\") \n\n\n\n\nBased on the y-axis (Age Group), 2 issues are noticed:\n\nEach Age Group is written with an underscore (“_”) instead of a space in between each word/number\nThe values are organized alphabetically with consideration of the starting value (number or alphabet). As such “5_to_9” came before “45_to_49”\n\n\nCorrecting Age Labels\n\npop_data$AG <- gsub(\"_\", \" \", pop_data$AG, fixed = TRUE)\n\n\n\nCorrecting Sequence\n\nage_correct <- c(\"0 to 4\", \"5 to 9\", \"10 to 14\", \"15 to 19\", \"20 to 24\", \"25 to 29\", \"30 to 34\", \"35 to 39\", \"40 to 44\", \"45 to 49\", \"50 to 54\", \"55 to 59\", \"60 to 64\", \"65 to 69\", \"70 to 74\", \"75 to 79\", \"80 to 84\", \"85 to 89\", \"90 and over\")\n\npop_sg <- pop_data %>%\n  group_by(AG, Sex) %>%\n  summarise(`sum_pop` = sum(`Pop`)) %>%\n  mutate(AG = factor(AG, levels = age_correct)) %>%\n  arrange(AG) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'AG'. You can override using the `.groups`\nargument.\n\npop_sg <- pop_sg %>%\n  mutate(pct = scales::percent((sum_pop/sum(sum_pop)), accuracy = 0.01),\n         res = str_c(sum_pop, \", \", pct))\n\npop_pa <- pop_data %>%\n  group_by(PA, AG, Sex) %>%\n  summarise(`sum_pop` = sum(`Pop`)) %>%\n  mutate(AG = factor(AG, levels = age_correct)) %>%\n  arrange(AG) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'PA', 'AG'. You can override using the\n`.groups` argument.\n\npop_pa <- pop_pa %>%\n  mutate(pct = scales::percent((sum_pop/sum(sum_pop)), accuracy = 0.01),\n         res = str_c(sum_pop, \", \", pct))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#creating-a-age-sex-pyramid",
    "href": "Take-home_Ex/Take-home_Ex02.html#creating-a-age-sex-pyramid",
    "title": "Data Visualization Makeover 02",
    "section": "Creating a Age-Sex Pyramid",
    "text": "Creating a Age-Sex Pyramid\nThis section explores the visualization of an Age-Sex Pyramid.\n\n\n\n\n\n\nNote\n\n\n\nThis section will be using the total Singapore data (cummulative of all Planning Area)\n\n\n\nSG_Pyr <- ggplot(pop_sg,\n                    aes(x = ifelse(Sex == \"Males\", \n                                   yes = sum_pop*(-1),\n                                   no = sum_pop),\n                        y = AG,\n                        fill = Sex)) + \n  geom_col() +\n  scale_x_continuous(limits = c(-170000, 170000),\n    breaks = seq(-200000, 200000, 50000), \n                     labels = paste0(\n                       as.character(\n                         c(seq(200, 0, -50), \n                           seq(50, 200, 50))),\n                       \"k\")) +\n  scale_y_discrete(expand = expansion(mult = c(0, 0.01))) +\n  labs (x = \"Count of Population\", \n        y = \"Age Group\",\n        fill = \"Gender\",\n        title = \"Singapore Population Pyramid 2022\",\n        subtitle = \"Distribution of gender and age groups\",\n        caption = \"Data Source : Singstat.gov.sg, June 2022\") +\n  theme_bw() +\n  theme(plot.title = element_text(size = 14, \n                                  colour = \"#424242\",\n                                  face = \"bold\",\n                                  hjust = 0.5),\n        plot.subtitle = element_text(size = 8,\n                                     colour = \"#424242\",\n                                     hjust = 0.5),\n        plot.caption = element_text(size = 5,\n                                    colour = \"#424242\",\n                                    hjust = 0),\n        axis.ticks = element_line(colour = \"#424242\",\n                                  linewidth = 0.1),\n        axis.title.y = element_text(angle = 0, \n                                    size = 8, \n                                    colour = \"#424242\",\n                                    face = \"bold\",\n                                    vjust = 1.05,\n                                    hjust = 1,\n                                    margin = margin(r = -40, l = 10)),\n        axis.title.x = element_text(size = 8, \n                                    colour = \"#424242\",\n                                    face = \"bold\"),\n        axis.text.x = element_text(size = 7,\n                                   colour = \"#424242\"),\n        axis.text.y = element_text(size = 7,\n                                   colour = \"#424242\"),\n        legend.position = \"bottom\",\n        legend.justification = \"left\",\n        legend.text = element_text(size = 7,\n                                   colour = \"#424242\"),\n        legend.title = element_text(size = 8, \n                                    colour = \"#424242\"),\n        panel.grid.major = element_line(linewidth = rel(0.5)),\n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#ffffff\"),\n        legend.background = element_rect(fill = \"#ffffff\"),\n        legend.margin = margin(t = -10),\n        panel.border = element_rect(colour = \"#424242\",\n                                    linewidth = 0.3)) \n  \nSG_Pyr"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#creating-a-trellis-age-sex-pyramid",
    "href": "Take-home_Ex/Take-home_Ex02.html#creating-a-trellis-age-sex-pyramid",
    "title": "Data Visualization Makeover 02",
    "section": "Creating A Trellis Age-Sex Pyramid",
    "text": "Creating A Trellis Age-Sex Pyramid\nThis section explores the visualization of an Age-Sex Pyramid within a Trellis Chart. Each Pyramid indicates per Planning Area.\n\nRemoving Planning Areas without Values\nIt was previously identified that 26 out of 55 Planning Areas have no value/data. To maximize space, 9 Planning Areas will be retained and filtered.\n\n\n\n\n\n\nNote\n\n\n\nDue to the limitations of space in r generated visualization in quarto only a limited number of planning areas can be shown\n\n\n\nt_pop_pa <- pop_data %>%\n  group_by(PA) %>%\n  summarise(`sum_pop` = sum(`Pop`)) %>%\n  ungroup()\n\ntrellis9 <- arrange(t_pop_pa, desc(t_pop_pa$sum_pop)) %>%\n  slice(1:9) %>%\n  select(PA)\n\ntrellis9_filter <- pop_pa %>%\n  filter(pop_pa$PA %in% trellis9$PA)\n\n\n\nCreating Trellis Chart Age-Sex Pyramid\n\nPA_Pyr <- ggplot() +\n  geom_bar(data = subset(trellis9_filter, \n                         Sex == \"Males\"), \n           aes(x = AG, \n               y = -sum_pop, \n               fill = PA),\n           stat = \"identity\", \n           fill = \"#2E9598\") +\n  geom_bar(data = subset(trellis9_filter, \n                         Sex == \"Females\"), \n           aes(x = AG, \n               y = sum_pop, \n               fill = PA), \n           stat = \"identity\", \n           fill = \"#EC1B4B\") +\n  coord_flip() +\n  facet_wrap(.~ PA,\n             drop = FALSE, \n             ncol = 3,\n             scales = \"fixed\")+\n  scale_y_continuous(limits = c(-13000, 13000),\n                     breaks = seq(-20000, 20000, 5000), \n                     labels = paste0(\n                       as.character(\n                         c(seq(200, 0, -50), \n                           seq(50, 200, 50))),\n                       \"k\"), \n                     expand = expansion(mult = c(0, .04)))+\n  labs (y = \"Population\", \n        x = \"Age Group\",\n        fill = \"Gender\",\n        title = \"Singapore Population Pyramid 2022\",\n        subtitle = \"Distribution of gender and age groups from Most Populated Planning Areas\",\n        caption = \"Data Source : Singstat.gov.sg, June 2022\") +\n  theme_bw() +\n  theme(plot.title = element_text(size = 14, \n                                  colour = \"#424242\",\n                                  face = \"bold\",\n                                  hjust = 0.5),\n        plot.subtitle = element_text(size = 8,\n                                     colour = \"#424242\",\n                                     hjust = 0.5),\n        plot.caption = element_text(size = 8,\n                                    colour = \"#424242\",\n                                    hjust = 0),\n        strip.text = element_text(size = 7,\n                                  colour = \"#424242\"),\n        strip.background = element_blank(),\n\n        axis.ticks = element_line(colour = \"#424242\",\n                                  linewidth = 0.5),\n        axis.ticks.x = element_line(colour = \"#424242\",\n                                  linewidth = 0.5),,\n        axis.title.y = element_text(angle = 0, \n                                    size = 8, \n                                    colour = \"#424242\",\n                                    vjust = 1.025,\n                                    hjust = 0.7,\n                                    margin = margin(r = -20, l = 20)),\n        axis.title.x = element_text(size = 8, \n                                    colour = \"#424242\"),\n        axis.text.x = element_text(size = 4,\n                                   colour = \"#424242\"),\n        axis.text.y = element_text(size = 4,\n                                   colour = \"#424242\"),\n        legend.position = \"bottom\",\n        legend.justification = \"left\",\n        legend.text = element_text(size = 5,\n                                   colour = \"#424242\"),\n        legend.title = element_text(size = 8, \n                                    colour = \"#424242\"),\n        panel.grid.major = element_line(linewidth = rel(0.5)),\n        panel.grid.major.x = element_line(linewidth = rel(0.5)),\n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#ffffff\"),\n        legend.background = element_rect(fill = \"#ffffff\"),\n        legend.margin = margin(t = -10),\n        panel.border = element_rect(colour = \"#424242\",\n                                    linewidth = 0.3)) \n\nPA_Pyr\n\n\n\n\n\n\nLearning from Practice\n\nClarity\n\nWith the subtitle indicating that these Planning Areas are the most populous in Singapore, the reader is more clear of the message. Not to mention that axis labels and ticks are present to further provide clarity.\nDue to the limitation of space, a 3x3 Trellis Chart may be the maximum representation that can at least maximize readability. Adding more Age-Sex Pyramids will diminish readability and make the chart more difficult to interpret. Furthermore, the limits in size also affects the font sizes, thus reducing clarity and readability.\n\n\n\nAesthetic\n\nThe removal of bar numbers lessens the elements present in the visualization and makes in more pleasing to look at. This less “noisy” visualization greatly improves its aesthetic and design.\n\n\n\nInteractivity\n\nCrafting the visualization in R Studios is more difficult and restrictive as the limits in visual size restrict creative and engaging visuals. Furthermore, transitioning to interactivity may be difficult in the future as the limitations may complicate it further. Future visualization may be better crafted in R Shiny instead of quarto/R Studios."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#further-improvements-and-developments",
    "href": "Take-home_Ex/Take-home_Ex02.html#further-improvements-and-developments",
    "title": "Data Visualization Makeover 02",
    "section": "Further Improvements and Developments",
    "text": "Further Improvements and Developments\nThis section improves upon the original visualization by increasing size and adding interactivity.\n\nIncreasing Visualization Size\n\n\nCode\nPA_Pyr <- ggplot() +\n  geom_bar(data = subset(trellis9_filter, \n                         Sex == \"Males\"), \n           aes(x = AG, \n               y = -sum_pop, \n               fill = PA),\n           stat = \"identity\", \n           fill = \"#2E9598\") +\n  geom_bar(data = subset(trellis9_filter, \n                         Sex == \"Females\"), \n           aes(x = AG, \n               y = sum_pop, \n               fill = PA), \n           stat = \"identity\", \n           fill = \"#EC1B4B\") +\n  coord_flip() +\n  facet_wrap(.~ PA,\n             drop = FALSE, \n             ncol = 3,\n             scales = \"fixed\")+\n  scale_y_continuous(limits = c(-13000, 13000),\n                     breaks = seq(-20000, 20000, 5000), \n                     labels = paste0(\n                       as.character(\n                         c(seq(200, 0, -50), \n                           seq(50, 200, 50))),\n                       \"k\"), \n                     expand = expansion(mult = c(0, .04)))+\n  labs (y = \"Population\", \n        x = \"Age Group\",\n        fill = \"Gender\",\n        title = \"Singapore Population Pyramid 2022\",\n        subtitle = \"Distribution of gender and age groups from Most Populated Planning Areas\",\n        caption = \"Data Source : Singstat.gov.sg, June 2022\") +\n  theme_bw() +\n  theme(plot.title = element_text(size = 20, \n                                  colour = \"#424242\",\n                                  face = \"bold\",\n                                  hjust = 0.5),\n        plot.subtitle = element_text(size = 14,\n                                     colour = \"#424242\",\n                                     hjust = 0.5),\n        plot.caption = element_text(size = 12,\n                                    colour = \"#424242\",\n                                    hjust = 0),\n        strip.text = element_text(size = 12,\n                                  colour = \"#424242\"),\n        strip.background = element_blank(),\n\n        axis.ticks = element_line(colour = \"#424242\",\n                                  linewidth = 0.5),\n        axis.ticks.x = element_line(colour = \"#424242\",\n                                  linewidth = 0.5),,\n        axis.title.y = element_text(angle = 0, \n                                    size = 12, \n                                    colour = \"#424242\",\n                                    vjust = 1.025,\n                                    hjust = 0.7,\n                                    margin = margin(r = -50, l = 50)),\n        axis.title.x = element_text(size = 12, \n                                    colour = \"#424242\"),\n        axis.text.x = element_text(size = 10,\n                                   colour = \"#424242\"),\n        axis.text.y = element_text(size = 10,\n                                   colour = \"#424242\"),\n        legend.position = \"bottom\",\n        legend.justification = \"left\",\n        legend.text = element_text(size = 12,\n                                   colour = \"#424242\"),\n        legend.title = element_text(size = 12, \n                                    colour = \"#424242\"),\n        panel.grid.major = element_line(linewidth = rel(0.5)),\n        panel.grid.major.x = element_line(linewidth = rel(0.5)),\n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#ffffff\"),\n        legend.background = element_rect(fill = \"#ffffff\"),\n        legend.margin = margin(t = -10),\n        panel.border = element_rect(colour = \"#424242\",\n                                    linewidth = 0.3)) \n\nPA_Pyr\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAdditional Codes:\nTo Increase Visualization size:\n#| fig-height: 12 #| fig-width: 12\nTo allow option to hide codes upon render:\n#| code-fold: true\n\n\n\n\nAdding Visualization\nThis section applies the ggiraph package to add interactive visualization per Bar within the Age Sex Pyramid.\n\n\nCode\nPA_Pyr <- ggplot() +\n  geom_bar_interactive(data = subset(trellis9_filter, \n                         Sex == \"Males\"), \n                       aes(x = AG, \n                           y = -sum_pop, \n                           fill = PA,\n                           tooltip =  paste0(\"Sex= \", Sex,\n  \"\\n Age Group= \", AG,\n  \"\\n Population= \", sum_pop)),\n                       stat = \"identity\", \n                       fill = \"#2E9598\") +\n  geom_bar_interactive(data = subset(trellis9_filter, \n                         Sex == \"Females\"), \n                       aes(x = AG, \n                           y = sum_pop, \n                           fill = PA,\n                           tooltip =  paste0(\"Sex= \", Sex,\n  \"\\n Age Group= \", AG,\n  \"\\n Population= \", sum_pop)), \n                       stat = \"identity\", \n                       fill = \"#EC1B4B\") +\n  coord_flip() +\n  facet_wrap(.~ PA,\n             drop = FALSE, \n             ncol = 3,\n             scales = \"fixed\")+\n  scale_y_continuous(limits = c(-13000, 13000),\n                     breaks = seq(-20000, 20000, 5000), \n                     labels = paste0(\n                       as.character(\n                         c(seq(200, 0, -50), \n                           seq(50, 200, 50))),\n                       \"k\"), \n                     expand = expansion(mult = c(0, .04)))+\n  labs (y = \"Population\", \n        x = \"Age Group\",\n        fill = \"Gender\",\n        title = \"Singapore Population Pyramid 2022\",\n        subtitle = \"Distribution of gender and age groups from Most Populated Planning Areas\",\n        caption = \"Data Source : Singstat.gov.sg, June 2022\") +\n  theme_bw() +\n  theme(plot.title = element_text(size = 36, \n                                  colour = \"#424242\",\n                                  face = \"bold\",\n                                  hjust = 0.5),\n        plot.subtitle = element_text(size = 28,\n                                     colour = \"#424242\",\n                                     hjust = 0.5),\n        plot.caption = element_text(size = 24,\n                                    colour = \"#424242\",\n                                    hjust = 0),\n        strip.text = element_text(size = 24,\n                                  colour = \"#424242\"),\n        strip.background = element_blank(),\n\n        axis.ticks = element_line(colour = \"#424242\",\n                                  linewidth = 0.5),\n        axis.ticks.x = element_line(colour = \"#424242\",\n                                  linewidth = 0.5),,\n        axis.title.y = element_text(angle = 0, \n                                    size = 24, \n                                    colour = \"#424242\",\n                                    vjust = 1.025,\n                                    hjust = 0.7,\n                                    margin = margin(r = -90, l = 90)),\n        axis.title.x = element_text(size = 24, \n                                    colour = \"#424242\"),\n        axis.text.x = element_text(size = 20,\n                                   colour = \"#424242\"),\n        axis.text.y = element_text(size = 20,\n                                   colour = \"#424242\"),\n        legend.position = \"bottom\",\n        legend.justification = \"left\",\n        legend.text = element_text(size = 24,\n                                   colour = \"#424242\"),\n        legend.title = element_text(size = 24, \n                                    colour = \"#424242\"),\n        panel.grid.major = element_line(linewidth = rel(0.5)),\n        panel.grid.major.x = element_line(linewidth = rel(0.5)),\n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#ffffff\"),\n        legend.background = element_rect(fill = \"#ffffff\"),\n        legend.margin = margin(t = -10),\n        panel.border = element_rect(colour = \"#424242\",\n                                    linewidth = 0.3)) \n\ngirafe(\n  ggobj = PA_Pyr,\n  width_svg = 24,\n  height_svg = 36*0.618\n)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-home_Ex04.html",
    "title": "Data Visualization Makeover 04",
    "section": "",
    "text": "The objective is to uncover the impact of COVID-19 as well as the global economic and political dynamic in 2022 on Singapore bi-lateral trade (i.e. Import, Export and Trade Balance) by using appropriate analytical visualisation techniques to enhance user and data discovery experiences.\nThe visualization is created using the Merchandise Trade provided by Department of Statistics, Singapore (DOS)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04.html#getting-started---data-loading-and-processing",
    "href": "Take-home_Ex/Take-home_Ex04.html#getting-started---data-loading-and-processing",
    "title": "Data Visualization Makeover 04",
    "section": "Getting Started - Data Loading and Processing",
    "text": "Getting Started - Data Loading and Processing\n\nInstalling and loading the required libraries\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table, readxl, lubridate, stringr, dplyr, gganimate, transformr, patchwork, countrycode)\n\n\n\nImporting Data\nThis code chunk is to import the data from Merchandise Trade Excel File. The following sheets are within the file:\n\nT1 = Import Data\nT2 = Export Data\n\nThe data shows the import export relationship between Singapore and the other nations in terms of Million Dollar or Thousand Dollar\n\n\n\n\n\n\nData Structure\n\n\n\nThe Merchandise Trade data set is labeled with Thousand Dollars and Million Dollars. Further examination shows the following:\nMillion Dollars - Continent:\n\nListed under this category are continental data and values, as such are the summation of nations within these continents.\nThe summation of this continents (except for European Union as it is part of Europe) is = Total Merchandise Exports\n\nThousand Dollars - Nations:\n\nNation specific data and values\n\n\n\n\nimport_continent <- read_excel(\"data/Merchandise_Trade.xlsx\", \n                          sheet = \"T1\",\n                          range = cell_rows(10:16))%>%\n  select(`Data Series`, contains(c(\"2019\",\"2020\", \"2021\", \"2022\"))) %>%\n  slice(-1) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nimport_continent$Country <- str_replace_all(import_continent$Country, \"\\\\s*\\\\(.*?\\\\)\", \"\")\n\nimport_continent\n\n# A tibble: 5 × 49\n  Country `2019 Dec` `2019 Nov` 2019 O…¹ 2019 …² 2019 …³ 2019 …⁴ 2019 …⁵ 2019 …⁶\n  <chr>        <dbl>      <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 America      5686.      6275.    5754.   5633.   6129.   5986.   5876.   5797.\n2 Asia        27689.     27905    28378.  26350.  26672.  28473.  26052.  27541 \n3 Europe       6315.      6827.    6625.   6310.   6534.   6325.   6055.   7987.\n4 Oceania      1369.       841.     942.    867.   1015.    815.    504.    889.\n5 Africa        521.       642      583.    290.    649.    430     493.    422.\n# … with 40 more variables: `2019 Apr` <dbl>, `2019 Mar` <dbl>,\n#   `2019 Feb` <dbl>, `2019 Jan` <dbl>, `2020 Dec` <dbl>, `2020 Nov` <dbl>,\n#   `2020 Oct` <dbl>, `2020 Sep` <dbl>, `2020 Aug` <dbl>, `2020 Jul` <dbl>,\n#   `2020 Jun` <dbl>, `2020 May` <dbl>, `2020 Apr` <dbl>, `2020 Mar` <dbl>,\n#   `2020 Feb` <dbl>, `2020 Jan` <dbl>, `2021 Dec` <dbl>, `2021 Nov` <dbl>,\n#   `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>, `2021 Jul` <dbl>,\n#   `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>, `2021 Mar` <dbl>, …\n\n\n\nexport_continent <- read_excel(\"data/Merchandise_Trade.xlsx\", \n                          sheet = \"T2\",\n                          range = cell_rows(10:16))%>%\n  select(`Data Series`, contains(c(\"2019\",\"2020\", \"2021\", \"2022\"))) %>%\n  slice(-1) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nexport_continent$Country <- str_replace_all(export_continent$Country, \"\\\\s*\\\\(.*?\\\\)\", \"\")\n\nexport_continent\n\n# A tibble: 5 × 49\n  Country `2019 Dec` `2019 Nov` 2019 O…¹ 2019 …² 2019 …³ 2019 …⁴ 2019 …⁵ 2019 …⁶\n  <chr>        <dbl>      <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 America      4614.      4822.    4938.   4754.   4838.   5209.   4990.   5809.\n2 Asia        34177      34253.   33530.  32056.  33370.  32193.  29552.  32512.\n3 Europe       3851       4173.    5163.   4007.   4278.   5232.   3891.   5480.\n4 Oceania      1918.      2078.    2591.   2113.   2046    2022.   2118.   2070.\n5 Africa        504.       432.     607.    563.    626.    735.    874.    761.\n# … with 40 more variables: `2019 Apr` <dbl>, `2019 Mar` <dbl>,\n#   `2019 Feb` <dbl>, `2019 Jan` <dbl>, `2020 Dec` <dbl>, `2020 Nov` <dbl>,\n#   `2020 Oct` <dbl>, `2020 Sep` <dbl>, `2020 Aug` <dbl>, `2020 Jul` <dbl>,\n#   `2020 Jun` <dbl>, `2020 May` <dbl>, `2020 Apr` <dbl>, `2020 Mar` <dbl>,\n#   `2020 Feb` <dbl>, `2020 Jan` <dbl>, `2021 Dec` <dbl>, `2021 Nov` <dbl>,\n#   `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>, `2021 Jul` <dbl>,\n#   `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>, `2021 Mar` <dbl>, …\n\n\n\nimport_nation <- read_excel(\"data/Merchandise_Trade.xlsx\", \n                          sheet = \"T1\",\n                          range = cell_rows(10:129))%>%\n  select(`Data Series`, contains(c(\"2019\",\"2020\", \"2021\", \"2022\"))) %>%\n  slice(-c(1:7))%>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nimport_nation$Country <- str_replace_all(import_nation$Country, \"\\\\s*\\\\(.*?\\\\)\", \"\")\n\nimport_nation\n\n# A tibble: 112 × 49\n   Country       2019 …¹ 2019 …² 2019 …³ 2019 …⁴ 2019 …⁵ 2019 …⁶ 2019 …⁷ 2019 …⁸\n   <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Belgium        148564  112197  148895  109280  110542  140243  154637  220417\n 2 Denmark         44062   53664  112559   59067   57022   53531   41769   89820\n 3 France        1305861 1607039 1539927 1553172 1384504 1377160 1247644 1692436\n 4 Germany, Fed… 1090801 1076037 1090588 1084790 1141855 1194530 1016793 1201604\n 5 Greece          12161   14507    9397   12033   11920   12095   27007   12964\n 6 Ireland         93080  111909   91189   72531   76235   93976   75391   79185\n 7 Italy          547815  544113  499738  350214  451463  486021  420572  479798\n 8 Luxembourg       2205   70742    4511    3546    3438    7249    9804    5269\n 9 Netherlands    243929  382026  248639  262842  496961  298550  270901  510772\n10 United Kingd… 1122876 1057533 1028921  961614 1044665  881698  852706  977237\n# … with 102 more rows, 40 more variables: `2019 Apr` <dbl>, `2019 Mar` <dbl>,\n#   `2019 Feb` <dbl>, `2019 Jan` <dbl>, `2020 Dec` <dbl>, `2020 Nov` <dbl>,\n#   `2020 Oct` <dbl>, `2020 Sep` <dbl>, `2020 Aug` <dbl>, `2020 Jul` <dbl>,\n#   `2020 Jun` <dbl>, `2020 May` <dbl>, `2020 Apr` <dbl>, `2020 Mar` <dbl>,\n#   `2020 Feb` <dbl>, `2020 Jan` <dbl>, `2021 Dec` <dbl>, `2021 Nov` <dbl>,\n#   `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>, `2021 Jul` <dbl>,\n#   `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>, `2021 Mar` <dbl>, …\n\n\n\nexport_nation <- read_excel(\"data/Merchandise_Trade.xlsx\", \n                          sheet = \"T2\",\n                          range = cell_rows(10:101))%>%\n  select(`Data Series`, contains(c(\"2019\",\"2020\", \"2021\", \"2022\"))) %>%\n  slice(-c(1:7)) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nexport_nation$Country <- str_replace_all(export_nation$Country, \"\\\\s*\\\\(.*?\\\\)\", \"\")\n\nexport_nation\n\n# A tibble: 84 × 49\n   Country       2019 …¹ 2019 …² 2019 …³ 2019 …⁴ 2019 …⁵ 2019 …⁶ 2019 …⁷ 2019 …⁸\n   <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Belgium        498029  553449  635001  463503  338818  389853  318325 1380735\n 2 Denmark         13039   11415   15446   12465   19571   21957   19587   27991\n 3 France         415758  435599  429136  438494  429193  410138  360330  577736\n 4 Germany, Fed…  601244  581154  718934  615005  637776  665181  596595  681759\n 5 Greece          52483   89984  103260   70956   97643   99937  108931   99698\n 6 Ireland         51855   37105   29955   18348   22930   48834   56440   46114\n 7 Italy           60013   63034   75656   99466   75998   79456   76213  111059\n 8 Luxembourg      12166   11691   10664    8097   15148   19069   13156   13103\n 9 Netherlands    924561 1085006 1014106  761725  866614 1108801  934829 1110456\n10 United Kingd…  371352  426137  805061  398734  683087  695876  351668  517108\n# … with 74 more rows, 40 more variables: `2019 Apr` <dbl>, `2019 Mar` <dbl>,\n#   `2019 Feb` <dbl>, `2019 Jan` <dbl>, `2020 Dec` <dbl>, `2020 Nov` <dbl>,\n#   `2020 Oct` <dbl>, `2020 Sep` <dbl>, `2020 Aug` <dbl>, `2020 Jul` <dbl>,\n#   `2020 Jun` <dbl>, `2020 May` <dbl>, `2020 Apr` <dbl>, `2020 Mar` <dbl>,\n#   `2020 Feb` <dbl>, `2020 Jan` <dbl>, `2021 Dec` <dbl>, `2021 Nov` <dbl>,\n#   `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>, `2021 Jul` <dbl>,\n#   `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>, `2021 Mar` <dbl>, …\n\n\n\n\nExploring and Cleaning the Data\n\nPivoting Dataset\nThis section ensures that the datetime column labels are represented correctly. The dataset must be pivoted to reflect that.\n\nimports_C_pivot <- import_continent %>%\n  pivot_longer(\n    cols = !\"Country\",\n    names_to = \"Month-Year\",\n    values_to = \"Amount\",\n    values_drop_na = TRUE\n  )\n\nimports_C_pivot\n\n# A tibble: 240 × 3\n   Country `Month-Year` Amount\n   <chr>   <chr>         <dbl>\n 1 America 2019 Dec      5686.\n 2 America 2019 Nov      6275.\n 3 America 2019 Oct      5754.\n 4 America 2019 Sep      5633.\n 5 America 2019 Aug      6129.\n 6 America 2019 Jul      5986.\n 7 America 2019 Jun      5876.\n 8 America 2019 May      5797.\n 9 America 2019 Apr      6128 \n10 America 2019 Mar      5529.\n# … with 230 more rows\n\n\n\nimports_N_pivot <- import_nation %>%\n  pivot_longer(\n    cols = !\"Country\",\n    names_to = \"Month-Year\",\n    values_to = \"Amount\",\n    values_drop_na = TRUE\n  )\n\nimports_N_pivot\n\n# A tibble: 5,376 × 3\n   Country `Month-Year` Amount\n   <chr>   <chr>         <dbl>\n 1 Belgium 2019 Dec     148564\n 2 Belgium 2019 Nov     112197\n 3 Belgium 2019 Oct     148895\n 4 Belgium 2019 Sep     109280\n 5 Belgium 2019 Aug     110542\n 6 Belgium 2019 Jul     140243\n 7 Belgium 2019 Jun     154637\n 8 Belgium 2019 May     220417\n 9 Belgium 2019 Apr     134313\n10 Belgium 2019 Mar     222413\n# … with 5,366 more rows\n\n\n\nexports_C_pivot <- export_continent %>%\n  pivot_longer(\n    cols = !\"Country\",\n    names_to = \"Month-Year\",\n    values_to = \"Amount\",\n    values_drop_na = TRUE\n  )\n\nexports_C_pivot\n\n# A tibble: 240 × 3\n   Country `Month-Year` Amount\n   <chr>   <chr>         <dbl>\n 1 America 2019 Dec      4614.\n 2 America 2019 Nov      4822.\n 3 America 2019 Oct      4938.\n 4 America 2019 Sep      4754.\n 5 America 2019 Aug      4838.\n 6 America 2019 Jul      5209.\n 7 America 2019 Jun      4990.\n 8 America 2019 May      5809.\n 9 America 2019 Apr      5024.\n10 America 2019 Mar      5281.\n# … with 230 more rows\n\n\n\nexports_N_pivot <- export_nation %>%\n  pivot_longer(\n    cols = !\"Country\",\n    names_to = \"Month-Year\",\n    values_to = \"Amount\",\n    values_drop_na = TRUE\n  )\n\nexports_N_pivot\n\n# A tibble: 4,032 × 3\n   Country `Month-Year`  Amount\n   <chr>   <chr>          <dbl>\n 1 Belgium 2019 Dec      498029\n 2 Belgium 2019 Nov      553449\n 3 Belgium 2019 Oct      635001\n 4 Belgium 2019 Sep      463503\n 5 Belgium 2019 Aug      338818\n 6 Belgium 2019 Jul      389853\n 7 Belgium 2019 Jun      318325\n 8 Belgium 2019 May     1380735\n 9 Belgium 2019 Apr      277437\n10 Belgium 2019 Mar      274500\n# … with 4,022 more rows\n\n\n\n\nOrganizing Month-Year\nThis Section converts the “Month-Year” column to datetime.\n\nimports_C_pivot$`Month-Year` <- as.Date(paste(imports_C_pivot$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\nimports_C_pivot\n\n# A tibble: 240 × 3\n   Country `Month-Year` Amount\n   <chr>   <date>        <dbl>\n 1 America 2019-12-01    5686.\n 2 America 2019-11-01    6275.\n 3 America 2019-10-01    5754.\n 4 America 2019-09-01    5633.\n 5 America 2019-08-01    6129.\n 6 America 2019-07-01    5986.\n 7 America 2019-06-01    5876.\n 8 America 2019-05-01    5797.\n 9 America 2019-04-01    6128 \n10 America 2019-03-01    5529.\n# … with 230 more rows\n\n\n\nimports_N_pivot$`Month-Year` <- as.Date(paste(imports_N_pivot$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\nimports_N_pivot\n\n# A tibble: 5,376 × 3\n   Country `Month-Year` Amount\n   <chr>   <date>        <dbl>\n 1 Belgium 2019-12-01   148564\n 2 Belgium 2019-11-01   112197\n 3 Belgium 2019-10-01   148895\n 4 Belgium 2019-09-01   109280\n 5 Belgium 2019-08-01   110542\n 6 Belgium 2019-07-01   140243\n 7 Belgium 2019-06-01   154637\n 8 Belgium 2019-05-01   220417\n 9 Belgium 2019-04-01   134313\n10 Belgium 2019-03-01   222413\n# … with 5,366 more rows\n\n\n\nexports_C_pivot$`Month-Year` <- as.Date(paste(exports_C_pivot$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\nexports_C_pivot\n\n# A tibble: 240 × 3\n   Country `Month-Year` Amount\n   <chr>   <date>        <dbl>\n 1 America 2019-12-01    4614.\n 2 America 2019-11-01    4822.\n 3 America 2019-10-01    4938.\n 4 America 2019-09-01    4754.\n 5 America 2019-08-01    4838.\n 6 America 2019-07-01    5209.\n 7 America 2019-06-01    4990.\n 8 America 2019-05-01    5809.\n 9 America 2019-04-01    5024.\n10 America 2019-03-01    5281.\n# … with 230 more rows\n\n\n\nexports_N_pivot$`Month-Year` <- as.Date(paste(exports_N_pivot$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\nexports_N_pivot\n\n# A tibble: 4,032 × 3\n   Country `Month-Year`  Amount\n   <chr>   <date>         <dbl>\n 1 Belgium 2019-12-01    498029\n 2 Belgium 2019-11-01    553449\n 3 Belgium 2019-10-01    635001\n 4 Belgium 2019-09-01    463503\n 5 Belgium 2019-08-01    338818\n 6 Belgium 2019-07-01    389853\n 7 Belgium 2019-06-01    318325\n 8 Belgium 2019-05-01   1380735\n 9 Belgium 2019-04-01    277437\n10 Belgium 2019-03-01    274500\n# … with 4,022 more rows\n\n\n\n\nMerge Dataset for both Continental and National Values\nThis section creates the consolidated dataset for both continental and national datasets with the following improvements:\n\nNet Trade = Exports - Imports\nOmit of all NA values\n\n\ncontinent <- merge(x=imports_C_pivot , y=exports_C_pivot, by= c(\"Country\", \"Month-Year\"), all.x = TRUE, all.y = TRUE)\n\nNet_Trade = continent$Amount.y - continent$Amount.x\n\ncontinent$Net_Trade <- Net_Trade\n\nna.omit(continent) %>%\n  rename(\n    Continent = Country,\n    Date = `Month-Year`,\n    Imports = Amount.x,\n    Exports = Amount.y\n  )\n\n\nnation <- merge(x=imports_N_pivot , y=exports_N_pivot, by= c(\"Country\", \"Month-Year\"), all.x = TRUE, all.y = TRUE)\n\nNet_Trade = nation$Amount.y - nation$Amount.x\n\nnation$Net_Trade <- Net_Trade\n\nna.omit(nation) %>%\n  rename(\n    Date = `Month-Year`,\n    Imports = Amount.x,\n    Exports = Amount.y\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04.html#continental-trade-analysis---visual-exploration",
    "href": "Take-home_Ex/Take-home_Ex04.html#continental-trade-analysis---visual-exploration",
    "title": "Data Visualization Makeover 04",
    "section": "Continental Trade Analysis - Visual Exploration",
    "text": "Continental Trade Analysis - Visual Exploration\nThis section explores macro trade relationship of Singapore on the continental level.\n\nLine Graph Visualization for Imports and Exports\n\n\nCode\ncontinent_import <- ggplot(continent,\n       aes(x = `Month-Year`, y = Amount.x, color = Country)) +\n  geom_line()+\n  labs (x = \"Date\",\n        y = \"Import in Million Dollars\",\n        fill = \"Continent\",\n        title = \"Import in Million Dollars by Continent\") +\n  scale_x_date(date_labels = \"%b-%y\")+\n  theme_bw() \n\ncontinent_export <- ggplot(continent,\n       aes(x = `Month-Year`, y = Amount.y, color = Country)) +\n  geom_line()+\n  labs (x = \"Date\",\n        y = \"Export in Million Dollars\",\n        fill = \"Continent\",\n        title = \"Export in Million Dollars by Continent\") +\n  scale_x_date(date_labels = \"%b-%y\")+\n  theme_bw() \n\n\n\ncontinent_import \n\n\n\n\n\ncontinent_export\n\n\n\n\nA simple beginning in visual analysis is a line chart to see the time series impact on both imports and exports. Here is the following insights:\n\nAsia remains as the highest import export partner for Singapore. Consistently, from 2019 to 2022, Asia remains as the top import export partner of Singapore due to proximity. America and Europe follows as close 2nd and 3rd.\nCOVID 19 had none to minimal impact to Singapore’s Macro Trade Relationship. Year 2019 and 2020 - 2021 show no distinct drop in import and export amount (drop = significant change in numbers as minimal up and downs are expected).\n\n\n\nAnimated Time Series Scatter Plot\n\n\nCode\nggplot(continent, aes(x = Amount.x, y = Amount.y, size = Net_Trade, color = Country)) + \n  geom_point(show.legend = FALSE, alpha = 0.7) +\n  scale_color_viridis_d() +\n  scale_size(range = c(2, 12)) +\n  transition_time(continent$`Month-Year`) +\n  labs(title = \"Animated Scatterplot per Continent per Year: {frame_time}\", x = \"Imports\", y = \"Exports\", fill = \"Continent\") +\n  theme(legend.position = \"bottom\") + \n  theme_bw() + \n  facet_wrap(~Country)\n\n\n\n\n\nThe Animated Scatter plot refocuses that Asia is the highest import export trade partner for Singapore, though there is an additional insight\n\nAsia remains as the highest import export partner and moving to 2022, both import and export increases as it reaches 2022 as the other continent remained constant.\nEurope shows periods of fluctuations in the index (export/import) as compared to the more stable continents.\n\n\n\nNext Step\n\nVisualize and Analyze nations within Asia and Europe separately to check and describe the time series progress of the import export trade amount."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04.html#asian-trade-analysis---visual-exploration",
    "href": "Take-home_Ex/Take-home_Ex04.html#asian-trade-analysis---visual-exploration",
    "title": "Data Visualization Makeover 04",
    "section": "Asian Trade Analysis - Visual Exploration",
    "text": "Asian Trade Analysis - Visual Exploration\nThis section explores the macro economic trade relation of Singapore to its Asian Trade partners.\n\nIdentifying Country - Continent Labels\nThis section adds a continent label to the nation database identifying which continent a country belongs to.\n\n\n\n\n\n\ncountrycode() Package\n\n\n\nYou can use the countrycode() package to identify the continent and region of the country\n\ncontinent = Continent as defined in the World Bank Development Indicators\nun.regionsub.name: United Nations sub-region name\n\n\n\n\nnation$Continent <- countrycode(sourcevar = nation$Country,\n                            origin = \"country.name\",\n                            destination = \"continent\")\n\nWarning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Cocos Islands, Commonwealth Of Independent States, French Southern Territories, Micronesia, Other Countries In America, Other Countries In Oceania, Yemen Democratic\n\nnation$Continent[nation$Country == \"Other Country\"] <- \"Unknown\"\n\nnation$Region <- countrycode(sourcevar = nation$Country,\n                            origin = \"country.name\",\n                            destination = \"un.regionsub.name\")\n\nWarning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Commonwealth Of Independent States, Micronesia, Netherlands Antilles, Other Countries In America, Other Countries In Oceania, Taiwan, Yemen Democratic\n\nnation$Region[nation$Country == \"Other Country\"] <- \"Unknown\"\n\nnation <- na.omit(nation)\n\nnation\n\n\nnation_asia <- nation %>%\n  filter(str_detect(Continent, \"Asia\")) %>%\n  select(-(Continent))\n\nnation_asia\n\n\nnation_eu <- nation %>%\n  filter(str_detect(Continent, \"Europe\")) %>%\n  select(-(Continent))\n\nnation_eu\n\n\n\nAsia Sub Region Visualization\n\n\nCode\nggplot(nation_asia, aes(x = Amount.x, y = Amount.y, size = Net_Trade, color = Country)) + \n  geom_point(show.legend = FALSE, alpha = 0.7) +\n  scale_color_viridis_d() +\n  scale_size(range = c(2, 12)) +\n  transition_time(nation_asia$`Month-Year`) +\n  labs(title = \"Animated Scatterplot per Asian Region per Year: {frame_time}\", x = \"Imports\", y = \"Exports\", fill = \"Region\") +\n  theme(legend.position = \"bottom\") + \n  theme_bw() + \n  facet_wrap(~Region)\n\n\n\n\n\nBased on the Animated Scatter Plot, the following insights are:\n\nEast Asia shows high import and export contribution. It is noted that there is a nation that have seen fluctuations in positioning in 2021 - 2022\nSoutheast Asia shows a more stable amount, thoigh there is a nation with more fluctuating position\n\n\n\nEast Asian Import Export Visualization\nThis section shows the trade relation in East Asia.\n\n\nCode\nnation_asia_ea <- nation_asia %>%\n  filter(str_detect(Region, \"Eastern Asia\")) %>%\n  select(-(Region))\n\n\nasia_ea_import <- ggplot(nation_asia_ea,\n       aes(x = `Month-Year`, y = Amount.x, color = Country)) +\n  geom_line()+\n  labs (x = \"Date\",\n        y = \"Import in Thousand Dollars\",\n        fill = \"Country\",\n        title = \"Import in Thousand Dollars by east Asian Country\") +\n  scale_x_date(date_labels = \"%b-%y\")+\n  theme_bw() \n\nasia_ea_export <- ggplot(nation_asia_ea,\n       aes(x = `Month-Year`, y = Amount.y, color = Country)) +\n  geom_line()+\n  labs (x = \"Date\",\n        y = \"Export in Thousand Dollars\",\n        fill = \"Country\",\n        title = \"Export in Thousand Dollars by East Asian Country\") +\n  scale_x_date(date_labels = \"%b-%y\")+\n  theme_bw() \n\n\n\n\nCode\nasia_ea_import \n\n\n\n\n\n\n\nCode\nasia_ea_export\n\n\n\n\n\n\n\nCode\nggplot(nation_asia_ea,\n  aes(x = `Month-Year`, y = Amount.x, color = Country)) +\n  geom_line() +\n  scale_color_viridis_d() +\n  labs(x = \"Date\",\n       y = \"Net Trade\",\n       fill = \"Country\",\n       title = \"Net Trade by East Asian Country\") +\n  theme(legend.position = \"top\") +\n  theme_bw() +\n  geom_point() +\n  transition_reveal(nation_asia_ea$`Month-Year`)\n\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\nInsights on the East Asian Region\nSingapore has the highest Import and Export Trade relationship with Mainland China. This is due to being supported by the updated bilateral agreement made in 2019. Given Singapore is one of the biggest trade hubs and China as a manufacturing hub, Merchandise Trade between these nations are part of the supply chain such as electronic equipment, machinery and minerals.\nSingapore - China Net Trade is higher in favor of Singapore (higher export). This is due to Singapore exporting more variety of goods from consumer to manufacturing requirements to China.\n\n\n\n\n\n\nSingapore - China Trade Relationship\n\n\n\nSINGAPORE-CHINA\nIn 2020, Singapore exported $42.9B to China. The main products that Singapore exported to China are Integrated Circuits ($10.6B), Ethylene Polymers ($2.25B), and Machinery Having Individual Functions ($1.86B).\nCHINA-SINGAPORE\nIn 2020, China exported $54B to Singapore. The main products that China exported to Singapore were Integrated Circuits ($5.55B), Refined Petroleum ($4.88B), and Broadcasting Equipment ($3.97B). South East Asian Import Export Visualization\n\n\nSingapore also have a high export low import relationship with Hong Kong. This is due to Hong Kong primarily acting as Financial Services Sector with minimal merchandise export on its own and rely on imports for consumer goods.\n\n\n\nSouth East Asian Import Export Visualization\nThis section shows the trade relation in South East Asia.\n\n\nCode\nnation_asia_sea <- nation_asia %>%\n  filter(str_detect(Region, \"South-eastern Asia\")) %>%\n  select(-(Region))\n\n\nasia_sea_import <- ggplot(nation_asia_sea,\n       aes(x = `Month-Year`, y = Amount.x, color = Country)) +\n  geom_line()+\n  labs (x = \"Date\",\n        y = \"Import in Thousand Dollars\",\n        fill = \"Country\",\n        title = \"Import in Thousand Dollars by Southeast Asian Country\") +\n  scale_x_date(date_labels = \"%b-%y\")+\n  theme_bw() \n\nasia_sea_export <- ggplot(nation_asia_sea,\n       aes(x = `Month-Year`, y = Amount.y, color = Country)) +\n  geom_line()+\n  labs (x = \"Date\",\n        y = \"Export in Thousand Dollars\",\n        fill = \"Country\",\n        title = \"Export in Thousand Dollars by Southeast Asian Country\") +\n  scale_x_date(date_labels = \"%b-%y\")+\n  theme_bw() \n\n\n\nasia_sea_import\n\n\n\n\n\nasia_sea_export\n\n\n\n\n\n\nCode\nggplot(nation_asia_sea,\n  aes(x = `Month-Year`, y = Amount.x, color = Country)) +\n  geom_line() +\n  scale_color_viridis_d() +\n  labs(x = \"Date\",\n       y = \"Net Trade\",\n       fill = \"Country\",\n       title = \"Net Trade by Southeast Asian Country\") +\n  theme(legend.position = \"top\") +\n  theme_bw() +\n  geom_point() +\n  transition_reveal(nation_asia_sea$`Month-Year`)\n\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\nInsights on the South East Asian Region\nMalaysia is the top import and export trade partner with Singapore. This is due to proximity between the nations. Furthermore. Net Trade has higher export with Singapore\n\n\n\n\n\n\nSingapore - Malaysia Trade Relationship\n\n\n\nMALAYSIA-SINGAPORE\nIn 2020, Malaysia exported $36.5B to Singapore. The main products that Malaysia exported to Singapore are Integrated Circuits ($11.1B), Refined Petroleum ($5.63B), and Office Machine Parts ($1.24B).\nSINGAPORE-MALAYSIA\nIn 2020, Singapore exported $22.9B to Malaysia. The main products that Singapore exported to Malaysia were Integrated Circuits ($5.7B), Refined Petroleum ($4.33B), and Gold ($894M).\n\n\nSingapore has a high export to Indonesia due to the high amounts of Gold and manufacturing parts sent over. Similar to nations that Singapore does bilateral trades of similar good, higher exports are primarily due to higher variety of goods."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04.html#european-trade-analysis---visual-exploration",
    "href": "Take-home_Ex/Take-home_Ex04.html#european-trade-analysis---visual-exploration",
    "title": "Data Visualization Makeover 04",
    "section": "European Trade Analysis - Visual Exploration",
    "text": "European Trade Analysis - Visual Exploration\nThis section explores the macro economic trade relation of Singapore to its European Trade partners.\n\nEurope Sub Region Visualization\n\n\nCode\nggplot(nation_eu, aes(x = Amount.x, y = Amount.y, size = Net_Trade, color = Country)) + \n  geom_point(show.legend = FALSE, alpha = 0.7) +\n  scale_color_viridis_d() +\n  scale_size(range = c(2, 12)) +\n  transition_time(nation_eu$`Month-Year`) +\n  labs(title = \"Animated Scatterplot per European Region per Year: {frame_time}\", x = \"Imports\", y = \"Exports\", fill = \"Region\") +\n  theme(legend.position = \"bottom\") + \n  theme_bw() + \n  facet_wrap(~Region)\n\n\n\n\n\nBased on the animated scatter plot, Western European nations have more dynamic trade relations as compared to others\n\n\nWestern European Import Export Visualization\nThis section shows the trade relation in West Europe.\n\n\nCode\nnation_eu_west <- nation_eu %>%\n  filter(str_detect(Region, \"Western Europe\")) %>%\n  select(-(Region))\n\n\neu_west_import <- ggplot(nation_eu_west,\n       aes(x = `Month-Year`, y = Amount.x, color = Country)) +\n  geom_line()+\n  labs (x = \"Date\",\n        y = \"Import in Thousand Dollars\",\n        fill = \"Country\",\n        title = \"Import in Thousand Dollars by West Euro Country\") +\n  scale_x_date(date_labels = \"%b-%y\")+\n  theme_bw() \n\neu_west_export <- ggplot(nation_eu_west,\n       aes(x = `Month-Year`, y = Amount.y, color = Country)) +\n  geom_line()+\n  labs (x = \"Date\",\n        y = \"Export in Thousand Dollars\",\n        fill = \"Country\",\n        title = \"Export in Thousand Dollars by West Euro Country\") +\n  scale_x_date(date_labels = \"%b-%y\")+\n  theme_bw() \n\n\n\neu_west_import\n\n\n\n\n\neu_west_import\n\n\n\n\n\n\nCode\nggplot(nation_eu_west,\n  aes(x = `Month-Year`, y = Amount.x, color = Country)) +\n  geom_line() +\n  scale_color_viridis_d() +\n  labs(x = \"Date\",\n       y = \"Net Trade\",\n       fill = \"Country\",\n       title = \"Net Trade by West Euro Country\") +\n  theme(legend.position = \"top\") +\n  theme_bw() +\n  geom_point() +\n  transition_reveal(nation_eu_west$`Month-Year`)\n\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\nInsights on the Western European Region\nAs compared to Asian Trade partners, Western Europe experience high levels of fluctuation, presenting no clear front runner in trade relations with Singapore. This may be due to West Europe being majority part of the European Union and its ‘Single Market’. The ‘Single Market’ allows companies in Europe to operate in all nation states and be able to cooperatively export their products as a block while import products outside in bulk as well."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03.html",
    "href": "In-Class_Ex/In-Class_Ex03.html",
    "title": "In-Class Exercise 03",
    "section": "",
    "text": "Two packages will be installed and loaded. They are tidyverse and ggiraph.\n\npacman::p_load(ggiraph, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03.html#importing-data",
    "href": "In-Class_Ex/In-Class_Ex03.html#importing-data",
    "title": "In-Class Exercise 03",
    "section": "Importing Data",
    "text": "Importing Data\nThis code chunk is to import the data from Exam_data.csv file to the Quarto/R page.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03.html#exploration-and-trial",
    "href": "In-Class_Ex/In-Class_Ex03.html#exploration-and-trial",
    "title": "In-Class Exercise 03",
    "section": "Exploration and Trial",
    "text": "Exploration and Trial\n\nGraphs and Visualization through ggplot2 and ggiraph\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05.html",
    "href": "In-Class_Ex/In-Class_Ex05.html",
    "title": "In-Class Exercise 05",
    "section": "",
    "text": "This is a walk through of In-Class Exercise 5"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex05.html#getting-started",
    "title": "In-Class Exercise 05",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and Launching R Packages\n\npacman::p_load(corrplot, tidyverse, ggtern, ggstatsplot, ggcorrplot, plotly, seriation, dendextend, heatmaply)\n\n\n\nImporting and Preparing The Data Set\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\nwh <- read_csv(\"data/WHData-2018.csv\")\nrow.names(wh) <- wh$Country\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05.html#building-the-correlation-matrix",
    "href": "In-Class_Ex/In-Class_Ex05.html#building-the-correlation-matrix",
    "title": "In-Class Exercise 05",
    "section": "Building the Correlation Matrix",
    "text": "Building the Correlation Matrix\n\nBuilding a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05.html#visualizing-correlation-matrix-ggcormat",
    "href": "In-Class_Ex/In-Class_Ex05.html#visualizing-correlation-matrix-ggcormat",
    "title": "In-Class Exercise 05",
    "section": "Visualizing Correlation Matrix: ggcormat()",
    "text": "Visualizing Correlation Matrix: ggcormat()\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\nNote\n\n\n\ncode cannot run due to ggcorrmat() is in conflict with ggtern(). Processed image will be presented instead.\n\n\n\n\nBuilding multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05.html#getting-started-with-corrplot",
    "href": "In-Class_Ex/In-Class_Ex05.html#getting-started-with-corrplot",
    "title": "In-Class Exercise 05",
    "section": "Getting started with corrplot",
    "text": "Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor <- cor(wine[, 1:11])\ncorrplot(wine.cor)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05.html#plotting-ternary-diagram-with-r",
    "href": "In-Class_Ex/In-Class_Ex05.html#plotting-ternary-diagram-with-r",
    "title": "In-Class Exercise 05",
    "section": "Plotting Ternary Diagram with R",
    "text": "Plotting Ternary Diagram with R\n\nPreparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\n\nPlotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\nPlotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = list(color = \"blue\",\n               title = \"Young\"), \n  baxis = list(color = \"red\", \n               title = \"Active\"), \n  caxis = list(color = \"green\", \n               title = \"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05.html#creating-interactive-heatmap",
    "href": "In-Class_Ex/In-Class_Ex05.html#creating-interactive-heatmap",
    "title": "In-Class Exercise 05",
    "section": "Creating Interactive Heatmap",
    "text": "Creating Interactive Heatmap\n\nGetting Started with Heatmaps\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\n\n\nFinishing Touches\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html",
    "href": "In-Class_Ex/In-Class_Ex10.html",
    "title": "In-Class Exercise 10",
    "section": "",
    "text": "By the end of this In-Class exercise, you will be able to:\n\nextract stock price data from financial portal such as Yahoo Finance by using tidyquant package\nplot horizon graph by using ggHoriPlot package,\nplot static and interactive stock prices line graph(s) by ggplot2 and plotly R packages,\nplot static candlestick chart by using tidyquant package,\nplot static bollinger bands by using tidyquant, and\nplot interactive candlestick chart by using ggplot2 and plotly R."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#tableau",
    "href": "In-Class_Ex/In-Class_Ex10.html#tableau",
    "title": "In-Class Exercise 10",
    "section": "Tableau",
    "text": "Tableau"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex10.html#getting-started",
    "title": "In-Class Exercise 10",
    "section": "Getting started",
    "text": "Getting started\nFor the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(lubridate, tidyquant, ggHoriPlot,\n               timetk, ggthemes, plotly, tidyverse)\n\n\ntidyverse provides a collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data. It is not a single package but a collection of modern R packages including but not limited to readr, tidyr, dplyr, ggplot, tibble, stringr, forcats and purrr.\nlubridate provides functions to work with dates and times more efficiently.\ntidyquant bringing business and financial analysis to the ‘tidyverse’. It provides a convenient wrapper to various ‘xts’, ‘zoo’, ‘quantmod’, ‘TTR’ and ‘PerformanceAnalytics’ package functions and returns the objects in the tidy ‘tibble’ format.\nggHoriPlot: A user-friendly, highly customisable R package for building horizon plots in the ‘ggplot2’ environment."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#data-extraction-with-tidyquant",
    "href": "In-Class_Ex/In-Class_Ex10.html#data-extraction-with-tidyquant",
    "title": "In-Class Exercise 10",
    "section": "Data Extraction with tidyquant",
    "text": "Data Extraction with tidyquant\ntidyquant integrates resources for collecting and analysing financial data with the tidy data infrastructure of the tidyverse, allowing for seamless interaction between each.\nIn this section, you will learn how to extract the daily stock values of a selected stocks from Yahoo Finance by using tidyquant.\nStep 1: We will import a pre-prepared company list called companySG.csv onto R. The list consists of top 45 companies by market capitalisation in Singapore. However, we just want the top 40.\n\ncompany <- read_csv(\"data/companySG.csv\")\nTop40 <- company %>% \n  slice_max(`marketcap`, n=40) %>% \n  select(symbol)\n\nStep 2: tq_get() method will be used to extract daily values of these stocks from Yahoo Finance via APIs. The time period for the data was set from 1st January 2020 to 31st March 2021. The data are specified to be returned in daily intervals.\n\nStock40_daily <- Top40 %>%\n  tq_get(get = \"stock.prices\", \n         from = \"2020-01-01\", \n         to = \"2022-03-31\") %>%\n  group_by(symbol) %>%\n  tq_transmute(select = NULL, \n               mutate_fun = to.period, \n               period  = \"days\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#plotting-a-horizon-graph",
    "href": "In-Class_Ex/In-Class_Ex10.html#plotting-a-horizon-graph",
    "title": "In-Class Exercise 10",
    "section": "Plotting a horizon graph",
    "text": "Plotting a horizon graph\nIn this section, you will learn how to plot a horizon graph by using geom_horizon() of ggHoriPlot package.\n\nStock40_daily %>% \n  ggplot() +\n  geom_horizon(aes(x = date, y=adjusted), origin = \"midpoint\", horizonscale = 6)+\n  facet_grid(symbol~.)+\n  theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand=c(0,0), date_breaks = \"1 month\", date_labels = \"%b%y\") +\n  ggtitle('Daily Adjusted Prices (Jan 2020 to Mar 2022)') \n\n\n\n\n\nHorizon graph makeover\n\nInstead of showing stock code, the stock name will be displayed.\nAdding reference lines\n\nStep 1: left_join() of dplyr package is used to append fields from company data.frame onto Stock_daily data.frame. Next select() is used to select columns 1 to 8 and 11 to 12.\n\nStock40_daily <- Stock40_daily %>%\n  left_join(company) %>%\n  select(1:8, 11:12)\n\nStep 2: geom_vline() is used to add the vertical reference lines.\n\nStock40_daily %>% \n  ggplot() +\n  geom_horizon(aes(x = date, y=adjusted), origin = \"midpoint\", horizonscale = 6)+\n  facet_grid(Name~.)+ #<<\n  geom_vline(xintercept = as.Date(\"2020-03-11\"), colour = \"grey15\", linetype = \"dashed\", size = 0.5)+ #<<\n  geom_vline(xintercept = as.Date(\"2020-12-14\"), colour = \"grey15\", linetype = \"dashed\", size = 0.5)+ #<<\n  theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"),\n        strip.text.y = element_text(size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand=c(0,0), date_breaks = \"1 month\", date_labels = \"%b%y\") +\n  ggtitle('Daily Adjusted Prices (Jan 2020 to Mar 2022)')"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#plotting-stock-price-line-graph-ggplot-methods",
    "href": "In-Class_Ex/In-Class_Ex10.html#plotting-stock-price-line-graph-ggplot-methods",
    "title": "In-Class Exercise 10",
    "section": "Plotting Stock Price Line Graph: ggplot methods",
    "text": "Plotting Stock Price Line Graph: ggplot methods\nIn the code chunk below, geom_line() of ggplot2 is used to plot the stock prices.\n\nStock40_daily %>%\n  filter(symbol == \"DBSDF\") %>%\n  ggplot(aes(x = date, y = close)) +\n    geom_line() +\n    labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\", \n         y = \"Closing Price\", x = \"\") + \n    theme_tq()"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#plotting-interactive-stock-price-line-graphs",
    "href": "In-Class_Ex/In-Class_Ex10.html#plotting-interactive-stock-price-line-graphs",
    "title": "In-Class Exercise 10",
    "section": "Plotting interactive stock price line graphs",
    "text": "Plotting interactive stock price line graphs\nIn this section, we will create interactive line graphs for four selected stocks.\nStep 1: Selecting the four stocks of interest\n\nselected_stocks <-  Stock40_daily %>%\n  filter (`symbol` == c(\"C09.SI\", \"SINGF\", \"SNGNF\", \"C52.SI\"))\n\nStep 2: Plotting the line graphs by using ggplot2 functions and ggplotly() of plotly R package\n\np <- ggplot(selected_stocks, \n            aes(x = date, y = adjusted)) + \n  scale_y_continuous() +\n  geom_line() +\n  facet_wrap(~Name, scales = \"free_y\",) +\n  theme_tq() +\n  labs(title = \"Daily stock prices of selected weak stocks\", \n       x = \"\", y = \"Adjusted Price\") + \n  theme(axis.text.x = element_text(size = 6), \n        axis.text.y = element_text(size = 6))\n\nggplotly(p)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#plotting-candlestick-chart-tidyquant-method",
    "href": "In-Class_Ex/In-Class_Ex10.html#plotting-candlestick-chart-tidyquant-method",
    "title": "In-Class Exercise 10",
    "section": "Plotting Candlestick Chart: tidyquant method",
    "text": "Plotting Candlestick Chart: tidyquant method\nIn this section, you will learn how to plot candlestick chart by using geom_candlestick() of tidyquant package.\nBefore plotting the candlesticks, the code chunk below will be used to define the end data parameter. It will be used when setting date limits throughout the examples.\n\nend <- as_date(\"2022-03-31\")\n\nNow we are ready to plot the candlesticks by using the code chunk below.\n\nStock40_daily %>%\n  filter(symbol == \"DBSDF\") %>%\n  ggplot(aes(\n    x = date, y = close)) +\n  geom_candlestick(aes(\n    open = open, high = high, \n    low = low, close = close)) +\n  geom_line(size = 0.5)+\n    coord_x_date(xlim = c(end - weeks(12), \n                          end),\n                 ylim = c(20, 35),\n                 expand = TRUE) +\n  labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\", \n       y = \"Closing Price\", x = \"\") + \n  theme_tq()\n\n\n\n\n\nPlotting candlestick chart and MA lines: tidyquant method\n\nStock40_daily %>%\n  filter(symbol == \"DBSDF\") %>%\n  ggplot(aes(\n    x = date, y = close)) +\n  geom_candlestick(aes(\n    open = open, high = high, \n    low = low, close = close)) +\n  geom_line(size = 0.5)+\n  geom_ma(color = \"darkgreen\", n = 20) +\n  geom_ma(color = \"lightgreen\", n = 5) + \n    coord_x_date(xlim = c(end - weeks(12), \n                          end),\n                 ylim = c(20, 35),\n                 expand = TRUE) +\n  labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\",\n       subtitle = \"darkgreen = 1-day MA, lightgreen = 5-day MA\",\n       y = \"Closing Price\", x = \"\") + \n  theme_tq()\n\n\n\n\nThings to learn from the code chunk:\n\ngeom_MA is used to add the moving average line. It is a wrapper function of SMA() from the TTR package."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#plotting-bollinger-bands-tidyquant-method",
    "href": "In-Class_Ex/In-Class_Ex10.html#plotting-bollinger-bands-tidyquant-method",
    "title": "In-Class Exercise 10",
    "section": "Plotting Bollinger Bands: tidyquant method",
    "text": "Plotting Bollinger Bands: tidyquant method\nIn this section, you will learn how to plot bollinger bands by using geom_bbands() of tidyquant package.\n\nStock40_daily %>%\n  filter(symbol == \"DBSDF\") %>% \n  ggplot(aes(x=date, y=close))+\n  geom_line(size=0.5)+\n  geom_bbands(aes(\n    high = high, low = low, close = close), \n    ma_fun = SMA, sd = 2, n = 20,\n    size = 0.75, color_ma = \"royalblue4\", \n    color_bands = \"red1\")+\n    coord_x_date(xlim = c(\"2020-02-01\", \n                          \"2022-03-31\"), \n                 expand = TRUE)+\n    labs(title = \"DBS Group Holdings Ltd (DBSDF) Daily Stock Price\",\n         subtitle = \"dotted red lines = bollinger bands\",\n         x = \"Date\", y =\"Price\") +\ntheme(legend.position=\"none\")\n\n\n\n\nThings you can learn from the code chunk:\n\ngeom_bbands() plots a range around a moving average typically two standard deviations up and down. The moving average functions used are specified in SMA() from the TTR package."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex10.html#plotting-interactive-candlesticks-chart-ggplot2-and-plotly-r-method",
    "href": "In-Class_Ex/In-Class_Ex10.html#plotting-interactive-candlesticks-chart-ggplot2-and-plotly-r-method",
    "title": "In-Class Exercise 10",
    "section": "Plotting Interactive Candlesticks Chart: ggplot2 and plotly R method",
    "text": "Plotting Interactive Candlesticks Chart: ggplot2 and plotly R method\nFirst, a candleStick_plot function is written as follows:\n\ncandleStick_plot<-function(symbol, from, to){\n  tq_get(symbol, from = from, to = to, warnings = FALSE) %>% \n    mutate(greenRed=ifelse(open-close>0, \"Red\", \"Green\")) %>% \n    ggplot()+\n    geom_segment(\n      aes(x = date, xend=date, y =open, yend =close, colour=greenRed), \n      size=3)+\n    theme_tq()+\n    geom_segment(\n      aes(x = date, xend=date, y =high, yend =low, colour=greenRed))+\n    scale_color_manual(values=c(\"ForestGreen\",\"Red\"))+\n    ggtitle(paste0(symbol,\" (\",from,\" - \",to,\")\"))+\n    theme(legend.position =\"none\",\n          axis.title.y = element_blank(),\n          axis.title.x=element_blank(),\n          axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1),\n          plot.title= element_text(hjust=0.5))\n}\n\nCredit: I learned this trick from RObservations #12: Making a Candlestick plot with the ggplot2 and tidyquant packages\n\np <- candleStick_plot(\"DBSDF\",\n                      from = '2022-01-01',\n                      to = today())\nggplotly(p)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04.html",
    "href": "In-Class_Ex/In-Class_Ex04.html",
    "title": "In-Class Exercise 04",
    "section": "",
    "text": "This is a walk through of In-Class Exercise 4"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04.html#getting-started---plotly-and-statistical-visualization",
    "href": "In-Class_Ex/In-Class_Ex04.html#getting-started---plotly-and-statistical-visualization",
    "title": "In-Class Exercise 04",
    "section": "Getting Started - Plotly and Statistical Visualization",
    "text": "Getting Started - Plotly and Statistical Visualization\n\nInstalling and Loading R Packages\n\npacman::p_load(plotly, DT, patchwork, crosstalk, ggstatsplot, readxl, performance, parameters, see, tidyverse)\n\n\n\nImporting Data\nThis code chunk is to import the data from Exam_data.csv file to the Quarto/R page.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\n\nWorking with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\n\nTwo-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\nSignificant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04.html#getting-started---visualizing-models",
    "href": "In-Class_Ex/In-Class_Ex04.html#getting-started---visualizing-models",
    "title": "In-Class Exercise 04",
    "section": "Getting Started - Visualizing Models",
    "text": "Getting Started - Visualizing Models\n\nInstalling and Loading R Packages\n\npacman::p_load(plotly, DT, patchwork, crosstalk, ggstatsplot, readxl, performance, parameters, see, tidyverse)\n\n\n\nImporting Data\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\n\nMultiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\nModel Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\nModel Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n <- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\nModel Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\nModel Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below performs the followings:\n\ngroup the observation by RACE,\ncomputes the count of observations, mean, standard deviation and standard error of Maths by RACE, and\nsave the output as a tibble data table called my_sum.\n\n\nmy_sum <- exam_data %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE,-mean), \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.95, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"95% confidence interval of mean maths score by race\")\n\n\n\n\n\np <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE,-mean), \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.99, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"99% confidence interval of mean maths score by race\")\n\npp <- highlight(ggplotly(p))\n\nd <- highlight_key(my_sum)\n\ncrosstalk::bscols(pp,\n                  DT::datatable(d))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06.html",
    "href": "In-Class_Ex/In-Class_Ex06.html",
    "title": "In-Class Exercise 06",
    "section": "",
    "text": "This document serves as my In-class Exercise 6 requirement.\nBeing able to look at the patterns in data over time is an important aspect of analytics, however, time-series data is often not very visually friendly. For this week’s exercise, we explore ways of graphing time, visualization of time-series patterns, and adding interactive techniques."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06.html#tableau",
    "href": "In-Class_Ex/In-Class_Ex06.html#tableau",
    "title": "In-Class Exercise 06",
    "section": "Tableau",
    "text": "Tableau\n\nTime Series Arrival Dashboard\nThis is a time series dashboard showing the arrivals per country with 2 time series charts\n\nYearly arrivals\nMonthly arrivals per year\n\n\n                   \n\n\n\n\n\n\nHtml\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor unclean datasets such as the arrivals data which each nation arrival is listed per column, it is best to transpose and summarize all the nation columns to 2 columns which lists the nation and aggregated arrivals per date.\n\n\n\n\nCalendar Heatmap\n\n                   \n\n\nSlope Graph\n\n                   \n\n\nAnimated Time Series Scatter Plot"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07.html",
    "href": "In-Class_Ex/In-Class_Ex07.html",
    "title": "In-Class Exercise 07",
    "section": "",
    "text": "This document serves as my In-class Exercise 7 requirement.\nIn this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07.html#tableau",
    "href": "In-Class_Ex/In-Class_Ex07.html#tableau",
    "title": "In-Class Exercise 07",
    "section": "Tableau",
    "text": "Tableau\n\nProportional Symbol Map - Branch Shop Data\n\n                   \nTo be able to render the distinct coloration, a new calculated field is to be created named “Channel” with the following equation (see image below)\n\n\n\n\n\n\n\nProportional Symbol Map - Residential Housing Data\n\n                   \nAggregreate all data found in separate sheets, highlight all datasets needed in the list and drag to the dashboards to be joined to a single dataset.\n\n\n\n\n\n\n\nProportional Symbol Map - Population Data\n\n                   \nWhen using two distinct datasets with different format of the same column variable, ensure to convert one of the relationships to match and join both datasets."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex09.html",
    "href": "In-Class_Ex/In-Class_Ex09.html",
    "title": "In-Class Exercise 09",
    "section": "",
    "text": "By the end of this In-Class exercise, you will be able to:\n\nCustomize Dashboards in Tableau\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex09.html#tableau",
    "href": "In-Class_Ex/In-Class_Ex09.html#tableau",
    "title": "In-Class Exercise 09",
    "section": "Tableau",
    "text": "Tableau\n\nImporting the Dataset\nFor the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\n\n\n\n\n\n\nNot Compatible Microsoft Database Access for Mac\n\n\n\nPlease note that Microsoft Database Access is not applicable for Mac, to be able to use the data convert the specific database to excel format\n\n\n\n\nCreating the Tableau Database\n\n                   \n\n\n\n\n\n\nEase in Visibility\n\n\n\nTo ensure that the dashboard is clear and easy to read, ensure that the charts and visuals can be fit in a single page. Adjust the size to reduce scrolling action by the user."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex09.html#getting-started-in-r",
    "href": "In-Class_Ex/In-Class_Ex09.html#getting-started-in-r",
    "title": "In-Class Exercise 09",
    "section": "Getting started in R",
    "text": "Getting started in R\nFor the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse, RODBC, readr)\n\n\ntidyverse provides a collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data. It is not a single package but a collection of modern R packages including but not limited to readr, tidyr, dplyr, ggplot, tibble, stringr, forcats and purrr.\nlubridate provides functions to work with dates and times more efficiently.\nggthemes is an extension of ggplot2. It provides additional themes beyond the basic themes of ggplot2.\ngtExtras provides some additional helper functions to assist in creating beautiful tables with gt, an R package specially designed for anyone to make wonderful-looking tables using the R programming language.\nreactablefmtr provides various features to streamline and enhance the styling of interactive reactable tables with easy-to-use and highly-customizable functions and themes."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex09.html#importing-microsoft-access-database",
    "href": "In-Class_Ex/In-Class_Ex09.html#importing-microsoft-access-database",
    "title": "In-Class Exercise 09",
    "section": "Importing Microsoft Access database",
    "text": "Importing Microsoft Access database\n\nThe data set\nFor the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\n\n\nImporting database into R\nIn the code chunk below, odbcConnectAccess() of RODBC package is used used to import a database query table into R.\n\n#library(RODBC)\n#con <- odbcConnectAccess('data/Coffee Chain.mdb')\n#coffeechain <- sqlFetch(con, 'CoffeeChain Query')\n#write_rds(coffeechain, \"data/CoffeeChain.rds\")\n#odbcClose(con)\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the odbcConnectAccess() is based on 32bit and not 64bit\n\n\nData Preparation\nThe code chunk below is used to import CoffeeChain.rds into R.\n\ncoffeechain <- read_rds(\"data/CoffeeChain.rds\")\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nproduct <- coffeechain %>%\n  group_by(`Product`) %>%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %>%\n  ungroup()\n\n\n\nBullet chart in ggplot2\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex09.html#plotting-sparklines-using-ggplot2",
    "href": "In-Class_Ex/In-Class_Ex09.html#plotting-sparklines-using-ggplot2",
    "title": "In-Class Exercise 09",
    "section": "Plotting sparklines using ggplot2",
    "text": "Plotting sparklines using ggplot2\nIn this section, you will learn how to plot sparklines by using ggplot2.\n\nPreparing the data\n\nsales_report <- coffeechain %>%\n  filter(Date >= \"2013-01-01\") %>%\n  mutate(Month = month(Date)) %>%\n  group_by(Month, Product) %>%\n  summarise(Sales = sum(Sales)) %>%\n  ungroup() %>%\n  select(Month, Product, Sales)\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\nmins <- group_by(sales_report, Product) %>% \n  slice(which.min(Sales))\nmaxs <- group_by(sales_report, Product) %>% \n  slice(which.max(Sales))\nends <- group_by(sales_report, Product) %>% \n  filter(Month == max(Month))\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\nquarts <- sales_report %>%\n  group_by(Product) %>%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %>%\n  right_join(sales_report)\n\n\n\nsparklines in ggplot2\nThe code chunk used.\n\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex09.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "href": "In-Class_Ex/In-Class_Ex09.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "title": "In-Class Exercise 09",
    "section": "Static Information Dashboard Design: gt and gtExtras methods",
    "text": "Static Information Dashboard Design: gt and gtExtras methods\nIn this section, you will learn how to create static information dashboard by using gt and gtExtras packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\n\nPlotting a simple bullet chart\nIn this section, you will learn how to prepare a bullet chart report by using functions of gt and gtExtras packages.\n\nproduct %>%\n  gt::gt() %>%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %>%\n  gt_theme_538()\n\n\n\n\n\n  \n  \n    \n      Product\n      current\n    \n  \n  \n    Amaretto\n          \n    Caffe Latte\n          \n    Caffe Mocha\n          \n    Chamomile\n          \n    Colombian\n          \n    Darjeeling\n          \n    Decaf Espresso\n          \n    Decaf Irish Cream\n          \n    Earl Grey\n          \n    Green Tea\n          \n    Lemon\n          \n    Mint\n          \n    Regular Espresso"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex09.html#sparklines-gtextras-method",
    "href": "In-Class_Ex/In-Class_Ex09.html#sparklines-gtextras-method",
    "title": "In-Class Exercise 09",
    "section": "sparklines: gtExtras method",
    "text": "sparklines: gtExtras method\nBefore we can prepare the sales report by product by using gtExtras functions, code chunk below will be used to prepare the data.\n\nreport <- coffeechain %>%\n  mutate(Year = year(Date)) %>%\n  filter(Year == \"2013\") %>%\n  mutate (Month = month(Date, \n                        label = TRUE, \n                        abbr = TRUE)) %>%\n  group_by(Product, Month) %>%\n  summarise(Sales = sum(Sales)) %>%\n  ungroup()\n\nIt is important to note that one of the requirement of gtExtras functions is that almost exclusively they require you to pass data.frame with list columns. In view of this, code chunk below will be used to convert the report data.frame into list columns.\n\nreport %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n# A tibble: 13 × 2\n   Product           `Monthly Sales`\n   <chr>             <list>         \n 1 Amaretto          <dbl [12]>     \n 2 Caffe Latte       <dbl [12]>     \n 3 Caffe Mocha       <dbl [12]>     \n 4 Chamomile         <dbl [12]>     \n 5 Colombian         <dbl [12]>     \n 6 Darjeeling        <dbl [12]>     \n 7 Decaf Espresso    <dbl [12]>     \n 8 Decaf Irish Cream <dbl [12]>     \n 9 Earl Grey         <dbl [12]>     \n10 Green Tea         <dbl [12]>     \n11 Lemon             <dbl [12]>     \n12 Mint              <dbl [12]>     \n13 Regular Espresso  <dbl [12]>     \n\n\n\nPlotting Coffechain Sales report\n\nreport %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %>%\n   gt() %>%\n   gt_plt_sparkline('Monthly Sales')\n\n\n\n\n\n  \n  \n    \n      Product\n      Monthly Sales\n    \n  \n  \n    Amaretto\n          1.2K\n    Caffe Latte\n          1.5K\n    Caffe Mocha\n          3.7K\n    Chamomile\n          3.3K\n    Colombian\n          5.5K\n    Darjeeling\n          3.0K\n    Decaf Espresso\n          3.2K\n    Decaf Irish Cream\n          2.7K\n    Earl Grey\n          3.0K\n    Green Tea\n          1.5K\n    Lemon\n          4.4K\n    Mint\n          1.5K\n    Regular Espresso\n          1.1K\n  \n  \n  \n\n\n\n\n\n\nAdding statistics\nFirst, calculate summary statistics by using the code chunk below.\n\nreport %>% \n  group_by(Product) %>% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %>%\n  gt() %>%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\n  \n  \n    \n      Product\n      Min\n      Max\n      Average\n    \n  \n  \n    Amaretto\n1016\n1210\n1,119.00\n    Caffe Latte\n1398\n1653\n1,528.33\n    Caffe Mocha\n3322\n3828\n3,613.92\n    Chamomile\n2967\n3395\n3,217.42\n    Colombian\n5132\n5961\n5,457.25\n    Darjeeling\n2926\n3281\n3,112.67\n    Decaf Espresso\n3181\n3493\n3,326.83\n    Decaf Irish Cream\n2463\n2901\n2,648.25\n    Earl Grey\n2730\n3005\n2,841.83\n    Green Tea\n1339\n1476\n1,398.75\n    Lemon\n3851\n4418\n4,080.83\n    Mint\n1388\n1669\n1,519.17\n    Regular Espresso\n890\n1218\n1,023.42\n  \n  \n  \n\n\n\n\n\n\nCombining the data.frame\nNext, use the code chunk below to add the statistics on the table.\n\nspark <- report %>%\n  group_by(Product) %>%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\nsales <- report %>% \n  group_by(Product) %>% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\nsales_data = left_join(sales, spark)\n\n\n\nPlotting the updated data.table\n\nsales_data %>%\n  gt() %>%\n  gt_plt_sparkline('Monthly Sales')\n\n\n\n\n\n  \n  \n    \n      Product\n      Min\n      Max\n      Average\n      Monthly Sales\n    \n  \n  \n    Amaretto\n1016\n1210\n1119.000\n          1.2K\n    Caffe Latte\n1398\n1653\n1528.333\n          1.5K\n    Caffe Mocha\n3322\n3828\n3613.917\n          3.7K\n    Chamomile\n2967\n3395\n3217.417\n          3.3K\n    Colombian\n5132\n5961\n5457.250\n          5.5K\n    Darjeeling\n2926\n3281\n3112.667\n          3.0K\n    Decaf Espresso\n3181\n3493\n3326.833\n          3.2K\n    Decaf Irish Cream\n2463\n2901\n2648.250\n          2.7K\n    Earl Grey\n2730\n3005\n2841.833\n          3.0K\n    Green Tea\n1339\n1476\n1398.750\n          1.5K\n    Lemon\n3851\n4418\n4080.833\n          4.4K\n    Mint\n1388\n1669\n1519.167\n          1.5K\n    Regular Espresso\n890\n1218\n1023.417\n          1.1K\n  \n  \n  \n\n\n\n\n\n\nCombining bullet chart and sparklines\nSimilarly, we can combining the bullet chart and sparklines using the steps below.\n\nbullet <- coffeechain %>%\n  filter(Date >= \"2013-01-01\") %>%\n  group_by(`Product`) %>%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %>%\n  ungroup() \n\n\nsales_data = sales_data %>%\n  left_join(bullet)\n\n\nsales_data %>%\n  gt() %>%\n  gt_plt_sparkline('Monthly Sales') %>%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %>%\n  gt_theme_538()\n\n\n\n\n\n  \n  \n    \n      Product\n      Min\n      Max\n      Average\n      Monthly Sales\n      Actual\n    \n  \n  \n    Amaretto\n1016\n1210\n1119.000\n          1.2K\n          \n    Caffe Latte\n1398\n1653\n1528.333\n          1.5K\n          \n    Caffe Mocha\n3322\n3828\n3613.917\n          3.7K\n          \n    Chamomile\n2967\n3395\n3217.417\n          3.3K\n          \n    Colombian\n5132\n5961\n5457.250\n          5.5K\n          \n    Darjeeling\n2926\n3281\n3112.667\n          3.0K\n          \n    Decaf Espresso\n3181\n3493\n3326.833\n          3.2K\n          \n    Decaf Irish Cream\n2463\n2901\n2648.250\n          2.7K\n          \n    Earl Grey\n2730\n3005\n2841.833\n          3.0K\n          \n    Green Tea\n1339\n1476\n1398.750\n          1.5K\n          \n    Lemon\n3851\n4418\n4080.833\n          4.4K\n          \n    Mint\n1388\n1669\n1519.167\n          1.5K\n          \n    Regular Espresso\n890\n1218\n1023.417\n          1.1K"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex09.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "href": "In-Class_Ex/In-Class_Ex09.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "title": "In-Class Exercise 09",
    "section": "Interactive Information Dashboard Design: reactable and reactablefmtr methods",
    "text": "Interactive Information Dashboard Design: reactable and reactablefmtr methods\nIn this section, you will learn how to create interactive information dashboard by using reactable and reactablefmtr packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\nIn order to build an interactive sparklines, we need to install dataui R package by using the code chunk below.\n\nremotes::install_github(\"timelyportfolio/dataui\")\n\nNext, you all need to load the package onto R environment by using the code chunk below.\n\nlibrary(dataui)\n\n\nPlotting interactive sparklines\nSimilar to gtExtras, to plot an interactive sparklines by using reactablefmtr package we need to prepare the list field by using the code chunk below.\n\nreport <- report %>%\n  group_by(Product) %>%\n  summarize(`Monthly Sales` = list(Sales))\n\nNext, react_sparkline will be to plot the sparklines as shown below.\n\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nChanging the pagesize\nBy default the pagesize is 10. In the code chunk below, arguments defaultPageSize is used to change the default setting.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding points and labels\nIn the code chunk below highlight_points argument is used to show the minimum and maximum values points and label argument is used to label first and last values.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding reference line\nIn the code chunk below statline argument is used to show the mean line.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nAdding bandline\nInstead adding reference line, bandline can be added by using the bandline argument.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nChanging from sparkline to sparkbar\nInstead of displaying the values as sparklines, we can display them as sparkbars as shiwn below.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html",
    "href": "In-Class_Ex/In-Class_Ex08.html",
    "title": "In-Class Exercise 08",
    "section": "",
    "text": "In this in class exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex08.html#getting-started",
    "title": "In-Class Exercise 08",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#the-data",
    "href": "In-Class_Ex/In-Class_Ex08.html#the-data",
    "title": "In-Class Exercise 08",
    "section": "The Data",
    "text": "The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nThe edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#the-data-1",
    "href": "In-Class_Ex/In-Class_Ex08.html#the-data-1",
    "title": "In-Class Exercise 08",
    "section": "The Data",
    "text": "The Data\n\nThe nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#importing-network-data-from-files",
    "href": "In-Class_Ex/In-Class_Ex08.html#importing-network-data-from-files",
    "title": "In-Class Exercise 08",
    "section": "Importing network data from files",
    "text": "Importing network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\nReviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nWarning: The output report of GAStech_edges above reveals that the SentDate is treated as “Character”” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\nWrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\nThings to learn from the code chunk above:\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\n\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\nReviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    <date> 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     <ord> Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\nWrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\nThings to learn from the code chunk above:\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\n\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\nReviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  <dbl> 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday <ord> Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  <int> 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#creating-network-objects-using-tidygraph",
    "href": "In-Class_Ex/In-Class_Ex08.html#creating-network-objects-using-tidygraph",
    "title": "In-Class Exercise 08",
    "section": "Creating network objects using tidygraph",
    "text": "Creating network objects using tidygraph\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 – A tidy hope\n\n\nThe tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network.\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#the-dplyr-verbs-in-tidygraph",
    "href": "In-Class_Ex/In-Class_Ex08.html#the-dplyr-verbs-in-tidygraph",
    "title": "In-Class Exercise 08",
    "section": "The dplyr verbs in tidygraph",
    "text": "The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\nUsing tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\nReviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# … with 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# … with 1,369 more rows\n\n\n\n\nReviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\nChanging the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# … with 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# … with 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\nPlotting Network Data with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\n[edges]((https://cran.r-project.org/web/packages/ggraph/vignettes/Edges.html) and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nPlotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\nThings to learn from the code chunk above:\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\nChanging the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\n\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\nChanging the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\nWorking with ggraph’s layouts\nggraph() support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\nFruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\nModifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\nModifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#creating-facet-graphs",
    "href": "In-Class_Ex/In-Class_Ex08.html#creating-facet-graphs",
    "title": "In-Class Exercise 08",
    "section": "Creating facet graphs",
    "text": "Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\nWorking with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\nWorking with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\nA framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nWorking with facet_nodes()\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#network-metrics-analysis",
    "href": "In-Class_Ex/In-Class_Ex08.html#network-metrics-analysis",
    "title": "In-Class Exercise 08",
    "section": "Network Metrics Analysis",
    "text": "Network Metrics Analysis\n\nComputing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\nVisualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\nVisualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "href": "In-Class_Ex/In-Class_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "title": "In-Class Exercise 08",
    "section": "Building Interactive Network Graph with visNetwork",
    "text": "Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\nData preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\nPlotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\nWorking with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\nWorking with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nWorking with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument. ]\n\n\nInteractivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n- The argument highlightNearest highlights nearest when clicking a node.\n- The argument nodesIdSelection adds an id node selection creating an HTML select element.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  }
]